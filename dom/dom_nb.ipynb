{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dom's Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hypothesis:\n",
    "\n",
    "(01/09/20)\n",
    "- Taxo ID [7,8] fall into Exec and consult\n",
    "- taxo ID [3,4,5,9] fall into specialists\n",
    "- Taxo ID [1,2,6] are further divided by experience level\n",
    "        - we weren't satisfied on the results of this grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wrangle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d0a726f7df52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwrangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminmax_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wrangle'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import wrangle, explore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import minmax_scale, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('/Users/dom/codeup_data_science/capstone/kev/survey_responses.xlsx', )\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = pd.read_excel('../data_files/data_dictionary.xlsx')\n",
    "data_dictionary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns = data_dictionary[['qid','column_name']].set_index('qid').column_name, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,_ = wrangle.wrangle_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking freds nlp functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('../fred')\n",
    "# import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat, vect = nlp.create_tfidf_matrix(df.best_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quantitative columns\n",
    "quant_cols = df.select_dtypes([int,float]).columns\n",
    "quant_cols.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jobs by taxo id\n",
    "    #1 is UX researchers\n",
    "    #2 is Developers\n",
    "    #3 is Researcher/Scientist\n",
    "    #4 is Academic/Students\n",
    "    #5 is Planners?\n",
    "    #6 is Design/Research Managers\n",
    "    #7 is Consultans\n",
    "    #8 is Executive\n",
    "    #9 is misc\n",
    "data.groupby(['job_taxo', 'job_title']).job_title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['persona_id','job_taxo']).persona_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.persona_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_cols = ['exp_conduct_res', 'exp_analyze_res',\n",
    "           'exp_buy_res_report', 'exp_manage_res_proj', 'exp_observe_res',\n",
    "           'exp_plan_res', 'exp_teach_res', 'exp_advocate_res',\n",
    "           'exp_hire_res_vendor', 'exp_lead_res_team']\n",
    "df[exp_cols].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show distributions of values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish features and target and split train and test data\n",
    "def assign_target(x):\n",
    "    group=0\n",
    "    if x.learning_conference > 1:\n",
    "        group += 1\n",
    "    if x.likely_conference > 1:\n",
    "        group += 1\n",
    "    return group\n",
    "df['target'] = df.apply(assign_target, axis = 1)\n",
    "\n",
    "x = quant_cols.drop(['likely_conference','learning_conference', 'likely_workshop','learning_workshop']).to_list()+['persona_id', 'job_taxo']\n",
    "y = 'target'\n",
    "train, test = train_test_split(df[x+[y]].dropna(subset = [y]), stratify = df[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/14/20\n",
    "#use svm or \n",
    "#form hypothesis and test them\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,11))\n",
    "sns.heatmap(df.corr(), cmap = 'icefire_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('persona_id').likely_conference.agg(['mean', 'median',]).plot.bar()\n",
    "plt.show()\n",
    "df.groupby('persona_id').likely_conference.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('persona_id').learning_conference.agg(['mean', 'median']).plot.bar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('persona_id').target.agg(['mean', 'median']).plot.bar()\n",
    "plt.ylim(.8, 2.2)\n",
    "plt.show()\n",
    "df.groupby('persona_id').target.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttests = {}\n",
    "row = {}\n",
    "for i in df.persona_id.unique().sort_values(ascending = False):\n",
    "    for j in df.persona_id.unique().sort_values(ascending = False):\n",
    "        ttests[j] = ttest_ind(df[df.persona_id == i].target,df[(df.persona_id == j)].target, nan_policy='omit')[1]\n",
    "    row[i] = ttests.copy()\n",
    "sns.heatmap(pd.DataFrame(row), vmin = .01, vmax=.05)\n",
    "plt.title('Statistical difference between persona groups of likelyhood to attend a conference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After consideration, I have decided to scrap this model and opt to use chi squared tests to determine which features to eliminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, max_features=20, random_state=123)\n",
    "tree.fit(train[x], train[y])\n",
    "predicted = tree.predict(test[x]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test[y], predicted))\n",
    "pd.crosstab(test[y], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(tree, feature_names=train[x].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(tree.feature_importances_, index = train[x].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = SVC(random_state=123)\n",
    "reg.fit(train[x], train[y])\n",
    "predicted = reg.predict(test[x])\n",
    "r2 = reg.score(test[x], test[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test[y], predicted))\n",
    "pd.crosstab(test[y], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mvp = df[['job_taxo', 'persona_id', 'num_employees']].join(pd.DataFrame(df[['exp_conduct_res']].apply(max, axis = 1), columns = ['experience']),).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode for job taxos\n",
    "df_mvp_ohe = pd.get_dummies(df_mvp, columns=['job_taxo']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_mvp_ohe.drop(columns=['persona_id']).columns.to_list()\n",
    "y = 'persona_id'\n",
    "train, test = train_test_split(df_mvp_ohe, random_state = 123, stratify = df_mvp_ohe.persona_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(random_state=123)\n",
    "classifier.fit(train[x], train[y])\n",
    "predicted = classifier.predict(test[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test[y], predicted))\n",
    "pd.crosstab(test[y], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "tree.fit(train[x], train[y])\n",
    "predicted = tree.predict(test[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test[y], predicted))\n",
    "pd.crosstab(test[y], predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['persona_id','job_title']).job_taxo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['persona_id','num_employees'], ).job_taxo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['persona_id','session_network']).job_taxo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['persona_id','factor_speaker']).job_taxo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['persona_id','factor_diverse_speak']).job_title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('persona_id').job_title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df.persona_id, y= df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.num_employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in quant_cols:\n",
    "    df[i].plot.hist()\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.persona_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.persona_id.value_counts()/df.persona_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_trained_in_research(df, persona_column = 'persona_id'):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chi2 = pd.read_csv('../kev/chi2_2dfall.txt', index_col='index')\n",
    "sns.heatmap(pd.crosstab(index = chi2.chk_col, columns=chi2.vs_col,values = chi2.p_val, aggfunc='median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_row = {}\n",
    "chi2_df = {}\n",
    "for i in quant_cols:\n",
    "    for j in quant_cols:\n",
    "        observations = pd.crosstab(index = df[i], columns = df[j])\n",
    "        chi2_row[j] = chi2_contingency(observations)[1]\n",
    "    chi2_df[i] = chi2_row.copy()\n",
    "chi2_df = pd.DataFrame(chi2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,14))\n",
    "sns.heatmap(chi2_df,cmap = 'BuGn', vmax=.05, vmin=.01)\n",
    "plt.title('big bad mega chi2 plot muah hah hah hah')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_qs  = ['job_conduct_res', 'job_analyze_res', 'job_buy_res_report',\n",
    "           'job_manage_res_proj', 'job_observe_res', 'job_plan_res',\n",
    "           'job_teach_res', 'job_advocate_res', 'job_hire_res_vendor',\n",
    "           'job_lead_res_team',]\n",
    "sns.heatmap(chi2_df.loc[job_qs,job_qs],cmap = 'BuGn', vmax=.05, vmin=.01)\n",
    "plt.title('How much is your current job devoted to...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_qs  = ['exp_conduct_res', 'exp_analyze_res',\n",
    "           'exp_buy_res_report', 'exp_manage_res_proj', 'exp_observe_res',\n",
    "           'exp_plan_res', 'exp_teach_res', 'exp_advocate_res',\n",
    "           'exp_hire_res_vendor', 'exp_lead_res_team',]\n",
    "sns.heatmap(chi2_df.loc[exp_qs,exp_qs],cmap = 'BuGn', vmax=.05, vmin=.01)\n",
    "plt.title('How much experience do you have with...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_qs = ['learning_talks',\n",
    "               'learning_read', 'learning_meetup', 'learning_workshop',\n",
    "               'learning_conference']\n",
    "sns.heatmap(chi2_df.loc[learning_qs,learning_qs],cmap = 'BuGn', vmax=.05, vmin=.01)\n",
    "plt.title('How much experience do you have with...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likely_qs  =  ['likely_watch_video', 'likely_internet',\n",
    "               'likely_book', 'likely_online_group', 'likely_colleague',\n",
    "               'likely_meetup', 'likely_conference', 'likely_workshop',]\n",
    "sns.heatmap(chi2_df.loc[likely_qs,likely_qs],cmap = 'BuGn', vmax=.1, vmin=.01)\n",
    "plt.title('How much experience do you have with...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = ['factor_speaker', 'factor_diverse_speak', 'factor_topics', \n",
    "           'factor_format_sessions', 'factor_size', 'factor_network', \n",
    "           'factor_variety_attend', 'factor_code', 'factor_location', \n",
    "           'factor_ability_to_pay']\n",
    "sns.heatmap(chi2_df.loc[factors,factors],cmap = 'BuGn', vmax=.05, vmin=.01)\n",
    "plt.title('factor questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_qs  = ['session_keynote', 'session_long_talk',\n",
    "               'session_short_talk', 'session_workshop', 'session_network',\n",
    "               'session_social_event', 'session_qa', 'sesson_topic_tables']\n",
    "sns.heatmap(chi2_df.loc[session_qs,session_qs],cmap = 'BuGn', vmax=.05, vmin=.01)\n",
    "plt.title('most important session types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.persona_id.unique():\n",
    "    print(df[df.persona_id == i].factor_speaker.value_counts().sort_index(),f'[{i}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_factor_speaker(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x == 1 or x == 2:\n",
    "        return 1\n",
    "    elif x == 3:\n",
    "        return 2\n",
    "    elif x == 4:\n",
    "        return 3\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.persona_id.unique():\n",
    "    print(f'[ {i} ]')\n",
    "    print(df[df.persona_id == i].factor_diverse_speak.apply(encode_factor_speaker).value_counts().sort_index(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.persona_id, df.factor_speaker,).plot(kind = 'bar', stacked = True, cmap = 'Greys').set_facecolor('xkcd:salmon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.persona_id, df.factor_diverse_speak.apply(encode_factor_speaker),).plot(kind = 'bar', stacked = True, cmap = 'Greys').set_facecolor('xkcd:salmon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.crosstab(df.factor_network.apply(encode_factor_speaker),df.persona_id, )\n",
    "# .plot(kind = 'bar', stacked = True, cmap = 'Greys').set_facecolor('xkcd:salmon')\n",
    "for i in matrix:\n",
    "    matrix[i] = matrix[i]/sum(matrix[i])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_bars(df, factor, return_matrix = False):\n",
    "    matrix = pd.crosstab(df[factor].apply(encode_factor_speaker),df.persona_id,)\n",
    "    for i in matrix:\n",
    "        matrix[i] = matrix[i]/sum(matrix[i])\n",
    "    ax = matrix.transpose().plot(kind = 'barh', stacked = True, cmap = 'Greys')\n",
    "    ax.set_facecolor('xkcd:light grey')\n",
    "    plt.title(factor)\n",
    "    plt.legend().remove()\n",
    "    plt.ylabel(' ')\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([0,1,2,3,4],['Exec & Consult', 'Specialist','High Experience','Mid Experience','Low Experience'])\n",
    "    plt.show()\n",
    "    if return_matrix is True:\n",
    "        return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matricies = {}\n",
    "j = 0\n",
    "for i in ['factor_speaker','factor_diverse_speak','factor_network']:\n",
    "    matricies[j] = create_stacked_bars(df, i, return_matrix=True)\n",
    "    j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona = {}\n",
    "all_personas = {}\n",
    "titles = ['Execs/Consult', 'Specialists', 'Very Expd', 'Med Expd', 'Less Expd']\n",
    "for j in range(1,6):\n",
    "    for i in [0,1,2]:\n",
    "        persona[matricies[i].index.name] = matricies[i][j]\n",
    "    all_personas[j] = pd.DataFrame(persona.copy())\n",
    "for dataframe in all_personas.keys():\n",
    "    ax = all_personas[dataframe].transpose().plot(kind = 'barh', stacked = True, cmap = 'Blues')\n",
    "    ax.set_facecolor('xkcd:light grey')\n",
    "    plt.title(dataframe)\n",
    "    plt.legend().remove()\n",
    "    plt.ylabel(' ')\n",
    "    plt.xticks([],[])\n",
    "    plt.annotate('Networking Opportunities', (0,2.4), fontsize=15)\n",
    "    plt.annotate('Diversity of Speakers', (0,1.4), fontsize=15)\n",
    "    plt.annotate('Speaker Name Recognition',(0,.4),fontsize=15)\n",
    "    plt.annotate('',xy=(1 , -.5), xycoords='data',\n",
    "                    xytext=(0, -.5), textcoords='data',\n",
    "                    arrowprops=dict(arrowstyle=\"->\",\n",
    "                    connectionstyle=\"arc3\"))\n",
    "    plt.yticks([],[])\n",
    "    plt.ylim(-.7,2.8)\n",
    "    plt.xlim(-.1,1.1)\n",
    "    sns.despine(left=True, bottom=True, right=True)\n",
    "\n",
    "    plt.savefig(f'/Users/dom/codeup_data_science/capstone/viz_files/their_personas/{dataframe}_stacked_bars', transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "persona_counts = (pd.DataFrame(df\n",
    "                               .groupby(by=['persona_id'])\n",
    "                               .target\n",
    "                               .agg('count')\n",
    "                              )\n",
    "                  .rename(columns={'target': 'count'})\n",
    "                 )\n",
    "job_group_by = ['persona_id', 'job_title']\n",
    "job_counts = (pd.DataFrame(df\n",
    "                           .groupby(by=job_group_by)\n",
    "                           .target\n",
    "                           .agg('count')\n",
    "                          )\n",
    "              .reset_index()\n",
    "              .rename(columns={'target': 'count'})\n",
    "              .sort_values(by=['persona_id','count'], ascending=[True,False]))\n",
    "job_counts = job_counts.merge(\n",
    "    persona_counts.rename(columns={'count':'total'}), \n",
    "    how='left', left_on='persona_id', right_on='persona_id')\n",
    "job_counts['pid_pct'] = np.array(job_counts['count'])/np.array(job_counts['total'])\n",
    "job_counts = job_counts.drop(columns='total')\n",
    "job_counts = job_counts.set_index(['persona_id', 'job_title'])\n",
    "for p in persona_counts.index:\n",
    "    jc = job_counts.loc[idx[[p],:]].head(3).copy()\n",
    "    display(jc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.pid_pct.max()*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Execs_Consult', 'Specialists', 'Very_Expd', 'Med_Expd', 'Less_Expd']\n",
    "\n",
    "# Consultant Job Titles\n",
    "print(titles[0])\n",
    "jc = job_counts.loc[idx[[1],:]].head(3).copy()\n",
    "jc=jc.reset_index().sort_values(by='pid_pct')\n",
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "ax1.barh(jc.job_title, width=jc.pid_pct, height=.5, tick_label = jc.job_title, color = '#00297f')\n",
    "ax1.set_facecolor('xkcd:light grey')\n",
    "pcts = [int(round(jc[\"pid_pct\"][0]*100)), int(round(jc[\"pid_pct\"][1]*100))]\n",
    "plt.annotate(f'Consultant {pcts[0]}%', (0,1.3), fontsize = 15)\n",
    "plt.annotate(f'Executive {pcts[1]}%'  ,(0,.3), fontsize = 15)\n",
    "plt.ylim(-.5,2.1)\n",
    "plt.xlim(-.1*jc.pid_pct.max(), jc.pid_pct.max()*1.1)\n",
    "plt.yticks([],[])\n",
    "plt.xticks([],[])\n",
    "sns.despine(left=True, bottom=True, right=True)\n",
    "\n",
    "plt.savefig(f'/Users/dom/codeup_data_science/capstone/viz_files/their_personas/{titles[0]}_titles.png', transparent = True)\n",
    "\n",
    "# Everyone Else Job Titles\n",
    "for i in range(2,6):\n",
    "    print(titles[i-1])\n",
    "    persona_titles = []\n",
    "    jc = job_counts.loc[idx[[i],:]].head(3).copy()\n",
    "    jc = jc.reset_index().sort_values(by='pid_pct')\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "    ax1.barh(jc.job_title, width=jc.pid_pct, height=.5, tick_label = jc.job_title, color = '#00297f')\n",
    "    ax1.set_facecolor('xkcd:light grey')\n",
    "    pcts = [int(round(jc[\"pid_pct\"][0]*100)), int(round(jc[\"pid_pct\"][1]*100)),int(round(jc[\"pid_pct\"][2]*100))]\n",
    "    plt.annotate(f'{jc.job_title[0]} {pcts[0]}%', (0,2.3), fontsize = 15)\n",
    "    plt.annotate(f'{jc.job_title[1]} {pcts[1]}%', (0,1.3), fontsize = 15)\n",
    "    plt.annotate(f'{jc.job_title[2]} {pcts[2]}%'  ,(0,.3), fontsize = 15)\n",
    "    plt.yticks([],[])\n",
    "    plt.xticks([],[])\n",
    "    plt.ylim(-.7,2.8)\n",
    "    plt.xlim(-.1*jc.pid_pct.max(), jc.pid_pct.max()*1.1)\n",
    "    sns.despine(left=True, bottom=True, right=True)\n",
    "\n",
    "    plt.savefig(f'/Users/dom/codeup_data_science/capstone/viz_files/their_personas/{titles[i-1]}_titles.png', transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets bust out these pi charts hoe\n",
    "def sm_med_large_co(x):\n",
    "    if x is 0 or x is 1 or x is 2:\n",
    "        return 1\n",
    "    if x is 3 or x is 4:\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matricies = {}\n",
    "co_size_matrix = pd.crosstab(df.persona_id,df.num_employees.apply(int).apply(sm_med_large_co))\n",
    "matricies[0] = co_size_matrix.transpose()\n",
    "res_edu_matrix = pd.crosstab(df.persona_id,df.research_educ_cat).rename(columns = {0:1,1:2})\n",
    "matricies[1] = res_edu_matrix.transpose().sort_index()\n",
    "matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona = {}\n",
    "all_personas = {}\n",
    "titles = ['Execs/Consult', 'Specialists', 'Very Expd', 'Med Expd', 'Less Expd']\n",
    "for j in range(1,6):\n",
    "    for i in [0,1]:\n",
    "        persona[matricies[i].index.name] = matricies[i][j]/sum(matricies[i][j])\n",
    "    all_personas[j] = pd.DataFrame(persona.copy())\n",
    "for dataframe in all_personas.keys():\n",
    "    ax = all_personas[dataframe].transpose().plot(kind = 'barh', stacked = True, cmap = 'Blues')\n",
    "    ax.set_facecolor('xkcd:light grey')\n",
    "    plt.title(dataframe)\n",
    "    plt.legend().remove()\n",
    "    plt.ylabel(' ')\n",
    "    plt.xticks([],[])\n",
    "    plt.annotate('Academically Trained in Research', (0,1.4), fontsize=15)\n",
    "    plt.annotate('Organization Size (>500)',(0,.4),fontsize=15)\n",
    "    plt.annotate('No',  (0.05, .96))\n",
    "    plt.annotate('Yes', (.885, .96), color = 'white')\n",
    "    plt.annotate('No', (0.05,-.04))\n",
    "    plt.annotate('Yes', (.885,-.04), color = 'white')\n",
    "    plt.yticks([],[])\n",
    "    plt.ylim(-.7,1.8)\n",
    "    plt.xlim(-.1,1.1)\n",
    "    sns.despine(left=True, bottom=True, right=True)\n",
    "\n",
    "    plt.savefig(f'/Users/dom/codeup_data_science/capstone/viz_files/their_personas/{dataframe}_not_pie_charts', transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
