{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import wrangle\n",
    "\n",
    "import nlp\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, data_dict = wrangle.wrangle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_questions = ['research_educ', 'research_educ_desc', 'how_pick_events', 'best_event',\n",
    "       'events_attend_recent', 'ideal_conference_size', 'ideal_structure',\n",
    "       'other_conference_types', 'ideal_topics', 'ideal_attendees',\n",
    "       'recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual = df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_id = df['persona_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_persona_corpus(df):\n",
    "    df_qual = df.select_dtypes(include='object')\n",
    "    persona_id = df['persona_id']\n",
    "    \n",
    "    return execs = df_qual[df_qual.persona_id == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['research_educ', 'research_educ_desc', 'how_pick_events', 'best_event',\n",
       "       'events_attend_recent', 'ideal_conference_size', 'ideal_structure',\n",
       "       'other_conference_types', 'ideal_topics', 'ideal_attendees',\n",
       "       'recommendations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qual.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual = df_qual.fillna('n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual = df_qual.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual['persona_id'] = persona_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual['big_answer'] = df_qual['research_educ'] + df_qual['research_educ_desc'] + df_qual['how_pick_events'] + df_qual['best_event'] + df_qual['events_attend_recent'] + df_qual['ideal_conference_size'] + df_qual['ideal_structure'] + df_qual['other_conference_types'] + df_qual['ideal_topics'] + df_qual['ideal_attendees'] + df_qual['recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qual['persona_id'] = persona_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "execs = df_qual[df_qual.persona_id == 1]\n",
    "specials = df_qual[df_qual.persona_id == 2]\n",
    "highs = df_qual[df_qual.persona_id == 3]\n",
    "mids = df_qual[df_qual.persona_id == 4]\n",
    "lows = df_qual[df_qual.persona_id == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4146245324407144"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execs.big_answer.apply(nlp.find_subjectivity).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4324475374544341"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specials.big_answer.apply(nlp.find_subjectivity).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4225761296898248"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highs.big_answer.apply(nlp.find_subjectivity).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43490051257783063"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mids.big_answer.apply(nlp.find_subjectivity).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44317635562947644"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lows.big_answer.apply(nlp.find_subjectivity).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_persona_keywords(input_column, max_df, min_df, ngram_range, n_keywords):\n",
    "    \"\"\"\n",
    "    Use a column/Series. Indicate the maximum and minimum amount of documents the words to be anlayzed. And ngram size\n",
    "    Returns a list \n",
    "    \"\"\"\n",
    "    input_column = input_column.dropna().apply(nlp.basic_clean)\n",
    "    input_column = input_column.apply(nlp.lemmatize)\n",
    "    count_vect = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english', ngram_range=ngram_range\n",
    "    matrix = count_vect.fit_transform(input_column)\n",
    "    return list(count_vect.vocabulary_.keys())[:n_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column = lows.big_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column = input_column.dropna().apply(nlp.basic_clean)\n",
    "input_column = input_column.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_df=.6, min_df=2, stop_words='english', ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = count_vect.fit_transform(input_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['researchnalocation',\n",
       " 'event',\n",
       " 'travelling',\n",
       " 'know',\n",
       " 'going',\n",
       " 'plus',\n",
       " 'topic',\n",
       " 'relevant',\n",
       " 'help',\n",
       " 'make',\n",
       " 'speaker',\n",
       " 'follow',\n",
       " 've',\n",
       " 'attended',\n",
       " 'consider',\n",
       " 'workshop',\n",
       " 'design',\n",
       " '300',\n",
       " 'timeslotsnoresearch',\n",
       " 'indi']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_vect.vocabulary_.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['ux', '300', 'conference 300', 'content', 'event', 'attendee experience', 'experience content', 'attendeessingletrack attendee', 'attendeessingletrack', 'experience']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['company', 'just', 'data', 'talk', 'ux', 'work', 'design', 'event', 'learning', 'people']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['good', 'practice', 'level', 'work', 'different', 'design', 'experience', 'new', 'topic', 'ux']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['case', 'ux research', 'really', 'make', 'researcher', 'pay', '300', 'conference 300', '300 attendeesmultitrack', 'ux']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['master degree', 'master', '300500 attendeesmultitrack', 'travel', 'design', 'degree', '50', '50 attendeesmultitrack', 'timeslotsnananana', 'available timeslotsnananana']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp.show_LDA_topic_words(matrix, count_vect, n_topics=5, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
