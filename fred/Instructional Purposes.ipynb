{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (nlp.py, line 230)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3319\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-79f4ef9170ec>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import nlp\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/fredricklambuth/Projects/capstone/fred/nlp.py\"\u001b[0;36m, line \u001b[0;32m230\u001b[0m\n\u001b[0;31m    blob = cv.fit_transform(input_column)\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import wrangle\n",
    "import explore\n",
    "import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_counts(input_column, max_df=.3, min_df=2, ngram_range=(1,3), stop_words='english'):\n",
    "    input_column = input_column.dropna().apply(nlp.basic_clean)\n",
    "    input_column = input_column.apply(nlp.lemmatize)\n",
    "    cv = CountVectorizer(max_df=max_df, min_df=min_df, stop_words=stop_words, ngram_range=ngram_range)   \n",
    "    cv_fit=cv.fit_transform(input_column)    \n",
    "    word_list = cv.get_feature_names()    \n",
    "    count_list = cv_fit.toarray().sum(axis=0)\n",
    "    word_counts = {'word_list': word_list, 'count_list': count_list}\n",
    "    df_word_count = pd.DataFrame(data=word_counts)\n",
    "    return df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df, data_dict = wrangle.wrangle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = nlp.create_biganswer_col(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=.9, min_df=2, ngram_range=(1,3), stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column = blob.apply(nlp.basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column = input_column.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit = cv.fit_transform(input_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer(\"This is a text document to analyze.\") == (['this', 'is', 'text', 'document', 'to', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv_fit.toarray().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_counts(input_column, max_df=.3, min_df=2, ngram_range=(1,3), stop_words='english'):\n",
    "#Cleans up nulls, weird characters, and reduces them to lemmas\n",
    "    input_column = input_column.dropna().apply(nlp.basic_clean)\n",
    "    input_column = input_column.apply(nlp.lemmatize)\n",
    "\n",
    "#cv is the Vector, cv_fit is the Matrix\n",
    "    cv = CountVectorizer(max_df=max_df, min_df=min_df, stop_words=stop_words, ngram_range=ngram_range)   \n",
    "    cv_fit=cv.fit_transform(input_column)\n",
    "    \n",
    "#An array of all the words that make up the Vector\n",
    "    word_list = cv.get_feature_names()    \n",
    "#An array of the freq-counts of each of the words in word_list\n",
    "#   .toarray() is a matrix that is as wide as the word list, tall as the amount of rows.  \n",
    "#   sum(axis=0) collapses the matrix into a vector, summing each column into one value. It will be as wide as word_list\n",
    "    count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "#The dictionary that will define what the DataFrame will be shaped\n",
    "    word_counts = {'word_list': word_list, 'count_list': count_list}\n",
    "    df_word_count = pd.DataFrame(data=word_counts)\n",
    "    return df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dale = find_word_counts(input_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
