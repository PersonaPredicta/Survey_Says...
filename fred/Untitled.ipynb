{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, data_dict = wrangle.wrangle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_name                                              future_res\n",
       "is_required                                                   False\n",
       "from_orig_file                                                 True\n",
       "in_wrangle                                                     True\n",
       "char_type                                                   numeric\n",
       "function                                                categorical\n",
       "data_type                                                  category\n",
       "encoder                                                         NaN\n",
       "survey_section                                                 Work\n",
       "question_group                                      Future Research\n",
       "question_text     What types of research are you (or your  team)...\n",
       "Name: q07, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.loc['q07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resp_id\n",
       "284           both qualitative and quantitative research\n",
       "288                                             Multiple\n",
       "294                                            Online FG\n",
       "281    surveys, interviews, focus groups, secondary d...\n",
       "280                                                  NaN\n",
       "                             ...                        \n",
       "869                                          Qual, quant\n",
       "879                                          diary study\n",
       "136    I don't know about the whole organisation, but...\n",
       "74     I would like to use geofencing techniques, mob...\n",
       "2                                                    NaN\n",
       "Name: future_res, Length: 726, dtype: category\n",
       "Categories (576, object): [- Cultural probes\\n- Live A/B testing\\n- Dairy..., - Making more use of remote testing possibilit..., /, 30 second test, user interviews, ..., what do you mean by \"type\"?, would like to incorporate more quant research ..., would like to open up toolkit to use panel stu..., would like to up our remote research game such...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 726 entries, 284 to 2\n",
      "Data columns (total 78 columns):\n",
      "job_title                         726 non-null category\n",
      "job_taxo                          726 non-null category\n",
      "job_id                            723 non-null category\n",
      "job_conduct_res                   726 non-null int64\n",
      "job_analyze_res                   726 non-null int64\n",
      "job_buy_res_report                726 non-null int64\n",
      "job_manage_res_proj               726 non-null int64\n",
      "job_observe_res                   726 non-null int64\n",
      "job_plan_res                      726 non-null int64\n",
      "job_teach_res                     726 non-null int64\n",
      "job_advocate_res                  726 non-null int64\n",
      "job_hire_res_vendor               726 non-null int64\n",
      "job_lead_res_team                 726 non-null int64\n",
      "num_employees                     723 non-null category\n",
      "num_researchers                   722 non-null category\n",
      "primary_industry                  726 non-null category\n",
      "types_res_used                    690 non-null category\n",
      "future_res                        609 non-null category\n",
      "exp_conduct_res                   726 non-null int64\n",
      "exp_analyze_res                   726 non-null int64\n",
      "exp_buy_res_report                726 non-null int64\n",
      "exp_manage_res_proj               726 non-null int64\n",
      "exp_observe_res                   726 non-null int64\n",
      "exp_plan_res                      726 non-null int64\n",
      "exp_teach_res                     726 non-null int64\n",
      "exp_advocate_res                  726 non-null int64\n",
      "exp_hire_res_vendor               726 non-null int64\n",
      "exp_lead_res_team                 726 non-null int64\n",
      "research_educ                     726 non-null object\n",
      "research_educ_cat                 726 non-null category\n",
      "research_educ_desc                540 non-null object\n",
      "learning_talks                    726 non-null int64\n",
      "learning_read                     726 non-null int64\n",
      "learning_meetup                   726 non-null int64\n",
      "learning_workshop                 726 non-null int64\n",
      "learning_conference               726 non-null int64\n",
      "likely_watch_video                726 non-null int64\n",
      "likely_internet                   726 non-null int64\n",
      "likely_book                       726 non-null int64\n",
      "likely_online_group               726 non-null int64\n",
      "likely_colleague                  726 non-null int64\n",
      "likely_meetup                     726 non-null int64\n",
      "likely_conference                 726 non-null int64\n",
      "likely_workshop                   726 non-null int64\n",
      "factor_speaker                    726 non-null int64\n",
      "factor_diverse_speak              726 non-null int64\n",
      "factor_topics                     726 non-null int64\n",
      "factor_format_sessions            726 non-null int64\n",
      "factor_size                       726 non-null int64\n",
      "factor_network                    726 non-null int64\n",
      "factor_variety_attend             726 non-null int64\n",
      "factor_code                       726 non-null int64\n",
      "factor_location                   726 non-null int64\n",
      "factor_ability_to_pay             726 non-null int64\n",
      "how_pick_events                   644 non-null object\n",
      "best_event                        594 non-null object\n",
      "events_attend_recent              558 non-null object\n",
      "ideal_conference_size             726 non-null object\n",
      "ideal_conference_size_cat_orig    724 non-null category\n",
      "ideal_conference_size_cat         726 non-null category\n",
      "ideal_structure                   726 non-null object\n",
      "ideal_structure_cat               726 non-null category\n",
      "ideal_multi_track                 726 non-null int64\n",
      "ideal_single_track                726 non-null int64\n",
      "ideal_unconference                726 non-null int64\n",
      "session_keynote                   726 non-null int64\n",
      "session_long_talk                 726 non-null int64\n",
      "session_short_talk                726 non-null int64\n",
      "session_workshop                  726 non-null int64\n",
      "session_network                   726 non-null int64\n",
      "session_social_event              726 non-null int64\n",
      "session_qa                        726 non-null int64\n",
      "sesson_topic_tables               726 non-null int64\n",
      "other_conference_types            258 non-null object\n",
      "ideal_topics                      560 non-null object\n",
      "ideal_attendees                   471 non-null object\n",
      "recommendations                   494 non-null object\n",
      "persona_id                        726 non-null category\n",
      "dtypes: category(13), int64(54), object(11)\n",
      "memory usage: 463.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_research = df.future_res.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True user research usability studies, ethnographic research, customer interview (we donâ€™t do any now!)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(text):\n",
    "    \"\"\"\n",
    "    accept some text and return the text after applying lemmatization to each word.\n",
    "    Use with .apply to a Pandas Series\n",
    "    \"\"\"\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "lemmatize(lemma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    \"\"\"\n",
    "    Lowercase everything\n",
    "    Normalize unicode characters\n",
    "    Replace anything that is not a letter, number, whitespace or a single quote\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    text = re.sub(r\"[^a-z0-9'\\s]\", '', text)\n",
    "    text = re.sub(r\"[\\r|\\n|\\r\\n]+\", ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lemma_test = basic_clean(lemma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true user research usability study ethnographic research customer interview we dont do any now'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.lemmatize(clean_lemma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['True',\n",
       " 'user',\n",
       " 'research',\n",
       " 'usability',\n",
       " 'studies,',\n",
       " 'ethnographic',\n",
       " 'research,',\n",
       " 'customer',\n",
       " 'interview',\n",
       " '(we',\n",
       " 'donâ€™t',\n",
       " 'do',\n",
       " 'any',\n",
       " 'now!)']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resp_id\n",
       "833    True user research usability studies, ethnogra...\n",
       "783    Diary studies, more contextual, increase in qu...\n",
       "791    All the method out there have a time and place...\n",
       "697                Unmoderated usability studies, survey\n",
       "754    More field studies, but my team more training ...\n",
       "854    More contextual/observational studies, unmoder...\n",
       "522    Just about everything. Still figuring out the ...\n",
       "476    Love/Breakup Letters, Diary studies, relations...\n",
       "486    Benchmark, true intent studies, more working w...\n",
       "856    We are considering exploring activity like dia...\n",
       "467    Longitudinal research and diary studies, affec...\n",
       "514                           Diary studies, card sorts.\n",
       "867                               Lots of field studies.\n",
       "395                Diary studies, competitive evaluation\n",
       "848     More quantitative surveys. Longitudinal studies.\n",
       "348                         Diary studies, on site visit\n",
       "390    Surveys, live/remote/in-home interviews, diary...\n",
       "273    More observational research a we have healthca...\n",
       "84     diary studies, remote usability testing, more ...\n",
       "38                Diary studies, more formative research\n",
       "67                            Diary studies, field study\n",
       "195    Diary studies, contextual inquiries, card sort...\n",
       "103    diary studies, remote unmoderated qualitative ...\n",
       "Name: future_res, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_research[future_research.str.find('studies')>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_test = future_research.loc[833]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lemma_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True user research usability studies, ethnographic research, customer interview (we donâ€™t do any now!)'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.lemmatize(lemma_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resp_id\n",
       "284                         research-practice connection\n",
       "288    Donâ€™t create schedule conflict with other rele...\n",
       "294                                     Looking forward!\n",
       "295    I actually feel like the biggest contribution ...\n",
       "290                Go ahead! Your prestige is a guaranty\n",
       "                             ...                        \n",
       "853    Research in agile, research on a shoestring bu...\n",
       "869    provide tool and resource and support for netw...\n",
       "879          Make it affordable. Somewhere in Europe. :)\n",
       "136    My goal is to provide constructive criticism, ...\n",
       "74     Instead of trying to create a general ideal co...\n",
       "Name: recommendations, Length: 494, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.recommendations.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix, count_vect = nlp.create_wordcount_matrix(future_research, max_df=0.3, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<609x566 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3024 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=3, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=3, random_state=42)\n",
    "LDA.fit(word_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el263901124270655363214253139\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el263901124270655363214253139_data = {\"mdsDat\": {\"x\": [-0.052133232145345425, -0.1172881782492527, 0.16942141039459815], \"y\": [-0.13000591488121538, 0.10046198362540783, 0.029543931255807475], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [38.02174675529758, 33.9776848065017, 28.00056843820072]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"Freq\": [42.0, 26.0, 53.0, 24.0, 22.0, 45.0, 15.0, 13.0, 13.0, 36.0, 16.0, 89.0, 30.0, 11.0, 140.0, 39.0, 13.0, 10.0, 10.0, 31.0, 14.0, 32.0, 9.0, 9.0, 21.0, 16.0, 8.0, 21.0, 11.0, 7.0, 21.458103363985245, 8.760079895953517, 11.090084004756847, 7.913174559459649, 8.571119305013305, 6.9531917888434664, 5.373051321072477, 5.370509169961515, 14.511007981633188, 5.343450374609968, 4.527938267289937, 4.503191621590613, 4.4950751222677665, 4.487736950951036, 5.184462438073015, 4.442226527009596, 3.6789473097183216, 3.678760006020733, 3.6639633306976895, 3.6639017146562316, 3.663077924033908, 4.3609357459028155, 7.957309872594657, 3.617925965300698, 5.749255824060578, 8.539681071003265, 2.8301856000958394, 2.829418930478642, 2.829216441366177, 2.8291445897499754, 24.646714687864222, 27.79405807890057, 32.49140151888487, 10.198354602562127, 82.97023797125566, 26.34955463329657, 54.75511259785215, 15.56738596592609, 16.088653473820287, 5.995360198063657, 19.7293958213063, 13.015381737185304, 13.129560485945257, 13.59925128169534, 12.36692388137837, 8.637899117712927, 6.132895204407473, 7.131058823857684, 7.21649640272722, 6.147747923842073, 6.411481314638833, 6.315978380856748, 25.44532963343537, 13.008212096224387, 15.322134953636748, 7.924716252305495, 7.0685337868692155, 7.053553769387731, 7.043812883068579, 13.261683680172062, 6.224722170547729, 5.379486998669899, 5.379016372594182, 5.361774400771069, 5.319257548595178, 4.532704754588027, 4.53130588959766, 4.528911963021026, 4.52414097087852, 4.5240626348988, 10.320931973127308, 4.421786394709118, 3.6832866111602462, 3.6832790957654953, 3.6832790957654953, 3.6804505757637527, 3.6765168271778363, 3.675103778000763, 3.6741892786347043, 3.6695978967618204, 3.66633880526373, 3.6538795423055834, 7.117417063434897, 7.091257896452519, 9.522010089177886, 16.096033497508827, 6.254733008356475, 15.468609139697778, 33.41089103857238, 19.63664747176762, 10.488439155157911, 6.500783869606413, 9.267523244318296, 30.05395865033418, 13.708458829212665, 15.459589674498826, 13.778987862575287, 12.20297745280464, 8.895447254997576, 9.66531163298876, 22.30943503168025, 12.414432621536376, 12.18599077475205, 7.947045444193615, 7.78371814313333, 7.429898044468399, 12.864130463611074, 12.855812725166139, 11.178983504087752, 10.34632862075913, 10.345446531817235, 8.664012002688752, 8.664011979383176, 40.099649621841856, 14.10941651959187, 7.829488749050469, 6.988124787419778, 6.15037170824412, 5.298919465663392, 5.2956635470686315, 4.45865601161446, 4.412367568752693, 3.6332686169867974, 3.6294147820424927, 3.62618554918048, 3.6247629948830906, 3.6183189400326192, 3.615268413521463, 6.501810836599303, 3.5938798233879354, 3.5638706739011954, 20.50043707392668, 2.7983329056066237, 2.798287162483481, 2.7963234874782468, 2.794947744880493, 19.78186862575599, 6.192062063346137, 8.470261574704134, 9.67172989460465, 6.1540111077415345, 6.037558949809523, 35.31040285284773, 12.426261942908273, 13.203214633267049, 10.20308375656799, 5.764979778591343, 8.237788335838125, 8.229515488891833, 6.494802553565605, 6.155583273411593, 5.537490632412714], \"Term\": [\"data\", \"studies\", \"usability\", \"contextual\", \"diary study\", \"study\", \"inquiry\", \"tracking\", \"contextual inquiry\", \"quantitative\", \"qual\", \"testing\", \"remote\", \"need\", \"research\", \"diary\", \"focus\", \"type\", \"help\", \"analytics\", \"diary studies\", \"usability testing\", \"eye\", \"eye tracking\", \"survey\", \"ethnography\", \"sure\", \"ethnographic\", \"mixed\", \"site\", \"diary study\", \"quantitative research\", \"mixed\", \"lab\", \"participatory\", \"mixed method\", \"remote unmoderated\", \"tree testing\", \"ethnography\", \"ai\", \"remote testing\", \"testing diary\", \"ux research\", \"deeper\", \"specific\", \"research design\", \"unmoderated testing\", \"making\", \"contextual research\", \"focused\", \"social\", \"participatory design\", \"online\", \"incorporate\", \"experience\", \"ux\", \"testing diary study\", \"cx\", \"continue\", \"screen\", \"remote\", \"quantitative\", \"study\", \"use\", \"research\", \"diary\", \"testing\", \"qualitative\", \"user\", \"tree\", \"usability\", \"unmoderated\", \"design\", \"method\", \"usability testing\", \"interviews\", \"benchmarking\", \"new\", \"like\", \"methods\", \"surveys\", \"analytics\", \"studies\", \"focus\", \"qual\", \"unmoderated usability\", \"groups\", \"customer\", \"service\", \"diary studies\", \"focus groups\", \"service design\", \"unmoderated usability testing\", \"qual quant\", \"considering\", \"time\", \"large\", \"field study\", \"competitive\", \"group\", \"work\", \"usability study\", \"insight\", \"card sorts\", \"sorts\", \"focus group\", \"ve\", \"formative\", \"foundational\", \"budget\", \"access\", \"creation\", \"generative\", \"love\", \"team\", \"ethnographic\", \"session\", \"survey\", \"usability\", \"usability testing\", \"field\", \"trying\", \"card\", \"testing\", \"unmoderated\", \"method\", \"design\", \"quant\", \"surveys\", \"interviews\", \"research\", \"diary\", \"study\", \"like\", \"analysis\", \"new\", \"tracking\", \"contextual inquiry\", \"need\", \"type\", \"help\", \"eye\", \"eye tracking\", \"data\", \"inquiry\", \"sure\", \"site\", \"data science\", \"behavioral\", \"lot\", \"qualitative quantitative\", \"data analytics\", \"quant data\", \"currently\", \"plus\", \"people\", \"remote research\", \"data analysis\", \"science\", \"visit\", \"type research\", \"contextual\", \"good\", \"business\", \"na\", \"help inform\", \"analytics\", \"exploratory\", \"better\", \"product\", \"using\", \"market\", \"research\", \"quant\", \"user\", \"analysis\", \"user research\", \"quantitative\", \"method\", \"qualitative\", \"design\", \"remote\"], \"Total\": [42.0, 26.0, 53.0, 24.0, 22.0, 45.0, 15.0, 13.0, 13.0, 36.0, 16.0, 89.0, 30.0, 11.0, 140.0, 39.0, 13.0, 10.0, 10.0, 31.0, 14.0, 32.0, 9.0, 9.0, 21.0, 16.0, 8.0, 21.0, 11.0, 7.0, 22.076423892396736, 9.338278409206131, 11.883429346503023, 8.489199771795455, 9.336207386201988, 7.638636892665049, 5.941542715847265, 5.941578431302484, 16.129020835527008, 5.941281895147416, 5.092359003381656, 5.092390588427879, 5.092396410385985, 5.092093558655048, 5.9395748916138915, 5.092070443599004, 4.2431531899309665, 4.24314952377898, 4.242985712991064, 4.243085066489696, 4.242973253751182, 5.090546453540893, 9.329294119186072, 4.242691354235467, 6.785398728802473, 10.18881172353066, 3.3939469498222445, 3.3939427355989213, 3.3939415488257403, 3.3939403179831538, 30.50860577396928, 36.422298207408915, 45.01767468695142, 13.573559715989136, 140.59007585578365, 39.073822195344995, 89.99027378847366, 27.106090902810685, 34.67273064917226, 8.491338814660443, 53.532757046350405, 28.024248896192145, 33.064131621932134, 37.288356445086, 32.288475643780735, 20.368153114738554, 10.1483991219798, 17.80458460869022, 19.491196425835007, 11.020356295057846, 16.974998068103858, 31.200467416595817, 26.350370037227243, 13.598327425289963, 16.148646976184704, 8.49768343274982, 7.647358590154885, 7.647234261864528, 7.647085032818106, 14.44801871966313, 6.797280413546425, 5.947234381070388, 5.947226795053735, 5.947099331723831, 5.94683299754581, 5.09708704912206, 5.097082799962008, 5.097081646397485, 5.096972145977878, 5.096972497341039, 11.885876734554946, 5.096847989985248, 4.246933780637792, 4.246933626281105, 4.246933626281105, 4.246901097655316, 4.246922652289862, 4.246909810951619, 4.246822773871007, 4.246920136276309, 4.246723739029683, 4.246643306867498, 8.487615284329618, 8.48731071472729, 11.876353248609107, 21.231278713119195, 7.6373648198079165, 21.243836545611725, 53.532757046350405, 32.288475643780735, 15.275622106359117, 9.319766860710846, 15.292829838738708, 89.99027378847366, 28.024248896192145, 37.288356445086, 33.064131621932134, 28.744734430669663, 16.974998068103858, 20.368153114738554, 140.59007585578365, 39.073822195344995, 45.01767468695142, 19.491196425835007, 22.820753160053314, 17.80458460869022, 13.440745160251193, 13.440850269371023, 11.7615841289864, 10.921876294727149, 10.921887164225407, 9.242666819802196, 9.242666820068388, 42.85436979738437, 15.125430100939312, 8.402987490091087, 7.563391064717965, 6.723751706132, 5.884270757834845, 5.884307514377356, 5.044647908290481, 5.045223692334183, 4.204865191944963, 4.204918629965702, 4.2049538568334714, 4.204977119809307, 4.205036272862752, 4.205090877999738, 7.568946514620404, 4.205325386314915, 4.205738276324327, 24.395568650436072, 3.365191620517, 3.3651921555411892, 3.3652158232496068, 3.3652330170610982, 31.200467416595817, 8.421702086196621, 12.645686936737878, 15.17810829243028, 9.272385430747024, 9.272708507278182, 140.59007585578365, 28.744734430669663, 34.67273064917226, 22.820753160053314, 10.124984145533826, 36.422298207408915, 37.288356445086, 27.106090902810685, 33.064131621932134, 30.50860577396928], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9386, 0.9031, 0.8979, 0.8967, 0.8815, 0.873, 0.8664, 0.866, 0.8613, 0.861, 0.8495, 0.8441, 0.8422, 0.8407, 0.831, 0.8305, 0.8243, 0.8243, 0.8203, 0.8202, 0.8201, 0.8123, 0.8079, 0.8077, 0.8013, 0.7904, 0.7854, 0.7851, 0.785, 0.785, 0.7536, 0.6967, 0.6409, 0.6811, 0.4396, 0.573, 0.4702, 0.4124, 0.1992, 0.619, -0.0312, 0.2001, 0.0434, -0.0417, 0.0073, 0.1092, 0.4634, 0.052, -0.0266, 0.3834, -0.0066, -0.6303, 1.0445, 1.0351, 1.0269, 1.0097, 1.0008, 0.9987, 0.9973, 0.9938, 0.9915, 0.9791, 0.979, 0.9759, 0.9679, 0.9621, 0.9618, 0.9613, 0.9602, 0.9602, 0.9383, 0.9374, 0.9371, 0.9371, 0.9371, 0.9363, 0.9352, 0.9349, 0.9346, 0.9334, 0.9325, 0.9291, 0.9034, 0.8998, 0.8585, 0.8026, 0.8798, 0.7622, 0.6081, 0.5822, 0.7035, 0.7193, 0.5786, -0.0172, 0.3644, 0.199, 0.2042, 0.2227, 0.4333, 0.334, -0.7614, -0.0671, -0.2273, 0.1823, 0.0038, 0.2055, 1.2291, 1.2284, 1.2221, 1.2188, 1.2187, 1.2083, 1.2083, 1.2065, 1.2034, 1.2023, 1.1938, 1.1838, 1.1682, 1.1675, 1.1495, 1.1389, 1.1268, 1.1258, 1.1249, 1.1245, 1.1227, 1.1218, 1.121, 1.1158, 1.1073, 1.099, 1.0885, 1.0885, 1.0878, 1.0873, 0.8173, 0.9654, 0.8722, 0.8223, 0.863, 0.8439, -0.1087, 0.4343, 0.3075, 0.468, 0.7097, -0.2135, -0.238, -0.1558, -0.4081, -0.4335], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.0154, -4.9113, -4.6754, -5.0129, -4.9331, -5.1423, -5.4001, -5.4005, -4.4065, -5.4056, -5.5712, -5.5767, -5.5785, -5.5801, -5.4358, -5.5903, -5.7788, -5.7789, -5.7829, -5.7829, -5.7832, -5.6088, -5.0074, -5.7956, -5.3324, -4.9367, -6.0411, -6.0414, -6.0415, -6.0415, -3.8768, -3.7566, -3.6005, -4.7592, -2.663, -3.81, -3.0786, -4.3363, -4.3033, -5.2905, -4.0993, -4.5153, -4.5066, -4.4714, -4.5664, -4.9253, -5.2678, -5.117, -5.1051, -5.2654, -5.2234, -5.2384, -3.7325, -4.4034, -4.2397, -4.899, -5.0133, -5.0155, -5.0169, -4.3841, -5.1405, -5.2864, -5.2865, -5.2897, -5.2977, -5.4577, -5.458, -5.4585, -5.4596, -5.4596, -4.6348, -5.4825, -5.6652, -5.6652, -5.6652, -5.666, -5.667, -5.6674, -5.6677, -5.6689, -5.6698, -5.6732, -5.0065, -5.0101, -4.7154, -4.1904, -5.1357, -4.2302, -3.4601, -3.9916, -4.6187, -5.0971, -4.7425, -3.566, -4.351, -4.2308, -4.3459, -4.4673, -4.7835, -4.7005, -3.864, -4.4501, -4.4687, -4.8962, -4.917, -4.9635, -4.2211, -4.2217, -4.3615, -4.4389, -4.439, -4.6163, -4.6163, -3.0842, -4.1287, -4.7176, -4.8313, -4.959, -5.108, -5.1086, -5.2807, -5.2911, -5.4854, -5.4865, -5.4873, -5.4877, -5.4895, -5.4904, -4.9034, -5.4963, -5.5047, -3.7551, -5.7465, -5.7465, -5.7472, -5.7477, -3.7908, -4.9523, -4.639, -4.5063, -4.9584, -4.9775, -3.2113, -4.2557, -4.1951, -4.4528, -5.0237, -4.6668, -4.6678, -4.9045, -4.9582, -5.064]}, \"token.table\": {\"Topic\": [2, 1, 1, 2, 3, 1, 2, 3, 3, 1, 3, 2, 3, 2, 3, 1, 2, 2, 2, 2, 1, 2, 3, 3, 1, 1, 2, 3, 2, 1, 2, 3, 3, 3, 3, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 3, 1, 2, 3, 1, 3, 1, 3, 3, 3, 1, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 2, 3, 3, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 3, 3, 1, 2, 3, 1, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 2, 1, 2, 3, 3, 1, 2, 3, 3, 1, 3, 1, 1, 3, 3, 1, 1, 1, 2, 3, 1, 1, 3, 1, 2, 2, 2, 3, 3, 1, 2, 1, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 1, 2, 3, 3, 3, 1, 2, 3, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 1, 2, 3, 2, 3], \"Freq\": [0.9419025690882223, 0.8415692249990335, 0.21909881610534535, 0.35055810576855256, 0.4381976322106907, 0.19230481133140154, 0.16025400944283463, 0.6410160377713385, 0.8497229658139969, 0.5912262542970905, 0.3941508361980604, 0.3163133817886411, 0.6326267635772822, 0.941859011153243, 0.89147955342168, 0.3923407285158713, 0.588511092773807, 0.9418560194223389, 0.980974558384746, 0.8407836577996125, 0.08198210210460702, 0.08198210210460702, 0.8608120720983736, 0.967200715688677, 0.9427323754008652, 0.8839280102033463, 0.9419204088865583, 0.9512669214321102, 0.9153636151710198, 0.8839277011167948, 0.046669686416017965, 0.9333937283203593, 0.9512279558397333, 0.7928290684271706, 0.8923589481342767, 0.7855315213525853, 0.3931753039410485, 0.4234195580903599, 0.18146552489586854, 0.6654071329396968, 0.30711098443370616, 0.0692136423272378, 0.8997773502540913, 0.951241020844528, 0.18840127596875864, 0.7536051038750345, 0.04710031899218966, 0.9300006586239792, 0.06200004390826527, 0.06200004390826527, 0.8842516467796308, 0.14737527446327178, 0.23748168476275713, 0.7124450542882713, 0.9737449348187811, 0.9737449347907369, 0.19639134688669238, 0.6546378229556413, 0.13092756459112825, 0.9809534841439904, 0.9559999250954053, 0.9418632334547116, 0.8827059698820854, 0.9427103009530751, 0.9418613010535551, 0.9418806041566866, 0.8247310658535444, 0.11781872369336349, 0.8914796951559939, 0.9809744907606178, 0.9153487334844889, 0.9155926855530019, 0.8914687288489577, 0.9427977823573734, 0.06611382243853671, 0.9255935141395139, 0.9418559851901651, 0.4418662776787322, 0.49096253075414686, 0.09819250615082938, 0.9423738650348676, 0.9809532621359944, 0.35913649665557246, 0.4104417104635114, 0.2052208552317557, 0.849717657988354, 0.8247606615666269, 0.11782295165237526, 0.9426959803286806, 0.323530066500558, 0.647060133001116, 0.37545232170845577, 0.4022703446876312, 0.2145441838334033, 0.5444470069167129, 0.27222350345835644, 0.1814823356389043, 0.9256587201603557, 0.08415079274185051, 0.916393866911216, 0.8914732836074277, 0.9352481671997331, 0.39315716450825694, 0.39315716450825694, 0.16849592764639582, 0.857513965986738, 0.10718924574834225, 0.9639888691098626, 0.7857702579686061, 0.9512536896232618, 0.9512589522236015, 0.1976530897131745, 0.1976530897131745, 0.6588436323772483, 0.06192469260581118, 0.9288703890871677, 0.8407460042458541, 0.5902732362762396, 0.18446038633632486, 0.22135246360358984, 0.7929195600403182, 0.13915592122264087, 0.4174677636679226, 0.4174677636679226, 0.9512790107189614, 0.7687598360914063, 0.21964566745468753, 0.963775077762445, 0.8194409205461181, 0.19666582093106835, 0.951240308154782, 0.9818632183394133, 0.8415322819549904, 0.5903688400107333, 0.1564833069907968, 0.2489507156671767, 0.7855350872115696, 0.13211878272205652, 0.9248314790543956, 0.8839283307676864, 0.9153814780349523, 0.8407269126494551, 0.785611286295854, 0.13093521438264233, 0.9255107847925388, 0.9427351436786996, 0.9418560194223389, 0.8418110877025087, 0.03795013119691379, 0.9487532799228447, 0.710831917075347, 0.2665619689032551, 0.9520423551068836, 0.2353623833089054, 0.7060871499267163, 0.3534610122444752, 0.5301915183667127, 0.11782033741482506, 0.8420093096482412, 0.16840186192964823, 0.6111771604260263, 0.333369360232378, 0.05556156003872967, 0.9818571284304408, 0.8839266035543434, 0.9809524443694202, 0.9672082793776475, 0.7066023545828717, 0.23553411819429057, 0.8415272234156007, 0.7510917498923454, 0.32189646423957663, 0.91559359675478, 0.9510815312777533, 0.4638839759151013, 0.4995673586778014, 0.0356833827627001, 0.9426951658243283, 0.9414330462309571, 0.8407279850431235, 0.37360302557709385, 0.6164449922022048, 0.7847987634435175, 0.3716496291862384, 0.6194160486437307, 0.736726415858353, 0.1473452831716706, 0.0736726415858353, 0.46145774216320534, 0.14420554442600167, 0.37493441550760437, 0.3950623470126042, 0.5925935205189062, 0.21569422614466008, 0.10784711307233004, 0.6470826784339803, 0.8833218479457082, 0.09814687199396759, 0.7854848047261141, 0.9418584531656762, 0.9511749109871281, 0.8413346548452523, 0.08413346548452523], \"Term\": [\"access\", \"ai\", \"analysis\", \"analysis\", \"analysis\", \"analytics\", \"analytics\", \"analytics\", \"behavioral\", \"benchmarking\", \"benchmarking\", \"better\", \"better\", \"budget\", \"business\", \"card\", \"card\", \"card sorts\", \"competitive\", \"considering\", \"contextual\", \"contextual\", \"contextual\", \"contextual inquiry\", \"contextual research\", \"continue\", \"creation\", \"currently\", \"customer\", \"cx\", \"data\", \"data\", \"data analysis\", \"data analytics\", \"data science\", \"deeper\", \"design\", \"design\", \"design\", \"diary\", \"diary\", \"diary studies\", \"diary studies\", \"diary study\", \"ethnographic\", \"ethnographic\", \"ethnographic\", \"ethnography\", \"ethnography\", \"ethnography\", \"experience\", \"experience\", \"exploratory\", \"exploratory\", \"eye\", \"eye tracking\", \"field\", \"field\", \"field\", \"field study\", \"focus\", \"focus group\", \"focus groups\", \"focused\", \"formative\", \"foundational\", \"generative\", \"generative\", \"good\", \"group\", \"groups\", \"help\", \"help inform\", \"incorporate\", \"inquiry\", \"inquiry\", \"insight\", \"interviews\", \"interviews\", \"interviews\", \"lab\", \"large\", \"like\", \"like\", \"like\", \"lot\", \"love\", \"love\", \"making\", \"market\", \"market\", \"method\", \"method\", \"method\", \"methods\", \"methods\", \"methods\", \"mixed\", \"mixed\", \"mixed method\", \"na\", \"need\", \"new\", \"new\", \"new\", \"online\", \"online\", \"participatory\", \"participatory design\", \"people\", \"plus\", \"product\", \"product\", \"product\", \"qual\", \"qual\", \"qual quant\", \"qualitative\", \"qualitative\", \"qualitative\", \"qualitative quantitative\", \"quant\", \"quant\", \"quant\", \"quant data\", \"quantitative\", \"quantitative\", \"quantitative research\", \"remote\", \"remote\", \"remote research\", \"remote testing\", \"remote unmoderated\", \"research\", \"research\", \"research\", \"research design\", \"science\", \"science\", \"screen\", \"service\", \"service design\", \"session\", \"session\", \"site\", \"social\", \"sorts\", \"specific\", \"studies\", \"studies\", \"study\", \"study\", \"sure\", \"survey\", \"survey\", \"surveys\", \"surveys\", \"surveys\", \"team\", \"team\", \"testing\", \"testing\", \"testing\", \"testing diary\", \"testing diary study\", \"time\", \"tracking\", \"tree\", \"tree\", \"tree testing\", \"trying\", \"trying\", \"type\", \"type research\", \"unmoderated\", \"unmoderated\", \"unmoderated\", \"unmoderated testing\", \"unmoderated usability\", \"unmoderated usability testing\", \"usability\", \"usability\", \"usability study\", \"usability testing\", \"usability testing\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user research\", \"user research\", \"using\", \"using\", \"using\", \"ux\", \"ux\", \"ux research\", \"ve\", \"visit\", \"work\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el263901124270655363214253139\", ldavis_el263901124270655363214253139_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el263901124270655363214253139\", ldavis_el263901124270655363214253139_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el263901124270655363214253139\", ldavis_el263901124270655363214253139_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.052133 -0.130006       1        1  38.021747\n",
       "0     -0.117288  0.100462       2        1  33.977685\n",
       "2      0.169421  0.029544       3        1  28.000568, topic_info=    Category       Freq          Term      Total  loglift  logprob\n",
       "78   Default  42.000000          data  42.000000  30.0000  30.0000\n",
       "450  Default  26.000000       studies  26.000000  29.0000  29.0000\n",
       "522  Default  53.000000     usability  53.000000  28.0000  28.0000\n",
       "61   Default  24.000000    contextual  24.000000  27.0000  27.0000\n",
       "98   Default  22.000000   diary study  22.000000  26.0000  26.0000\n",
       "..       ...        ...           ...        ...      ...      ...\n",
       "355   Topic3   8.237788  quantitative  36.422298  -0.2135  -4.6668\n",
       "262   Topic3   8.229515        method  37.288356  -0.2380  -4.6678\n",
       "342   Topic3   6.494803   qualitative  27.106091  -0.1558  -4.9045\n",
       "88    Topic3   6.155583        design  33.064132  -0.4081  -4.9582\n",
       "370   Topic3   5.537491        remote  30.508606  -0.4335  -5.0640\n",
       "\n",
       "[182 rows x 6 columns], token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "0         2  0.941903       access\n",
       "6         1  0.841569           ai\n",
       "7         1  0.219099     analysis\n",
       "7         2  0.350558     analysis\n",
       "7         3  0.438198     analysis\n",
       "...     ...       ...          ...\n",
       "550       1  0.785485  ux research\n",
       "552       2  0.941858           ve\n",
       "553       3  0.951175        visit\n",
       "561       2  0.841335         work\n",
       "561       3  0.084133         work\n",
       "\n",
       "[203 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(LDA, word_count_matrix, count_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04865894, 0.48496094, 0.46638011],\n",
       "       [0.33333333, 0.33333333, 0.33333333],\n",
       "       [0.16682112, 0.66314436, 0.17003452],\n",
       "       ...,\n",
       "       [0.08755814, 0.82907687, 0.083365  ],\n",
       "       [0.51182215, 0.45753248, 0.03064537],\n",
       "       [0.02645341, 0.58808696, 0.38545963]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.transform(word_count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Documents for Topic 0: \n",
      "\n",
      "Document 1\n",
      "I'd love to just flat-out assemble a customer \"council\" database so that we can engage in more frequent and lighter-weight customer research sessions, a I've done at previous jobs, but there are major cultural hurdle - managing sales/channel partner relationship and mistrust, etc. This is still my major goal that I don't want to fully give up on, though.\n",
      "\n",
      "Document 2\n",
      "More contextual/observational studies, unmoderated studies, more co-design workshops, generally looking for opportunity to be more lean, quick, and agile with the process (leveraging existing insight from past research is a large part of that effort for us)\n",
      "\n",
      "Document 3\n",
      "more service design, design thinking learning proper SPSS quant method to complement qual method going to try out Delve for grounded theory analysis\n",
      "\n",
      "Top 3 Documents for Topic 1: \n",
      "\n",
      "Document 1\n",
      "User Experience Research (workshops, surveys, interviews, usability testing, benchmark, card sorting, etc.) and I would like to delve deeper in Analytics.\n",
      "\n",
      "Document 2\n",
      "Diaty study Surveys Ethnographic Research User research Usability testing Surveys Tree Testing Card sort\n",
      "\n",
      "Document 3\n",
      "A/B/n & Multivariate Testing Analytic Research Behavioural Research Card Sorting/Tree Testing Content Auditing Experience Mapping Information Architecture (IA) Lab (Testing & Build) Persona Development Research Participant Recruitment & Management Scenario/Task Mapping Survey Design & Analysis Usability Testing User/Stakeholder Interviews Workshops\n",
      "\n",
      "Top 3 Documents for Topic 2: \n",
      "\n",
      "Document 1\n",
      "I'd love to grow our user research to a better understanding of people's journey across our many tool and channel (we have persona and lot of quant stuff, but very little around journeys, reason people attend, drop out, etc.).\n",
      "\n",
      "Document 2\n",
      "Now we are opening research to our \"builders\" and reviewing quantitative collector such a Pendo and defining standardised KEIs. So we expect to have continuous product validation research run by product people apart from some core research drill that we are going to keep running. Also, we are thinking about including a librarian role that could help u to maintain the learning in a scalable repository that we could feed and share a easily a possible.\n",
      "\n",
      "Document 3\n",
      "Doing more strategic piece to help inform the product strategy early on before the okrs are set. Have fundamental understanding our user in different market since we have a global product and we havenâ€™t done a lot of thinking around localized content and market differences. Doing information architecture research.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp.find_top_documents_per_topic(LDA.transform(word_count_matrix), future_research, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'studies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'workshop'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word(word)\n",
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in text.split()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
