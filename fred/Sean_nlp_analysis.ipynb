{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "- All 11 qualitative questions analyzed for key topics\n",
    "- Number of topics varied within the recommended range of 2 - 5 based on unique key words for each group. This was a subjective process that had to be completed by adjusting the number of components, examing the key words, looking at the intertopic distance in the visualizations and reading the most relevant responses to each topic.\n",
    "- Non-cleaned text of must prominent topcs was included to make reading easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "import nlp\n",
    "import wrangle\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "datadf, dictionarydf = wrangle.wrangle_data(path_prefix='../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datadf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datadf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of qualitative questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What is your company or organization's primary industry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and lemmatize the data for this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.primary_industry = datadf.primary_industry.dropna().apply(nlp.basic_clean)\n",
    "datadf.primary_industry = datadf.primary_industry.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word count matrix and vector. Settings: 2 word ngrams permitted; words in more than 30% of documents were ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_industry_matrix, primary_industry_vector = nlp.create_wordcount_matrix(datadf.primary_industry.dropna(), ngram=(1,3), max_df=.3)\n",
    "primary_industry_matrix, primary_industry_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply LDA method using 4, 6 and 8 components (can be changed) and a random state set to ensure the results can be replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda5 = LatentDirichletAllocation(n_components= 8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda5.fit(primary_industry_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda5, primary_industry_matrix, primary_industry_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. education \n",
    "2. fintech \n",
    "3. healthcare \n",
    "4. Tech \n",
    "\n",
    "#### Topic groups (6) \n",
    "1. fintech\n",
    "2. education\n",
    "3. healthcare\n",
    "4. technology\n",
    "5. software\n",
    "6. consultancy\n",
    "\n",
    "#### Topic groups (8) - 5 & 8 slight overlap - go with this one\n",
    "1. fintech\n",
    "2. education\n",
    "3. technology\n",
    "4. consulting\n",
    "5. software\n",
    "6. healthcare\n",
    "7. government\n",
    "8. telecom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W5 = lda5.transform(primary_industry_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column5 = datadf.primary_industry.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create second word count matrix. Excludes words in appear in 80%+ of all documents and in 2 or fewer documents. Include bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix5, count_vect5 = nlp.create_wordcount_matrix(datadf.primary_industry, max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA5a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA5a.fit(word_count_matrix5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA5a.transform(word_count_matrix5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What types of research do you currently use to make decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_res_used = datadf.types_res_used.fillna('nan')\n",
    "types_res_used = types_res_used.apply(nlp.basic_clean)\n",
    "types_res_used = types_res_used.apply(nlp.lemmatize)\n",
    "\n",
    "types_res_used_matrix, types_res_used_vector = nlp.create_wordcount_matrix(types_res_used, ngram=(1,3), max_df=.3)\n",
    "types_res_used_matrix, types_res_used_vector\n",
    "\n",
    "lda6 = LatentDirichletAllocation(n_components= 8, random_state = 42)\n",
    "\n",
    "lda6.fit(types_res_used_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda6, types_res_used_matrix, types_res_used_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. card sort\n",
    "2. contextual inquiry\n",
    "3. focus group \n",
    "4. market rsearch\n",
    "\n",
    "#### Topic groups (6) \n",
    "1. diary study\n",
    "2. card (sort)\n",
    "3. contextual inquiry\n",
    "4. quantitative survey\n",
    "5. focus (group)\n",
    "6. generative (evaluative)\n",
    "\n",
    "#### Topic groups (8) - 8 overlaps with 2 & 6 - use this one\n",
    "1. diary (study)\n",
    "2. contextual inquiry\n",
    "3. interview usability\n",
    "4. gernative evaluative\n",
    "5. market (research)\n",
    "6. ux research\n",
    "7. indepth (interview)\n",
    "8. concept validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W6 = lda6.transform(types_res_used_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column6 = datadf.types_res_used.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix6, count_vect6 = nlp.create_wordcount_matrix(datadf.types_res_used.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA6a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA6a.fit(word_count_matrix6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA6a.transform(word_count_matrix6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What types of research are you considering in the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.future_res = datadf.future_res.dropna().apply(nlp.basic_clean)\n",
    "datadf.future_res = datadf.future_res.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_res_matrix, future_res_vector = nlp.create_wordcount_matrix(datadf.future_res.dropna(), ngram=(1,3), max_df=.3)\n",
    "future_res_matrix, future_res_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda7 = LatentDirichletAllocation(n_components=8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda7.fit(future_res_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda7, future_res_matrix, future_res_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. ab testing\n",
    "2. quantitative\n",
    "3. diary study\n",
    "4. participatory\n",
    "\n",
    "#### Topic groups (6) - 4 & 6 overlap\n",
    "1. quantitative\n",
    "2. usability testing\n",
    "3. field\n",
    "4. analytics\n",
    "5. diary study\n",
    "6. journey\n",
    "\n",
    "#### Topic groups (8) - 5 is almost completely within 2; 6 & 8 overlap - go with this one\n",
    "1. quantitative\n",
    "2. unmoderated usability\n",
    "3. diary study\n",
    "4. ab testing\n",
    "5. ux\n",
    "6. focus group\n",
    "7. ethnographic\n",
    "8. field study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W7 = lda7.transform(future_res_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column7 = datadf.future_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix7, count_vect7 = nlp.create_wordcount_matrix(datadf.future_res.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA7a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA7a.fit(word_count_matrix7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA7a.transform(word_count_matrix7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column7, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Describe your educational background with research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.research_educ_desc = datadf.research_educ_desc.dropna().apply(nlp.basic_clean)\n",
    "datadf.research_educ_desc = datadf.research_educ_desc.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_educ_desc_matrix, research_educ_desc_vector = nlp.create_wordcount_matrix(datadf.research_educ_desc.dropna(), ngram=(1,3), max_df=.3)\n",
    "research_educ_desc_matrix, research_educ_desc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda10 = LatentDirichletAllocation(n_components= 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda10.fit(research_educ_desc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda10, research_educ_desc_matrix, research_educ_desc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - no overlapping circles  - use this one\n",
    "1. ethnographic\n",
    "2. grad school\n",
    "3. master degree\n",
    "4. pyschology\n",
    "\n",
    "#### Topic groups (6) - 1 &4, 2 & 3 overlap - use this one\n",
    "1. running study\n",
    "2. design research\n",
    "3. social science\n",
    "4. grad school\n",
    "5. human factor\n",
    "6. master degree\n",
    "\n",
    "#### Topic groups (8) - extreme overlap between topics 1, 2, 4 & 8, 54% of all the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W10 = lda10.transform(research_educ_desc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column10 = datadf.research_educ_desc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix10, count_vect10 = nlp.create_wordcount_matrix(datadf.research_educ_desc.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA10a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA10a.fit(word_count_matrix10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA10a.transform(word_count_matrix10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. How do you decide which events to attend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.how_pick_events = datadf.how_pick_events.dropna().apply(nlp.basic_clean)\n",
    "datadf.how_pick_events = datadf.how_pick_events.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_pick_events_matrix, how_pick_events_vector = nlp.create_wordcount_matrix(datadf.how_pick_events.dropna(), ngram=(1,3), max_df=.3)\n",
    "how_pick_events_matrix, how_pick_events_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda14 = LatentDirichletAllocation(n_components= 8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda14.fit(how_pick_events_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda14, how_pick_events_matrix, how_pick_events_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) \n",
    "1. pay\n",
    "2. topic\n",
    "3. location\n",
    "4. cost\n",
    "\n",
    "#### Topic groups (6) - overlap between 3 & 6 - use this one\n",
    "1. pay\n",
    "2. value\n",
    "3. price\n",
    "4. reputation\n",
    "5. networking\n",
    "6. relevance\n",
    "\n",
    "#### Topic groups (8) - small amount of overlap among 2, 3, 4, & 6\n",
    "1. design\n",
    "2. affordable\n",
    "3. speaker topic\n",
    "4. reputation\n",
    "5. location cost\n",
    "6. value\n",
    "7. location price\n",
    "8. time away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W14 = lda14.transform(how_pick_events_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column14 = datadf.how_pick_events.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix14, count_vect14 = nlp.create_wordcount_matrix(datadf.how_pick_events.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA14a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA14a.fit(word_count_matrix14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA14a.transform(word_count_matrix14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column14, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. What was the best professional learning experience you've ever had?  What made it great?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.best_event = datadf.best_event.dropna().apply(nlp.basic_clean)\n",
    "datadf.best_event = datadf.best_event.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_event_matrix, best_event_vector = nlp.create_wordcount_matrix(datadf.best_event.dropna(), ngram=(1,3), max_df=.3)\n",
    "best_event_matrix, best_event_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda15 = LatentDirichletAllocation(n_components= 5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda15.fit(best_event_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda15, best_event_matrix, best_event_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD\n",
    "#### Topic groups (4) - 3 is almost entirely enclosed by 2\n",
    "1. research\n",
    "2. networking\n",
    "3. day\n",
    "4. variety\n",
    "\n",
    "#### Topic groups (6) - 2 intersects with 1 & 4\n",
    "1. think\n",
    "2. practical\n",
    "3. learn\n",
    "4. design\n",
    "5. variety\n",
    "6. intimate\n",
    "\n",
    "#### Topic groups (8) - overlap between 1 & 2 and 3 & 4\n",
    "1. strive\n",
    "2. world\n",
    "3. concept\n",
    "4. uxpa\n",
    "5. immediately\n",
    "6. sxsw\n",
    "7. relevant\n",
    "8. start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W15 = lda15.transform(best_event_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column15 = datadf.best_event.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix15, count_vect15 = nlp.create_wordcount_matrix(datadf.best_event.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA15a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA15a.fit(word_count_matrix15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA15a.transform(word_count_matrix15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column15, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. What if any events have you attended on the subject of research in the past few years? Fix stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['nan', 'Nan', 'NaN', 'NAN', 'dont', 'research', 'conference', 'make', 'researcher', 'people', 'like', 'event']\n",
    "\n",
    "words_to_stop = nlp.set_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent = datadf.events_attend_recent.fillna('nan')\n",
    "events_attend_recent = events_attend_recent.astype('str')\n",
    "events_attend_recent = events_attend_recent.apply(nlp.basic_clean)\n",
    "events_attend_recent = events_attend_recent.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent_matrix, events_attend_recent_vector = nlp.create_wordcount_matrix(datadf.events_attend_recent, ngram=(1,3), max_df=.3)\n",
    "events_attend_recent_matrix, events_attend_recent_vector\n",
    "\n",
    "# ideal_att_matrix, ideal_att_vector = nlp.create_wordcount_matrix(ideal_attendees, ngram=(1,3), max_df=.3, stop_words=words_to_stop)\n",
    "# ideal_att_matrix, ideal_att_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda16 = LatentDirichletAllocation(n_components= 7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda16.fit(events_attend_recent_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda16, events_attend_recent_matrix, events_attend_recent_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check on groups after code is fixed\n",
    "\n",
    "\n",
    "#### Topic groups (4)\n",
    "1. day\n",
    "2. london\n",
    "3. epic\n",
    "4. uxpa\n",
    "\n",
    "#### Topic groups (6)\n",
    "1. london\n",
    "2. summit\n",
    "3. session\n",
    "4. design research\n",
    "5. epic\n",
    "6. uxr\n",
    "\n",
    "#### Topic groups (7) - use this one\n",
    "1. user research\n",
    "2. ia\n",
    "3. local meetups\n",
    "4. service design day\n",
    "5. epic\n",
    "6. design research\n",
    "7. uxr\n",
    "\n",
    "\n",
    "#### Topic groups (8)\n",
    "Heavy overlap among 6 of the 8 topics\n",
    "1. local meetups\n",
    "2. qrca\n",
    "3. design research\n",
    "4. uxpa\n",
    "5. attended\n",
    "6. epic\n",
    "7. user research\n",
    "8. focused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W16 = lda16.transform(events_attend_recent_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column16 = datadf.events_attend_recent.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix16, count_vect16 = nlp.create_wordcount_matrix(datadf.events_attend_recent.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA16a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA16a.fit(word_count_matrix16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA16a.transform(word_count_matrix16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column16, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Did we miss any other types of conference sessions that you'd like to mention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.other_conference_types = datadf.other_conference_types.dropna().apply(nlp.basic_clean)\n",
    "datadf.other_conference_types = datadf.other_conference_types.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_conference_types_matrix, other_conference_types_vector = nlp.create_wordcount_matrix(datadf.other_conference_types.dropna(), ngram=(1,3), max_df=.3)\n",
    "other_conference_types_matrix, other_conference_types_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda20 = LatentDirichletAllocation(n_components= 7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda20.fit(other_conference_types_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda20, other_conference_types_matrix, other_conference_types_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - use this one\n",
    "1. case study\n",
    "2. talk\n",
    "3. poster session\n",
    "4. nope\n",
    "\n",
    "#### Topic groups (6)\n",
    "1. reatreat\n",
    "2. working\n",
    "3. quality\n",
    "4. case study\n",
    "5. panel discussion\n",
    "6. tutorial\n",
    "\n",
    "#### Topic groups (7) - use this one\n",
    "1. industry\n",
    "2. practical\n",
    "3. case study\n",
    "4. poster\n",
    "5. nope\n",
    "6. networking\n",
    "7. panel discussion\n",
    "\n",
    "#### Topic groups (8) - 3 is completely inside 1; 4 and 5 share about 75% of the same area\n",
    "1. working\n",
    "2. case study\n",
    "3. nice\n",
    "4. outside\n",
    "5. variety\n",
    "6. multitrack\n",
    "7. panel\n",
    "8. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W20 = lda20.transform(other_conference_types_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column20 = datadf.other_conference_types.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix20, count_vect20 = nlp.create_wordcount_matrix(datadf.other_conference_types.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA20a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA20a.fit(word_count_matrix20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA20a.transform(word_count_matrix20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column20, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Subjects you most want to see covered at a research conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.ideal_topics = datadf.ideal_topics.dropna().apply(nlp.basic_clean)\n",
    "datadf.ideal_topics = datadf.ideal_topics.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_topics_matrix, ideal_topics_vector = nlp.create_wordcount_matrix(datadf.ideal_topics.dropna(), ngram=(1,3), max_df=.3)\n",
    "ideal_topics_matrix, ideal_topics_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda21 = LatentDirichletAllocation(n_components= 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda21.fit(ideal_topics_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda21, ideal_topics_matrix, ideal_topics_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - considerable overlap between 2 & 3 - use this one\n",
    "1. case study\n",
    "2. finding/data\n",
    "3. ops/ai\n",
    "4. new method\n",
    "\n",
    "#### Topic groups (6)\n",
    "1. case study\n",
    "2. ops\n",
    "3. stakeholder\n",
    "4. new method\n",
    "5. user research\n",
    "6. quantitative\n",
    "\n",
    "#### Topic groups (8)\n",
    "1. case study\n",
    "2. ops\n",
    "3. user research\n",
    "4. working\n",
    "5. quant\n",
    "6. mixed method\n",
    "7. ethic\n",
    "8. qualitative data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W21 = lda21.transform(ideal_topics_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column21 = datadf.ideal_topics.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix21, count_vect21 = nlp.create_wordcount_matrix(datadf.ideal_topics.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA21a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA21a.fit(word_count_matrix21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA21a.transform(word_count_matrix21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column21, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. If attending a conference about research, who might you be excited to see there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.ideal_attendees = datadf.ideal_attendees.dropna().apply(nlp.basic_clean)\n",
    "datadf.ideal_attendees = datadf.ideal_attendees.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_att_matrix, ideal_att_vector = nlp.create_wordcount_matrix(datadf.ideal_attendees.dropna(), ngram=(1,3), max_df=.3)\n",
    "ideal_att_matrix, ideal_att_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda22 = LatentDirichletAllocation(n_components= 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda22.fit(ideal_att_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda22, ideal_att_matrix, ideal_att_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - use this one\n",
    "1. industry\n",
    "2. field\n",
    "3. erika hall\n",
    "4. Indi young\n",
    "\n",
    "#### Topic groups (6) - some overlap between 2, 3, & 4; 5 is mostly overlapped with 2 & 4\n",
    "1. steve portigal\n",
    "2. expert\n",
    "3. diverse\n",
    "4. new\n",
    "5. startup\n",
    "6. doing research\n",
    "\n",
    "#### Topic groups (8)\n",
    "1. google\n",
    "2. jared spool\n",
    "3. different\n",
    "4. new\n",
    "5. consultant\n",
    "6. erika hall\n",
    "7. practioner\n",
    "8. steve portigal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W22 = lda22.transform(ideal_att_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_doc_column22 = datadf.ideal_attendees.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix22, count_vect22 = nlp.create_wordcount_matrix(datadf.ideal_attendees.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA22a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA22a.fit(word_count_matrix22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA22a.transform(word_count_matrix22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column22, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.recommendations = datadf.recommendations.dropna().apply(nlp.basic_clean)\n",
    "datadf.recommendations = datadf.recommendations.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_matrix, recommendations_vector = nlp.create_wordcount_matrix(datadf.recommendations.dropna(), ngram=(1,3), max_df=.3)\n",
    "recommendations_matrix, recommendations_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda23 = LatentDirichletAllocation(n_components= 8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda23.fit(recommendations_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda23, recommendations_matrix, recommendations_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - use this one\n",
    "1. pratical\n",
    "2. affordable\n",
    "3. expensive\n",
    "4. miscellaneous\n",
    "\n",
    "#### Topic groups (6) - some overlap between 2, 3, & 4; 5 is mostly overlapped with 2 & 4\n",
    "1. ux\n",
    "2. interesting\n",
    "3. content\n",
    "4. food\n",
    "5. learning\n",
    "6. affordalbe\n",
    "\n",
    "#### Topic groups (8) - significant overlap amoung 6 of the 8 groups\n",
    "1. events\n",
    "2. ux\n",
    "3. world\n",
    "4. new\n",
    "5. food\n",
    "6. diverse\n",
    "7. make accessible\n",
    "8. north america"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W23 = lda23.transform(recommendations_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column23 = datadf.recommendations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix23, count_vect23 = nlp.create_wordcount_matrix(datadf.recommendations.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA23a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA23a.fit(word_count_matrix23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda23.fit(recommendations_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA23a.transform(word_count_matrix23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column23, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
