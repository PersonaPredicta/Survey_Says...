{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description\n",
    "- All 11 qualitative questions analyzed for key topics\n",
    "- Number of topics varied within the recommended range of 2 - 5 based on unique key words for each group. This was a subjective process that had to be completed by adjusting the number of components, examing the key words, looking at the intertopic distance in the visualizations and reading the most relevant responses to each topic.\n",
    "- Non-cleaned text of must prominent topcs was included to make reading easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "import nlp\n",
    "import wrangle\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "datadf, dictionarydf = wrangle.wrangle_data(path_prefix='../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datadf.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datadf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of qualitative questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What is your company or organization's primary industry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and lemmatize the data for this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.primary_industry = datadf.primary_industry.dropna().apply(nlp.basic_clean)\n",
    "datadf.primary_industry = datadf.primary_industry.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create word count matrix and vector. Settings: 2 word ngrams permitted; words in more than 30% of documents were ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_industry_matrix, primary_industry_vector = nlp.create_wordcount_matrix(datadf.primary_industry.dropna(), ngram=(1,3), max_df=.3)\n",
    "primary_industry_matrix, primary_industry_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply LDA method using 4, 6 and 8 components (can be changed) and a random state set to ensure the results can be replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda5 = LatentDirichletAllocation(n_components= 8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda5.fit(primary_industry_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda5, primary_industry_matrix, primary_industry_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. education \n",
    "2. fintech \n",
    "3. healthcare \n",
    "4. Tech \n",
    "\n",
    "#### Topic groups (6) \n",
    "1. fintech\n",
    "2. education\n",
    "3. healthcare\n",
    "4. technology\n",
    "5. software\n",
    "6. consultancy\n",
    "\n",
    "#### Topic groups (8) - 5 & 8 slight overlap\n",
    "1. fintech\n",
    "2. education\n",
    "3. technology\n",
    "4. consulting\n",
    "5. software\n",
    "6. healthcare\n",
    "7. government\n",
    "8. public (sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W5 = lda5.transform(primary_industry_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column5 = datadf.primary_industry.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create second word count matrix. Excludes words in appear in 80%+ of all documents and in 2 or fewer documents. Include bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix5, count_vect5 = nlp.create_wordcount_matrix(datadf.primary_industry, max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA5a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA5a.fit(word_count_matrix5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA5a.transform(word_count_matrix5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. What types of research do you currently use to make decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.types_res_used = datadf.types_res_used.dropna().apply(nlp.basic_clean)\n",
    "datadf.types_res_used = datadf.types_res_used.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_res_used_matrix, types_res_used_vector = nlp.create_wordcount_matrix(datadf.types_res_used.dropna(), ngram=(1,3), max_df=.3)\n",
    "types_res_used_matrix, types_res_used_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda6 = LatentDirichletAllocation(n_components= 8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda6.fit(types_res_used_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda6, types_res_used_matrix, types_res_used_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. card sort\n",
    "2. contextual inquiry\n",
    "3. focus group \n",
    "4. market rsearch\n",
    "\n",
    "#### Topic groups (6) \n",
    "1. diary study\n",
    "2. card (sort)\n",
    "3. contextual inquiry\n",
    "4. quantitative survey\n",
    "5. focus (group)\n",
    "6. generative (evaluative)\n",
    "\n",
    "#### Topic groups (8) - 8 overlaps with 2 & 6\n",
    "1. diary (study)\n",
    "2. contextual inquiry\n",
    "3. interview usability\n",
    "4. gernative evaluative\n",
    "5. market (research)\n",
    "6. ux research\n",
    "7. indepth (interview)\n",
    "8. concept validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W6 = lda6.transform(types_res_used_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column6 = datadf.types_res_used.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix6, count_vect6 = nlp.create_wordcount_matrix(datadf.types_res_used.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA6a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA6a.fit(word_count_matrix6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA6a.transform(word_count_matrix6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What types of research are you considering in the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.future_res = datadf.future_res.dropna().apply(nlp.basic_clean)\n",
    "datadf.future_res = datadf.future_res.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_res_matrix, future_res_vector = nlp.create_wordcount_matrix(datadf.future_res.dropna(), ngram=(1,3), max_df=.3)\n",
    "future_res_matrix, future_res_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda7 = LatentDirichletAllocation(n_components=7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda7.fit(future_res_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda7, future_res_matrix, future_res_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. ab testing\n",
    "2. quantitative\n",
    "3. diary study\n",
    "4. participatory\n",
    "\n",
    "#### Topic groups (6) - 4 & 6 overlap\n",
    "1. quantitative\n",
    "2. usability testing\n",
    "3. field\n",
    "4. analytics\n",
    "5. diary study\n",
    "6. journey\n",
    "\n",
    "#### Topic groups (8) - 5 is almost completely within 2; 6 & 8 overlap\n",
    "1. quantitative\n",
    "2. unmoderated usability\n",
    "3. diary study\n",
    "4. ab testing\n",
    "5. ux\n",
    "6. focus group\n",
    "7. ethnographic\n",
    "8. field study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W7 = lda7.transform(future_res_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column7 = datadf.future_res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix7, count_vect7 = nlp.create_wordcount_matrix(datadf.future_res.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA7a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA7a.fit(word_count_matrix7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA7a.transform(word_count_matrix7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column7, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Describe your educational background with research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.research_educ_desc = datadf.research_educ_desc.dropna().apply(nlp.basic_clean)\n",
    "datadf.research_educ_desc = datadf.research_educ_desc.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_educ_desc_matrix, research_educ_desc_vector = nlp.create_wordcount_matrix(datadf.research_educ_desc.dropna(), ngram=(1,3), max_df=.3)\n",
    "research_educ_desc_matrix, research_educ_desc_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda10 = LatentDirichletAllocation(n_components= 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda10.fit(research_educ_desc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda10, research_educ_desc_matrix, research_educ_desc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - no overlapping circles\n",
    "1. participated\n",
    "2. grad school\n",
    "3. master degree\n",
    "4. pyschology\n",
    "\n",
    "#### Topic groups (6) - 1 &4, 2 & 3 overlap\n",
    "1. participated\n",
    "2. design research\n",
    "3. social science\n",
    "4. grad school\n",
    "5. human factor\n",
    "6. master degree\n",
    "\n",
    "#### Topic groups (8) - extreme overlap between topics 1, 2, 4 & 8, 54% of all the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W10 = lda10.transform(research_educ_desc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column10 = datadf.research_educ_desc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix10, count_vect10 = nlp.create_wordcount_matrix(datadf.research_educ_desc.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA10a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA10a.fit(word_count_matrix10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA10a.transform(word_count_matrix10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. How do you decide which events to attend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.how_pick_events = datadf.how_pick_events.dropna().apply(nlp.basic_clean)\n",
    "datadf.how_pick_events = datadf.how_pick_events.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_pick_events_matrix, how_pick_events_vector = nlp.create_wordcount_matrix(datadf.how_pick_events.dropna(), ngram=(1,3), max_df=.3)\n",
    "how_pick_events_matrix, how_pick_events_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda14 = LatentDirichletAllocation(n_components= 6, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda14.fit(how_pick_events_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda14, how_pick_events_matrix, how_pick_events_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. pay\n",
    "2. topic\n",
    "3. location\n",
    "4. cost\n",
    "\n",
    "#### Topic groups (6) - overlap between 3 & 6\n",
    "1. pay\n",
    "2. value\n",
    "3. price\n",
    "4. reputation\n",
    "5. networking\n",
    "6. relevance\n",
    "\n",
    "#### Topic groups (8) - small amount of overlap among 2, 3, 4, & 6\n",
    "1. design\n",
    "2. affordable\n",
    "3. speaker topic\n",
    "4. reputation\n",
    "5. location cost\n",
    "6. value\n",
    "7. location price\n",
    "8. time away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W14 = lda14.transform(how_pick_events_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column14 = datadf.how_pick_events.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix14, count_vect14 = nlp.create_wordcount_matrix(datadf.how_pick_events.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA14a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA14a.fit(word_count_matrix14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA14a.transform(word_count_matrix14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column14, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. What was the best professional learning experience you've ever had?  What made it great?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf.best_event = datadf.best_event.dropna().apply(nlp.basic_clean)\n",
    "datadf.best_event = datadf.best_event.dropna().apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_event_matrix, best_event_vector = nlp.create_wordcount_matrix(datadf.best_event.dropna(), ngram=(1,3), max_df=.3)\n",
    "best_event_matrix, best_event_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda15 = LatentDirichletAllocation(n_components= 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda15.fit(best_event_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda15, best_event_matrix, best_event_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - 3 is almost entirely enclosed by 2\n",
    "1. research\n",
    "2. networking\n",
    "3. day\n",
    "4. variety\n",
    "\n",
    "#### Topic groups (6) - 2 intersects with 1 & 4\n",
    "1. think\n",
    "2. practical\n",
    "3. learn\n",
    "4. design\n",
    "5. variety\n",
    "6. intimate\n",
    "\n",
    "#### Topic groups (8) - overlap between 1 & 2 and 3 & 4\n",
    "1. strive\n",
    "2. world\n",
    "3. concept\n",
    "4. uxpa\n",
    "5. immediately\n",
    "6. sxsw\n",
    "7. relevant\n",
    "8. start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Be Decided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W15 = lda15.transform(best_event_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column15 = datadf.best_event.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix15, count_vect15 = nlp.create_wordcount_matrix(datadf.best_event.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA15a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA15a.fit(word_count_matrix15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA15a.transform(word_count_matrix15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column15, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. What if any events have you attended on the subject of research in the past few years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['nan', 'Nan', 'NaN', 'NAN']\n",
    "\n",
    "stopWords = nlp.set_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_wordcount_matrix(input_column, max_df=0.8, min_df=2, ngram=(1,1), stop_words='english'):\n",
    "    \"\"\"\n",
    "    Creates a feature matrix. Matrix is as wide as the terms that meet the min/max parameters. Each document/row\n",
    "    will have a wordcount for each term.\n",
    "    Can find ngrams, but has default set to 1-word ngrams. Set ngrams to (1,n) to look for ngrams.\n",
    "    \"\"\"\n",
    "    count_vect = CountVectorizer(max_df=max_df, min_df=min_df, stop_words='english', ngram_range=ngram)\n",
    "    doc_term_matrix = count_vect.fit_transform(input_column.values.astype('U'))\n",
    "    return doc_term_matrix, count_vect\n",
    "\n",
    "word_count_matrix10, count_vect10 = create_wordcount_matrix(datadf.research_educ_desc.dropna(), max_df=0.8, min_df=2, ngram=(1,3), stop_words=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent = datadf.events_attend_recent.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent = events_attend_recent.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent = events_attend_recent.apply(nlp.basic_clean)\n",
    "events_attend_recent = events_attend_recent.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_attend_recent_matrix, events_attend_recent_vector = create_wordcount_matrix(events_attend_recent, ngram=(1,3), max_df=.3, stop_words=stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events_attend_recent_matrix, events_attend_recent_vector = nlp.create_wordcount_matrix(datadf.events_attend_recent.dropna(), ngram=(1,3), max_df=.3)\n",
    "# events_attend_recent_matrix, events_attend_recent_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda16 = LatentDirichletAllocation(n_components= 7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda16.fit(events_attend_recent_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda16, events_attend_recent_matrix, events_attend_recent_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic groups (4)\n",
    "\n",
    "1. day\n",
    "2. london\n",
    "3. epic\n",
    "4. uxpa\n",
    "\n",
    "#### Topic groups (6)\n",
    "1. london\n",
    "2. summit\n",
    "3. session\n",
    "4. design research\n",
    "5. epic\n",
    "6. uxr\n",
    "\n",
    "#### Topic groups (8)\n",
    "Heavy overlap among 6 of the 8 topics\n",
    "1. local meetups\n",
    "2. qrca\n",
    "3. design research\n",
    "4. uxpa\n",
    "5. attended\n",
    "6. epic\n",
    "7. user research\n",
    "8. focused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W16 = lda16.transform(events_attend_recent_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column16 = datadf.events_attend_recent.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix16, count_vect16 = nlp.create_wordcount_matrix(datadf.events_attend_recent.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA16a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA16a.fit(word_count_matrix16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA16a.transform(word_count_matrix16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column16, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Did we miss any other types of conference sessions that you'd like to mention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_conference_types = datadf.other_conference_types.fillna('nan').apply(nlp.basic_clean)\n",
    "other_conference_types = other_conference_types.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_conference_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_conference_types_matrix, other_conference_types_vector = nlp.create_wordcount_matrix(other_conference_types, ngram=(1,3), max_df=.3)\n",
    "other_conference_types_matrix, other_conference_types_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda20 = LatentDirichletAllocation(n_components= 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda20.fit(other_conference_types_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda20, other_conference_types_matrix, other_conference_types_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. case study\n",
    "2. talk\n",
    "3. poster session\n",
    "4. nope\n",
    "\n",
    "#### Topic groups (6)\n",
    "1. reatreat\n",
    "2. working\n",
    "3. quality\n",
    "4. case study\n",
    "5. panel discussion\n",
    "6. tutorial\n",
    "\n",
    "#### Topic groups (8) - 3 is completely inside 1; 4 and 5 share about 75% of the same area\n",
    "1. working\n",
    "2. case study\n",
    "3. nice\n",
    "4. outside\n",
    "5. variety\n",
    "6. multitrack\n",
    "7. panel\n",
    "8. method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W20 = lda20.transform(other_conference_types_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column20 = datadf.other_conference_types.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix20, count_vect20 = nlp.create_wordcount_matrix(datadf.other_conference_types.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA20a = LatentDirichletAllocation(n_components=6, random_state=42)\n",
    "LDA20a.fit(word_count_matrix20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA20a.transform(word_count_matrix20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column20, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Subjects you most want to see covered at a research conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['nan', 'Nan', 'NaN', 'NAN']\n",
    "\n",
    "stopWords = nlp.set_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_topics = datadf.ideal_topics.fillna('nan')\n",
    "ideal_topics = ideal_topics.apply(nlp.basic_clean)\n",
    "ideal_topics = ideal_topics.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<726x1123 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 6020 stored elements in Compressed Sparse Row format>,\n",
       " CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=0.3, max_features=None, min_df=2,\n",
       "                 ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, vocabulary=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal_topics_matrix, ideal_topics_vector = nlp.create_wordcount_matrix(ideal_topics, ngram=(1,3), max_df=.3, stop_words=stopWords)\n",
    "ideal_topics_matrix, ideal_topics_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda21 = LatentDirichletAllocation(n_components= 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=4, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda21.fit(ideal_topics_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el327801122587335446985547363\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el327801122587335446985547363_data = {\"mdsDat\": {\"x\": [0.022131033826180885, 0.10912841873439917, -0.13657274680708842, 0.005313294246508403], \"y\": [0.10686619429515869, 0.006254895910547923, 0.017243420177005604, -0.13036451038271224], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [28.49230658710321, 27.790722700660066, 24.033549650395194, 19.683421061841518]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [137.0, 59.0, 126.0, 44.0, 52.0, 23.0, 46.0, 32.0, 21.0, 14.0, 10.0, 10.0, 36.0, 26.0, 15.0, 38.0, 14.0, 18.0, 18.0, 30.0, 10.0, 7.0, 47.0, 20.0, 8.0, 8.0, 25.0, 8.0, 14.0, 14.0, 13.178902237708256, 5.418189052288171, 5.403570021676589, 4.554339968489649, 4.5505859785395595, 4.550177752555523, 4.550177724554889, 3.686754292349932, 3.686500413849467, 3.6857117968436075, 3.685114982059854, 3.6826760117102215, 3.682090354336685, 3.6806005941987485, 3.6227184156191474, 15.712506250692288, 2.819371899147106, 2.8193625255110577, 2.8193460511016655, 2.8193460511016655, 2.819295895545623, 2.819090232776107, 2.8190276716025098, 2.818412339885587, 2.817774680948849, 2.817774680948849, 2.815492291721161, 2.811413404682595, 2.810992852408789, 2.810472393739508, 6.292950991695451, 8.309890150459443, 25.50458658121831, 8.843190804715876, 6.2104629761165695, 20.18629332711772, 11.293161389353907, 13.387588634041673, 5.32196075324907, 11.072859939712862, 11.379052493645354, 19.862336085527726, 16.39597081543565, 4.555705067878699, 23.293773435394787, 26.669665454972034, 12.93307703002476, 15.962421239219028, 9.981583490118286, 9.202088430619346, 6.673413242611872, 14.7968368395041, 6.068674628559633, 20.6703765248802, 15.512317696612328, 11.807777074732483, 7.573979356346177, 6.890332824991667, 14.764295560555293, 16.709573461698216, 9.017286418677745, 18.340347171008204, 10.47354756513221, 7.86256430670949, 12.7468855324963, 11.67795137678826, 10.314282413334537, 9.94371772212301, 9.709405110702649, 58.474151290935964, 43.71862577850848, 14.138351118946227, 14.311815690440225, 47.00716318537901, 4.5659260125757, 4.56592601257441, 8.908547462307313, 3.6990687945386034, 3.698881330179723, 3.698866831208857, 3.694933174839227, 3.6949331748391883, 9.629249213419934, 3.6926320170108355, 3.6902771488046033, 2.829080568468191, 2.829080568468191, 2.8290698624790678, 2.8284137368306608, 2.828094875694453, 2.8276961568418995, 2.827696156841838, 2.8274071714437565, 2.826887182018474, 2.8267334546974308, 2.8260249121329855, 2.8226840994578057, 2.8224179196656682, 2.8224179196196677, 14.030815408244539, 5.3884835029814235, 7.548293777694804, 12.01787939596921, 9.282482434544157, 3.4311273543193956, 3.4141955621563103, 14.01587255388787, 19.835425157408775, 20.271160341357742, 8.251685036795426, 6.066999676583431, 40.746351314452454, 9.500923417909275, 15.209660014376002, 11.786694489401635, 14.890198191061998, 8.542537672570882, 9.037058619708848, 9.499535563880094, 7.697555054708189, 9.280639070380833, 7.266978431784699, 10.299742639693061, 6.2936144583344324, 7.872813508660737, 7.379643810301076, 6.91885886741041, 6.943993578568027, 136.57657517532428, 7.5858301117449365, 3.4783665523200433, 3.4683376237746755, 3.4658216300987146, 7.611598805687421, 2.669892392788184, 2.66985049877663, 2.669839065838434, 2.669816823346507, 2.669803056733484, 2.669795910862994, 2.669791258273235, 2.6662311627399977, 2.665734908295196, 2.6654630505883348, 2.6626702072049087, 2.659504003260408, 2.6458223355486945, 7.868898039231357, 1.8483908090053873, 1.8483908090053873, 1.8483897351030554, 1.848387544670856, 1.8483834385026303, 1.848382349290956, 1.8483779411728156, 1.8483779411728156, 1.8483768498258084, 1.8483732769017827, 4.316876617892143, 10.305019814833642, 6.602744048843561, 8.301457853645102, 3.4916260290586703, 3.495259478997287, 5.028126381187298, 8.84196934145466, 15.105981742906183, 7.828576054300182, 18.3839780855513, 6.107099264579265, 8.931712509485527, 9.659146637244612, 21.999367719829856, 5.844512290504572, 5.813345305605015, 7.6863330714699085, 5.074034561438243, 4.320801602432089, 9.150393939679038, 4.3120618499678445, 8.345929933067595, 6.718662039183617, 7.175068080761444, 27.286281065071936, 11.271859720340748, 9.779679728783636, 7.074278237348996, 6.983523666075968, 10.301796330636108, 11.314794297785058, 7.0917721433596155, 9.322542574749518, 7.1968484149106, 7.548792179460122, 10.212831002230528, 10.212831001222119, 6.881647813473469, 5.215753830830758, 3.5428368957315866, 3.526139544025989, 6.888944224104236, 2.7124786168096304, 2.7124630592678027, 2.712046665795735, 2.7114556668617222, 2.7101135502488263, 2.7090706058128236, 2.7078488040879947, 2.7072018431771485, 2.706782160438068, 2.705395645205571, 2.700068857813121, 6.722916836144215, 8.016904776779834, 2.672138991727108, 2.649613191048018, 5.208350333280252, 1.8778576956474968, 1.8778572931419988, 1.8778544717798102, 1.877850772492919, 1.877850772492919, 1.877849104229309, 1.8778474625300092, 4.380516475812041, 17.149760145662164, 6.050489746029366, 5.942899082039405, 14.61447387748094, 7.600669290688821, 3.5508495589563003, 58.184711555462506, 21.669342003437084, 7.986752589648383, 14.651630682225147, 6.732063930957957, 4.764067279675064, 9.657947491207917, 10.610270515190185, 10.114145479931167, 3.550941167652191, 3.5499867976007726, 3.548618074043244, 6.394396903364535, 9.935844176525807, 5.624550951411608, 5.951029314369331, 6.063653313748234, 9.15414691378215, 11.056831500444321, 6.521696411199448, 7.334842537980527, 8.286160832024208, 8.053925676977824, 7.503312963339209, 6.666571649818209, 6.228491296384228, 6.255219886149757], \"Term\": [\"nan\", \"study\", \"method\", \"case study\", \"case\", \"research method\", \"analysis\", \"best\", \"strategy\", \"example\", \"mixed\", \"mixed method\", \"product\", \"ethic\", \"bias\", \"way\", \"user research\", \"workshop\", \"research team\", \"user\", \"method research\", \"analysis method\", \"data\", \"ops\", \"scaling research\", \"apply\", \"work\", \"research agile\", \"ai\", \"best practice\", \"user research\", \"enterprise\", \"ethic research\", \"new technique\", \"qualitative data\", \"leading research team\", \"leading research\", \"internal\", \"support\", \"academia\", \"don know\", \"research work\", \"research ethic\", \"include\", \"share research\", \"research team\", \"sell\", \"executive\", \"embedding research\", \"embedding\", \"listening\", \"involve\", \"engage\", \"doe\", \"know don\", \"know don know\", \"instead\", \"business case\", \"research enterprise\", \"inspirational\", \"anthropology\", \"help\", \"best\", \"recruiting\", \"small\", \"ethic\", \"best practice\", \"company\", \"science\", \"research ops\", \"don\", \"user\", \"work\", \"teaching research\", \"practice\", \"team\", \"ops\", \"qualitative\", \"value\", \"learning\", \"lot\", \"impact\", \"teaching\", \"data\", \"tool\", \"want\", \"culture\", \"trend\", \"researcher\", \"analysis\", \"process\", \"new\", \"stakeholder\", \"research practice\", \"way\", \"design\", \"technique\", \"product\", \"ux\", \"study\", \"case study\", \"example\", \"bias\", \"case\", \"case study research\", \"study research\", \"research technique\", \"space\", \"research example\", \"avoiding\", \"method case study\", \"method case\", \"right\", \"compelling\", \"various\", \"exploratory research\", \"exploratory\", \"bias research\", \"evaluation\", \"avoiding bias\", \"topic case study\", \"topic case\", \"inhouse research\", \"creativity\", \"worked\", \"research approach\", \"method approach\", \"love case study\", \"love case\", \"workshop\", \"deep\", \"specific\", \"need\", \"challenge\", \"research case study\", \"privacy\", \"field\", \"technique\", \"design\", \"question\", \"human\", \"method\", \"advanced\", \"ux\", \"organization\", \"data\", \"leadership\", \"different\", \"approach\", \"ux research\", \"people\", \"technology\", \"new\", \"use\", \"team\", \"practice\", \"topic\", \"tool\", \"nan\", \"apply\", \"building research\", \"mix\", \"matter\", \"strategic\", \"teach research\", \"method ethic\", \"research want\", \"translate\", \"like new\", \"research ai\", \"research application\", \"learn new\", \"new interesting\", \"year\", \"ux researcher\", \"directly\", \"strategic research\", \"thing\", \"practical advice\", \"personal\", \"consistently\", \"coverage\", \"ux researcher role\", \"influential\", \"apply real life\", \"apply real\", \"just starting\", \"uxr manager\", \"advice\", \"ai\", \"effective\", \"building\", \"persona\", \"research way\", \"designer\", \"application\", \"like\", \"learn\", \"way\", \"future\", \"just\", \"practical\", \"new\", \"doing\", \"ha\", \"love\", \"role\", \"manager\", \"management\", \"failure\", \"project\", \"synthesis\", \"qual\", \"method\", \"product\", \"topic\", \"emerging\", \"experience\", \"researcher\", \"data\", \"technology\", \"ux\", \"make\", \"impact\", \"mixed\", \"mixed method\", \"analysis method\", \"recruitment\", \"mixed method research\", \"day\", \"scaling research\", \"large orgs\", \"presentation skill\", \"participant recruitment\", \"recruitment strategy\", \"research working\", \"scientific\", \"refresher\", \"blending\", \"new research method\", \"advance\", \"feel\", \"research agile\", \"method research\", \"outcome\", \"turn research\", \"product team\", \"contact\", \"research analysis method\", \"mixing\", \"sprint\", \"design sprint\", \"research communication\", \"method impact\", \"research analysis\", \"research method\", \"academic\", \"development\", \"strategy\", \"scaling\", \"research planning\", \"method\", \"analysis\", \"agile\", \"product\", \"working\", \"le\", \"skill\", \"methodology\", \"insight\", \"collaboration\", \"firm\", \"orgs\", \"presentation\", \"topic\", \"session\", \"research research\", \"new method\", \"researcher\", \"new\", \"business\", \"people\", \"team\", \"design\", \"technique\", \"ux\", \"organization\", \"practice\"], \"Total\": [137.0, 59.0, 126.0, 44.0, 52.0, 23.0, 46.0, 32.0, 21.0, 14.0, 10.0, 10.0, 36.0, 26.0, 15.0, 38.0, 14.0, 18.0, 18.0, 30.0, 10.0, 7.0, 47.0, 20.0, 8.0, 8.0, 25.0, 8.0, 14.0, 14.0, 14.680214352180911, 6.053457995033636, 6.053631959531677, 5.186086572356902, 5.1859929254439505, 5.185865461531418, 5.185865460047022, 4.318573574283333, 4.318576804705883, 4.318533452227832, 4.318510726696753, 4.318390674481887, 4.318458827171721, 4.318483833787095, 4.31879661223794, 18.98820533493355, 3.4510675365496164, 3.4510672188575238, 3.4510667848777494, 3.4510667848777494, 3.4510652484598947, 3.4510588596590877, 3.451056733309631, 3.4510169219660742, 3.4510068611631906, 3.4510068611631906, 3.45107986272038, 3.450940919089531, 3.450750134038429, 3.4509816733634286, 7.791587792298163, 10.389605965139529, 32.857994282189686, 11.21603624019212, 7.791857230345413, 26.636676250001646, 14.738316967006062, 18.860975039946283, 6.92422140199292, 15.497486793068276, 16.478856696043128, 30.960563054750214, 25.878470840894412, 6.0082389093657556, 40.359762743128584, 48.81354531626597, 20.59211220391431, 27.403114954473185, 15.417685754111806, 14.609359168194972, 9.52691646236426, 27.99233833779618, 8.552652346465681, 47.121170701705935, 32.50130636042577, 23.034553614695714, 11.934940021639601, 10.301026866710645, 37.24332509397062, 46.71264934388026, 16.41169333941605, 61.696289030975436, 23.032888119165555, 12.910776263848541, 38.02329706177509, 44.60523552885935, 38.749152984063016, 36.09521683134891, 40.90817934964638, 59.17189754716457, 44.37352379933488, 14.776557129162056, 15.618697309219774, 52.19240877370742, 5.200864107964779, 5.2008641079647076, 10.387722004318315, 4.330533675675563, 4.330533214978745, 4.330532661919486, 4.330426481304181, 4.330426481304177, 11.290998946749315, 4.330538804932424, 4.330225195653928, 3.460055550016479, 3.460055550016479, 3.460055295283103, 3.4600178778698996, 3.4600149850944, 3.459998509986611, 3.459998509986608, 3.460049316385092, 3.459965625106892, 3.4600110979450855, 3.4600452211385857, 3.459919258585317, 3.4600326957479783, 3.4600326957478207, 18.878381906374564, 6.890191691780993, 10.308627900925766, 17.30141114130299, 13.024687448334673, 4.3295271175701755, 4.329580481343214, 23.925986326248776, 38.749152984063016, 44.60523552885935, 13.888842981120101, 9.498105434605927, 126.44598828342248, 18.048861710342813, 40.90817934964638, 28.14586485887918, 47.121170701705935, 18.094893191304305, 22.194643349343025, 28.178458887456305, 20.373934254621293, 30.658407667289687, 18.67120660466864, 61.696289030975436, 16.318227040936755, 48.81354531626597, 40.359762743128584, 28.580054477382788, 32.50130636042577, 137.2204330413967, 8.242919164557353, 4.135113996838767, 4.13557698793622, 4.135884787710235, 9.1089075671405, 3.313091108772274, 3.313092800760361, 3.313093256095946, 3.3130940308829095, 3.313094656471495, 3.3130950614992765, 3.3130952646702805, 3.3132978863805986, 3.313338714157923, 3.3131616633843284, 3.3132073697331936, 3.3137077266578254, 3.3134747274215925, 9.921289543549852, 2.491573180323264, 2.491573180323264, 2.4915732171771188, 2.491573344575822, 2.4915734720043923, 2.4915735323359183, 2.4915736611432617, 2.4915736611432617, 2.491573765613417, 2.4915739005947652, 5.8232427440878105, 14.169106372730285, 9.166935939938538, 12.506912128344869, 4.969222724692112, 5.001904745973652, 7.485837347475514, 14.211263747683539, 28.535881258620076, 13.447133237382287, 38.02329706177509, 10.072069569296401, 16.858877958352682, 19.42371112428248, 61.696289030975436, 10.043498489688654, 10.083111297066484, 15.195072950654769, 8.369733927527514, 6.6903122143496505, 20.208335911347035, 6.690942646561116, 18.631729095285692, 13.50557786767283, 15.134054248317547, 126.44598828342248, 36.09521683134891, 28.580054477382788, 15.9851799295266, 16.090688875032715, 37.24332509397062, 47.121170701705935, 18.67120660466864, 40.90817934964638, 21.173317423829918, 27.99233833779618, 10.864311082130905, 10.864311082170575, 7.525560674504949, 5.856242034350163, 4.186937798584014, 4.187784789834348, 8.392851364925685, 3.3523872023431798, 3.352387600635108, 3.352403984530758, 3.3523954845261974, 3.3523515298989373, 3.3525181526320234, 3.352568026657129, 3.3523073474966414, 3.352613137264069, 3.3522834607129663, 3.352193121235255, 8.402954237686172, 10.060316562336856, 3.3538509113115182, 3.355089624181483, 6.678316312926004, 2.517770997957295, 2.5177710325053795, 2.5177710577125603, 2.5177712043136156, 2.5177712043136156, 2.5177711671388177, 2.5177712040552764, 5.892002440667779, 23.41039571030771, 8.425820100101149, 8.433385148048188, 21.799694224740236, 10.970615357466158, 5.054363801317165, 126.44598828342248, 46.71264934388026, 14.338242595911716, 36.09521683134891, 12.542829785666441, 7.609084534893447, 21.936541061314497, 25.288629758832194, 23.56494267035481, 5.0572784187729205, 5.05738501133989, 5.054458761846347, 12.711959120551464, 28.580054477382788, 11.06142238737651, 12.77634340131273, 14.206417829594834, 37.24332509397062, 61.696289030975436, 20.23877217359619, 30.658407667289687, 48.81354531626597, 44.60523552885935, 38.749152984063016, 40.90817934964638, 28.14586485887918, 40.359762743128584], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1477, 1.1447, 1.1419, 1.1256, 1.1248, 1.1248, 1.1248, 1.0974, 1.0973, 1.0971, 1.0969, 1.0963, 1.0961, 1.0957, 1.0798, 1.0662, 1.0534, 1.0534, 1.0534, 1.0534, 1.0533, 1.0533, 1.0532, 1.053, 1.0528, 1.0528, 1.052, 1.0506, 1.0505, 1.0502, 1.0419, 1.0322, 1.0022, 1.0178, 1.0287, 0.9783, 0.9893, 0.9128, 0.9924, 0.9194, 0.8852, 0.8116, 0.7992, 0.9788, 0.7059, 0.6511, 0.7904, 0.7151, 0.8208, 0.7933, 0.8995, 0.618, 0.9124, 0.4315, 0.5159, 0.5873, 0.8008, 0.8534, 0.3303, 0.2275, 0.6567, 0.0424, 0.4675, 0.7596, 0.1626, -0.0846, -0.068, -0.0337, -0.1827, 1.2686, 1.2656, 1.2363, 1.1931, 1.1758, 1.1503, 1.1503, 1.1269, 1.1229, 1.1228, 1.1228, 1.1218, 1.1218, 1.1213, 1.1211, 1.1205, 1.0791, 1.0791, 1.0791, 1.0789, 1.0788, 1.0787, 1.0787, 1.0785, 1.0784, 1.0783, 1.0781, 1.0769, 1.0768, 1.0768, 0.9837, 1.0346, 0.9688, 0.9161, 0.9418, 1.0479, 1.0429, 0.7457, 0.6108, 0.4918, 0.7598, 0.8322, 0.148, 0.6388, 0.2911, 0.41, 0.1284, 0.5299, 0.382, 0.1932, 0.3071, 0.0855, 0.3368, -0.5096, 0.3277, -0.5441, -0.4186, -0.138, -0.2629, 1.421, 1.3426, 1.2528, 1.2498, 1.249, 1.2461, 1.2099, 1.2099, 1.2099, 1.2098, 1.2098, 1.2098, 1.2098, 1.2084, 1.2082, 1.2082, 1.2071, 1.2058, 1.2007, 1.194, 1.1271, 1.1271, 1.1271, 1.1271, 1.1271, 1.1271, 1.1271, 1.1271, 1.1271, 1.1271, 1.1264, 1.1073, 1.0976, 1.0159, 1.0728, 1.0673, 1.0278, 0.9512, 0.7896, 0.8847, 0.699, 0.9254, 0.7905, 0.7271, 0.3945, 0.8843, 0.875, 0.7442, 0.9252, 0.9885, 0.6334, 0.9864, 0.6226, 0.7275, 0.6794, -0.1077, 0.2619, 0.3533, 0.6105, 0.591, 0.1406, -0.0009, 0.4577, -0.0532, 0.3466, 0.1152, 1.5636, 1.5636, 1.5359, 1.5096, 1.4584, 1.4534, 1.4279, 1.4136, 1.4136, 1.4134, 1.4132, 1.4127, 1.4123, 1.4118, 1.4117, 1.4114, 1.411, 1.4091, 1.4023, 1.3983, 1.3982, 1.3893, 1.3768, 1.3322, 1.3322, 1.3321, 1.3321, 1.3321, 1.3321, 1.3321, 1.329, 1.3142, 1.2942, 1.2754, 1.2255, 1.2584, 1.2723, 0.8492, 0.8573, 1.0402, 0.7238, 1.0031, 1.1572, 0.805, 0.7569, 0.7796, 1.2718, 1.2715, 1.2717, 0.9383, 0.5688, 0.9491, 0.8614, 0.774, 0.2221, -0.0938, 0.4929, 0.1951, -0.148, -0.0863, -0.0164, -0.1888, 0.1171, -0.239], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.9265, -5.8153, -5.818, -5.989, -5.9898, -5.9899, -5.9899, -6.2003, -6.2004, -6.2006, -6.2008, -6.2014, -6.2016, -6.202, -6.2178, -4.7506, -6.4686, -6.4686, -6.4686, -6.4686, -6.4686, -6.4687, -6.4687, -6.4689, -6.4691, -6.4691, -6.4699, -6.4714, -6.4715, -6.4717, -5.6656, -5.3876, -4.2662, -5.3254, -5.6788, -4.5001, -5.0809, -4.9107, -5.8332, -5.1006, -5.0733, -4.5162, -4.708, -5.9887, -4.3569, -4.2215, -4.9453, -4.7348, -5.2043, -5.2856, -5.6069, -4.8107, -5.7019, -4.4764, -4.7634, -5.0363, -5.4804, -5.575, -4.8129, -4.6891, -5.3059, -4.596, -5.1562, -5.443, -4.9598, -5.0474, -5.1715, -5.2081, -5.232, -3.4116, -3.7024, -4.8313, -4.8191, -3.6298, -5.9615, -5.9615, -5.2931, -6.1721, -6.1721, -6.1721, -6.1732, -6.1732, -5.2153, -6.1738, -6.1744, -6.4402, -6.4402, -6.4402, -6.4404, -6.4405, -6.4407, -6.4407, -6.4408, -6.441, -6.441, -6.4413, -6.4425, -6.4425, -6.4425, -4.8389, -5.7959, -5.4588, -4.9937, -5.252, -6.2473, -6.2522, -4.84, -4.4927, -4.4709, -5.3697, -5.6773, -3.7728, -5.2288, -4.7582, -5.0132, -4.7794, -5.3351, -5.2788, -5.2289, -5.4392, -5.2522, -5.4968, -5.148, -5.6406, -5.4167, -5.4814, -5.5459, -5.5423, -2.418, -5.3086, -6.0883, -6.0912, -6.0919, -5.3052, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3529, -6.3542, -6.3544, -6.3545, -6.3556, -6.3568, -6.3619, -5.272, -6.7206, -6.7206, -6.7206, -6.7206, -6.7206, -6.7206, -6.7206, -6.7206, -6.7206, -6.7206, -5.8724, -5.0023, -5.4474, -5.2185, -6.0845, -6.0835, -5.7198, -5.1554, -4.6198, -5.2771, -4.4234, -5.5254, -5.1453, -5.067, -4.2439, -5.5694, -5.5747, -5.2954, -5.7108, -5.8714, -5.1211, -5.8735, -5.2131, -5.43, -5.3643, -4.0285, -4.9126, -5.0546, -5.3784, -5.3913, -5.0026, -4.9088, -5.376, -5.1025, -5.3612, -5.3135, -4.8116, -4.8116, -5.2064, -5.4835, -5.8703, -5.875, -5.2053, -6.1374, -6.1374, -6.1375, -6.1377, -6.1382, -6.1386, -6.1391, -6.1393, -6.1395, -6.14, -6.1419, -5.2297, -5.0537, -6.1523, -6.1608, -5.485, -6.5051, -6.5051, -6.5051, -6.5051, -6.5051, -6.5051, -6.5051, -5.658, -4.2932, -5.3351, -5.353, -4.4532, -5.107, -5.868, -3.0716, -4.0593, -5.0574, -4.4507, -5.2283, -5.5741, -4.8674, -4.7734, -4.8213, -5.868, -5.8683, -5.8687, -5.2798, -4.8391, -5.4081, -5.3517, -5.3329, -4.921, -4.7322, -5.2601, -5.1426, -5.0206, -5.0491, -5.1199, -5.2381, -5.3061, -5.3018]}, \"token.table\": {\"Topic\": [1, 1, 4, 4, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 4, 1, 2, 1, 2, 3, 4, 3, 3, 3, 1, 2, 3, 4, 2, 2, 1, 2, 3, 4, 1, 2, 2, 4, 2, 4, 2, 3, 4, 3, 1, 3, 4, 1, 1, 2, 2, 2, 1, 2, 2, 4, 1, 2, 3, 4, 2, 3, 4, 3, 2, 1, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 4, 1, 3, 4, 1, 2, 4, 1, 2, 3, 4, 3, 1, 1, 3, 4, 1, 2, 1, 1, 2, 3, 1, 1, 1, 2, 3, 4, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 2, 3, 2, 2, 1, 3, 4, 1, 2, 3, 4, 2, 4, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 3, 4, 1, 3, 2, 1, 2, 3, 4, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 4, 1, 4, 1, 2, 4, 1, 1, 1, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 1, 2, 1, 2, 3, 2, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 3, 2, 3, 4, 2, 2, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 3, 4, 4, 4, 4, 3, 1, 2, 4, 1, 2, 3, 4, 3, 2, 3, 4, 4, 1, 1, 2, 4, 1, 2, 3, 4, 1, 4, 4, 4, 1, 2, 3, 4, 3, 4, 3, 1, 2, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4, 1, 2, 1, 2, 4, 1, 3, 4, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 1, 2, 3, 4, 4, 4, 2, 4, 3, 2, 4, 4, 3, 2, 2, 4, 1, 1, 2, 2, 3, 4, 1, 2, 4, 1, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 2, 4, 3, 1, 3, 1, 4, 1, 2, 3, 4, 1, 2, 1, 3, 4, 1, 2, 4, 1, 4, 1, 2, 4, 1, 2, 4, 1, 1, 2, 3, 4, 1, 2, 2, 2, 3, 4, 1, 2, 3, 4, 1, 3, 3, 1, 3, 4, 2, 2, 1, 1, 2, 3, 3, 1, 3, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 3, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 3, 3, 3, 1, 2, 3, 2, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 2, 1, 3, 4, 2, 3, 3], \"Freq\": [0.9262403647554224, 0.2373656185676206, 0.7120968557028617, 0.8949123888711839, 0.22162062429165932, 0.5540515607291483, 0.05540515607291483, 0.16621546821874447, 0.17172562504203942, 0.6869025001681577, 0.13948710845290502, 0.13948710845290502, 0.13948710845290502, 0.5579484338116201, 0.14115216213276366, 0.14115216213276366, 0.7057608106638183, 0.3639271212140559, 0.10703738859236939, 0.06422243315542163, 0.4709645098064253, 0.9301632533127477, 0.7700612711995476, 0.1283435451999246, 0.07036671880521546, 0.2111001564156464, 0.6333004692469392, 0.07036671880521546, 0.9705299591433761, 0.8027055475784318, 0.8027055475784318, 0.3193929105898111, 0.3193929105898111, 0.21292860705987407, 0.1419524047065827, 0.9236739016366224, 0.8670482679768368, 0.7912838433383322, 0.1521699698727562, 0.03043399397455124, 0.03043399397455124, 0.7463538764042837, 0.20355105720116828, 0.8963615673463208, 0.0640258262390229, 0.8670381667280664, 0.8949060121949352, 0.23986736048148857, 0.6396462946173028, 0.07995578682716285, 0.7254939047130153, 0.39528089606329586, 0.2964606720474719, 0.3458707840553839, 0.8693281253831191, 0.09579937231252704, 0.9005140997377542, 0.9915822822405534, 0.9613787048084628, 0.23033182269441543, 0.6909954680832463, 0.19773481252049324, 0.790939250081973, 0.6892538679716648, 0.053019528305512674, 0.2120781132220507, 0.053019528305512674, 0.9236725913745549, 0.8027056906101852, 0.7943534188068055, 0.8027056495663748, 0.8670606373169728, 0.6703008130325714, 0.2513628048872143, 0.08378760162907142, 0.44565955572151633, 0.3183282540867974, 0.23344071966365143, 0.9551589207042858, 0.725669215555248, 0.1451338431110496, 0.2690267153109429, 0.4483778588515715, 0.11209446471289287, 0.1793511435406286, 0.7943533537016648, 0.13358559017278607, 0.6679279508639303, 0.13358559017278607, 0.11857634656131395, 0.11857634656131395, 0.7114580793678837, 0.22527958306426235, 0.40550324951567224, 0.22527958306426235, 0.13516774983855742, 0.9053302968954875, 0.8693089798849418, 0.2987006970808037, 0.5974013941616074, 0.09956689902693457, 0.6675220376569753, 0.30341910802589783, 0.9262452389598709, 0.10908770461056638, 0.10908770461056638, 0.7636139322739647, 0.8692964196305091, 0.8692964196305091, 0.18767383371510443, 0.18767383371510443, 0.43790561200191036, 0.18767383371510443, 0.8692989515483686, 0.8259741794032582, 0.7508444301491544, 0.07508444301491544, 0.1877111075372886, 0.8259504432091064, 0.8670475430742278, 0.9474466804158668, 0.8692963103144512, 0.43503420234926193, 0.12429548638550342, 0.43503420234926193, 0.8670381028956925, 0.8670381028956925, 0.2989115444036756, 0.5978230888073512, 0.8949365061922582, 0.08359112024593257, 0.585137841721528, 0.2507733607377977, 0.08359112024593257, 0.1977306449395797, 0.7909225797583188, 0.39713784465841667, 0.595706766987625, 0.19835147516242008, 0.19835147516242008, 0.5950544254872603, 0.7700003279087363, 0.19250008197718407, 0.21056830899276907, 0.6317049269783072, 0.10528415449638454, 0.5358609137610524, 0.28579248733922796, 0.17862030458701747, 0.9262510070559183, 0.8027055890760508, 0.8670396649531772, 0.12730775720384258, 0.1697436762717901, 0.25461551440768515, 0.42435919067947525, 0.8693178590763455, 0.8692931254379006, 0.9262317594447375, 0.8692984159349733, 0.17794778557689592, 0.2965796426281599, 0.5338433567306877, 0.802705513921482, 0.8693115142022132, 0.8693115142022132, 0.8948846952712157, 0.26284370883625713, 0.6571092720906427, 0.33158526754296425, 0.49737790131444637, 0.22105684502864284, 0.9641592205816043, 0.9641592203056246, 0.0743652927614382, 0.2974611710457528, 0.5949223420915056, 0.9054422822444013, 0.6160434483391496, 0.13689854407536656, 0.13689854407536656, 0.06844927203768328, 0.21026159821812157, 0.14017439881208105, 0.5256539955453039, 0.10513079910906079, 0.9054978233537866, 0.8692968066421835, 0.7347603002139514, 0.20993151434684326, 0.13162161224858207, 0.3290540306214552, 0.5264864489943283, 0.8670438298709795, 0.86704382987094, 0.2833755277879689, 0.23614627315664072, 0.33060478241929697, 0.14168776389398444, 0.0989690595392862, 0.2969071786178586, 0.44536076792678786, 0.1484535893089293, 0.29893971102130623, 0.5978794220426125, 0.7253586968656593, 0.3242491166117545, 0.21352990606139932, 0.45869387228004294, 0.8670722568325575, 0.9236965498131113, 0.9236965498131106, 0.905498330536197, 0.7943533537831704, 0.09940045065219254, 0.09940045065219254, 0.7952036052175403, 0.1581738527609618, 0.19771731595120223, 0.23726077914144267, 0.4349780950926449, 0.7254126833453274, 0.9204449250765212, 0.9204449250731603, 0.9553521433618538, 0.7943533999540989, 0.9983935844209865, 0.17339626088869806, 0.6935850435547922, 0.11559750725913202, 0.2917517452461827, 0.16208430291454592, 0.35658546641200106, 0.17829273320600053, 0.9054311251611482, 0.140781442865463, 0.422344328596389, 0.422344328596389, 0.8948243883719247, 0.964118113000892, 0.6313096913646797, 0.09712456790225843, 0.2913737037067753, 0.17764598903141005, 0.4263503736753841, 0.17764598903141005, 0.21317518683769204, 0.1978451199460789, 0.7913804797843156, 0.8944941439948667, 0.8948802154642217, 0.26093984028190165, 0.2935573203171394, 0.19570488021142624, 0.22832236024666394, 0.6037161476166027, 0.2012387158722009, 0.8027057024833258, 0.2059338699183708, 0.30890080487755617, 0.5148346747959269, 0.8027057024833258, 0.5698745095798623, 0.17344006813300156, 0.07433145777128639, 0.14866291554257277, 0.07866608054011887, 0.31466432216047546, 0.07866608054011887, 0.47199648324071314, 0.8948845889513646, 0.23096926002626444, 0.6929077800787933, 0.5483894814427621, 0.3046608230237567, 0.12186432920950269, 0.2770450180899022, 0.30474951989889243, 0.4155675271348533, 0.14973834019578883, 0.7486917009789441, 0.2146875354157067, 0.32203130312356004, 0.4293750708314134, 0.198228442344424, 0.198228442344424, 0.4625330321369893, 0.13215229489628266, 0.5838752282936439, 0.14596880707341098, 0.14596880707341098, 0.14596880707341098, 0.9641355227209399, 0.36000118993330016, 0.5760019038932802, 0.8024225142701428, 0.08915805714112698, 0.08915805714112698, 0.8537898486217236, 0.8948824844345588, 0.8948364287156084, 0.11900576531943113, 0.833040357236018, 0.9054977126561556, 0.16972158617888547, 0.6788863447155419, 0.7943534079069308, 0.9054976571277555, 0.8670406911655334, 0.6929163205434927, 0.7943533654302626, 0.8693761887908952, 0.9262563706366772, 0.9236737836727648, 0.08543213129538815, 0.1708642625907763, 0.7261731160107994, 0.7097925068031086, 0.06452659152755533, 0.19357977458266598, 0.19784883702661063, 0.7913953481064425, 0.6196374126938282, 0.23236402976018558, 0.07745467658672853, 0.07745467658672853, 0.3130786230737202, 0.23480896730529013, 0.46961793461058027, 0.842628343109604, 0.05266427144435025, 0.05266427144435025, 0.05266427144435025, 0.8664074756966522, 0.09626749729962802, 0.9054982060888663, 0.19992383917445908, 0.5997715175233772, 0.9262709887821609, 0.8948942177583746, 0.40275673458674005, 0.08055134691734801, 0.26850448972449337, 0.24165404075204402, 0.08856612286620578, 0.8856612286620579, 0.3584343332747047, 0.5973905554578411, 0.11947811109156822, 0.1823051793205821, 0.09115258966029105, 0.7292207172823284, 0.11914901819649401, 0.834043127375458, 0.722102848785411, 0.1444205697570822, 0.8948497408268273, 0.869296230290354, 0.4520214331301631, 0.5424257197561957, 0.9261839255558867, 0.1823441530193689, 0.1823441530193689, 0.22793019127421116, 0.4558603825484223, 0.7700346429132429, 0.12833910715220714, 0.923673685409224, 0.7760489637308143, 0.19401224093270358, 0.7943533537016648, 0.4341617928356561, 0.17366471713426243, 0.21708089641782805, 0.17366471713426243, 0.10978264875663059, 0.8782611900530447, 0.9053939585452866, 0.18348881221739538, 0.13761660916304655, 0.6880830458152327, 0.9801950318353324, 0.9613787048084759, 0.9262310665961215, 0.22213044339115978, 0.22213044339115978, 0.5183043679127062, 0.9054987929721331, 0.7015367580654035, 0.23384558602180117, 0.8321906094988843, 0.16643812189977686, 0.553125158704727, 0.16388893591251172, 0.12291670193438378, 0.16388893591251172, 0.25807015714931525, 0.5161403142986305, 0.025807015714931523, 0.20645612571945218, 0.16067520774205699, 0.3749088180647996, 0.3749088180647996, 0.05355840258068566, 0.10079334905109508, 0.8063467924087606, 0.10079334905109508, 0.492287904448109, 0.21537595819604768, 0.18460796416804087, 0.12307197611202725, 0.06997887290882272, 0.24492605518087954, 0.3498943645441136, 0.3498943645441136, 0.8670523965085787, 0.867052396508578, 0.9054979943326653, 0.6795439028143474, 0.09707770040204963, 0.09707770040204963, 0.09707770040204963, 0.8941638930828527, 0.3676870033091271, 0.3676870033091271, 0.12256233443637571, 0.12256233443637571, 0.6459830838551704, 0.19379492515655114, 0.1614957709637926, 0.8855456526810661, 0.06811889636008202, 0.24444989141484347, 0.36667483712226523, 0.22000490227335912, 0.17111492399039044, 0.1472469657802851, 0.3926585754140936, 0.2944939315605702, 0.1963292877070468, 0.9054670188789252, 0.8027056085129463, 0.8027054704348038, 0.6486057738810157, 0.12972115477620313, 0.19458173216430472, 0.9237394868088242, 0.520956481324829, 0.13023912033120724, 0.2170652005520121, 0.17365216044160967, 0.34189565357468515, 0.18409765961713817, 0.473393981872641, 0.6182745533293268, 0.19321079791541462, 0.1545686383323317, 0.8670492420621749, 0.15945365074518816, 0.3189073014903763, 0.5580877776081585, 0.7415889809535368, 0.2118825659867248, 0.9054795101472833], \"Term\": [\"academia\", \"academic\", \"academic\", \"advance\", \"advanced\", \"advanced\", \"advanced\", \"advanced\", \"advice\", \"advice\", \"agile\", \"agile\", \"agile\", \"agile\", \"ai\", \"ai\", \"ai\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis method\", \"anthropology\", \"anthropology\", \"application\", \"application\", \"application\", \"application\", \"apply\", \"apply real\", \"apply real life\", \"approach\", \"approach\", \"approach\", \"approach\", \"avoiding\", \"avoiding bias\", \"best\", \"best\", \"best\", \"best\", \"best practice\", \"best practice\", \"bias\", \"bias\", \"bias research\", \"blending\", \"building\", \"building\", \"building\", \"building research\", \"business\", \"business\", \"business\", \"business case\", \"case\", \"case\", \"case study\", \"case study research\", \"challenge\", \"challenge\", \"collaboration\", \"collaboration\", \"company\", \"company\", \"company\", \"company\", \"compelling\", \"consistently\", \"contact\", \"coverage\", \"creativity\", \"culture\", \"culture\", \"culture\", \"data\", \"data\", \"data\", \"day\", \"deep\", \"deep\", \"design\", \"design\", \"design\", \"design\", \"design sprint\", \"designer\", \"designer\", \"designer\", \"development\", \"development\", \"development\", \"different\", \"different\", \"different\", \"different\", \"directly\", \"doe\", \"doing\", \"doing\", \"doing\", \"don\", \"don\", \"don know\", \"effective\", \"effective\", \"effective\", \"embedding\", \"embedding research\", \"emerging\", \"emerging\", \"emerging\", \"emerging\", \"engage\", \"enterprise\", \"ethic\", \"ethic\", \"ethic\", \"ethic research\", \"evaluation\", \"example\", \"executive\", \"experience\", \"experience\", \"experience\", \"exploratory\", \"exploratory research\", \"failure\", \"failure\", \"feel\", \"field\", \"field\", \"field\", \"field\", \"firm\", \"firm\", \"future\", \"future\", \"ha\", \"ha\", \"ha\", \"help\", \"help\", \"human\", \"human\", \"human\", \"impact\", \"impact\", \"impact\", \"include\", \"influential\", \"inhouse research\", \"insight\", \"insight\", \"insight\", \"insight\", \"inspirational\", \"instead\", \"internal\", \"involve\", \"just\", \"just\", \"just\", \"just starting\", \"know don\", \"know don know\", \"large orgs\", \"le\", \"le\", \"leadership\", \"leadership\", \"leadership\", \"leading research\", \"leading research team\", \"learn\", \"learn\", \"learn\", \"learn new\", \"learning\", \"learning\", \"learning\", \"learning\", \"like\", \"like\", \"like\", \"like\", \"like new\", \"listening\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love case\", \"love case study\", \"make\", \"make\", \"make\", \"make\", \"management\", \"management\", \"management\", \"management\", \"manager\", \"manager\", \"matter\", \"method\", \"method\", \"method\", \"method approach\", \"method case\", \"method case study\", \"method ethic\", \"method impact\", \"method research\", \"method research\", \"method research\", \"methodology\", \"methodology\", \"methodology\", \"methodology\", \"mix\", \"mixed\", \"mixed method\", \"mixed method research\", \"mixing\", \"nan\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"new\", \"new interesting\", \"new method\", \"new method\", \"new method\", \"new research method\", \"new technique\", \"ops\", \"ops\", \"ops\", \"organization\", \"organization\", \"organization\", \"organization\", \"orgs\", \"orgs\", \"outcome\", \"participant recruitment\", \"people\", \"people\", \"people\", \"people\", \"persona\", \"persona\", \"personal\", \"practical\", \"practical\", \"practical\", \"practical advice\", \"practice\", \"practice\", \"practice\", \"practice\", \"presentation\", \"presentation\", \"presentation\", \"presentation\", \"presentation skill\", \"privacy\", \"privacy\", \"process\", \"process\", \"process\", \"product\", \"product\", \"product\", \"product team\", \"product team\", \"project\", \"project\", \"project\", \"qual\", \"qual\", \"qual\", \"qual\", \"qualitative\", \"qualitative\", \"qualitative\", \"qualitative\", \"qualitative data\", \"question\", \"question\", \"recruiting\", \"recruiting\", \"recruiting\", \"recruitment\", \"recruitment strategy\", \"refresher\", \"research agile\", \"research agile\", \"research ai\", \"research analysis\", \"research analysis\", \"research analysis method\", \"research application\", \"research approach\", \"research case study\", \"research communication\", \"research enterprise\", \"research ethic\", \"research example\", \"research method\", \"research method\", \"research method\", \"research ops\", \"research ops\", \"research ops\", \"research planning\", \"research planning\", \"research practice\", \"research practice\", \"research practice\", \"research practice\", \"research research\", \"research research\", \"research research\", \"research team\", \"research team\", \"research team\", \"research team\", \"research technique\", \"research technique\", \"research want\", \"research way\", \"research way\", \"research work\", \"research working\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"right\", \"right\", \"role\", \"role\", \"role\", \"scaling\", \"scaling\", \"scaling\", \"scaling research\", \"scaling research\", \"science\", \"science\", \"scientific\", \"sell\", \"session\", \"session\", \"share research\", \"skill\", \"skill\", \"skill\", \"skill\", \"small\", \"small\", \"space\", \"specific\", \"specific\", \"sprint\", \"stakeholder\", \"stakeholder\", \"stakeholder\", \"stakeholder\", \"strategic\", \"strategic\", \"strategic research\", \"strategy\", \"strategy\", \"strategy\", \"study\", \"study research\", \"support\", \"synthesis\", \"synthesis\", \"synthesis\", \"teach research\", \"teaching\", \"teaching\", \"teaching research\", \"teaching research\", \"team\", \"team\", \"team\", \"team\", \"technique\", \"technique\", \"technique\", \"technique\", \"technology\", \"technology\", \"technology\", \"technology\", \"thing\", \"thing\", \"thing\", \"tool\", \"tool\", \"tool\", \"tool\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic case\", \"topic case study\", \"translate\", \"trend\", \"trend\", \"trend\", \"trend\", \"turn research\", \"use\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user research\", \"user research\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux research\", \"ux research\", \"ux research\", \"ux research\", \"ux researcher\", \"ux researcher role\", \"uxr manager\", \"value\", \"value\", \"value\", \"various\", \"want\", \"want\", \"want\", \"want\", \"way\", \"way\", \"way\", \"work\", \"work\", \"work\", \"worked\", \"working\", \"working\", \"working\", \"workshop\", \"workshop\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 4, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el327801122587335446985547363\", ldavis_el327801122587335446985547363_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el327801122587335446985547363\", ldavis_el327801122587335446985547363_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el327801122587335446985547363\", ldavis_el327801122587335446985547363_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.022131  0.106866       1        1  28.492307\n",
       "2      0.109128  0.006255       2        1  27.790723\n",
       "3     -0.136573  0.017243       3        1  24.033550\n",
       "0      0.005313 -0.130365       4        1  19.683421, topic_info=     Category        Freq          Term       Total  loglift  logprob\n",
       "620   Default  137.000000           nan  137.000000  30.0000  30.0000\n",
       "990   Default   59.000000         study   59.000000  29.0000  29.0000\n",
       "582   Default  126.000000        method  126.000000  28.0000  28.0000\n",
       "134   Default   44.000000    case study   44.000000  27.0000  27.0000\n",
       "132   Default   52.000000          case   52.000000  26.0000  26.0000\n",
       "...       ...         ...           ...         ...      ...      ...\n",
       "244    Topic4    8.053926        design   44.605236  -0.0863  -5.0491\n",
       "1017   Topic4    7.503313     technique   38.749153  -0.0164  -5.1199\n",
       "1084   Topic4    6.666572            ux   40.908179  -0.1888  -5.2381\n",
       "664    Topic4    6.228491  organization   28.145865   0.1171  -5.3061\n",
       "713    Topic4    6.255220      practice   40.359763  -0.2390  -5.3018\n",
       "\n",
       "[288 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "3         1  0.926240  academia\n",
       "4         1  0.237366  academic\n",
       "4         4  0.712097  academic\n",
       "21        4  0.894912   advance\n",
       "22        1  0.221621  advanced\n",
       "...     ...       ...       ...\n",
       "1115      3  0.318907   working\n",
       "1115      4  0.558088   working\n",
       "1118      2  0.741589  workshop\n",
       "1118      3  0.211883  workshop\n",
       "1122      3  0.905480      year\n",
       "\n",
       "[464 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 3, 4, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda21, ideal_topics_matrix, ideal_topics_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4) - considerable overlap between 2 & 3\n",
    "1. case study\n",
    "2. finding\n",
    "3. ops\n",
    "4. new method\n",
    "\n",
    "#### Topic groups (6)\n",
    "1. case study\n",
    "2. ops\n",
    "3. stakeholder\n",
    "4. new method\n",
    "5. user research\n",
    "6. quantitative\n",
    "\n",
    "#### Topic groups (8)\n",
    "1. case study\n",
    "2. ops\n",
    "3. user research\n",
    "4. working\n",
    "5. quant\n",
    "6. mixed method\n",
    "7. ethic\n",
    "8. qualitative data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W21 = lda21.transform(ideal_topics_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column21 = datadf.ideal_topics.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix21, count_vect21 = nlp.create_wordcount_matrix(datadf.ideal_topics.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA21a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA21a.fit(word_count_matrix21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA21a.transform(word_count_matrix21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column21, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. If attending a conference about research, who might you be excited to see there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_attendees = datadf.ideal_attendees.fillna('nan').apply(nlp.basic_clean)\n",
    "ideal_attendees = ideal_attendees.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_att_matrix, ideal_att_vector = nlp.create_wordcount_matrix(ideal_attendees, ngram=(1,3), max_df=.3)\n",
    "ideal_att_matrix, ideal_att_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda22 = LatentDirichletAllocation(n_components= 4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda22.fit(ideal_att_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda22, ideal_att_matrix, ideal_att_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. industry\n",
    "2. field\n",
    "3. erika hall\n",
    "4. Indi young\n",
    "\n",
    "#### Topic groups (6) - some overlap between 2, 3, & 4; 5 is mostly overlapped with 2 & 4\n",
    "1. steve portigal\n",
    "2. expert\n",
    "3. diverse\n",
    "4. new\n",
    "5. startup\n",
    "6. doing research\n",
    "\n",
    "#### Topic groups (8)\n",
    "1. google\n",
    "2. jared spool\n",
    "3. different\n",
    "4. new\n",
    "5. consultant\n",
    "6. erika hall\n",
    "7. practioner\n",
    "8. steve portigal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W22 = lda22.transform(ideal_att_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_doc_column22 = datadf.ideal_attendees.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix22, count_vect22 = nlp.create_wordcount_matrix(datadf.ideal_attendees.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA22a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA22a.fit(word_count_matrix22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA22a.transform(word_count_matrix22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column22, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['nan', 'Nan', 'NaN', 'NAN']\n",
    "\n",
    "stopWords = nlp.set_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = datadf.recommendations.fillna('nan').apply(nlp.basic_clean)\n",
    "recommendations = recommendations.apply(nlp.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<726x1410 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 7489 stored elements in Compressed Sparse Row format>,\n",
       " CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=0.3, max_features=None, min_df=2,\n",
       "                 ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=None, vocabulary=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_matrix, recommendations_vector = nlp.create_wordcount_matrix(recommendations, ngram=(1,3), max_df=.3, stop)\n",
    "recommendations_matrix, recommendations_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda23 = LatentDirichletAllocation(n_components= 8, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=8, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda23.fit(recommendations_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el327801121391581763126018302\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el327801121391581763126018302_data = {\"mdsDat\": {\"x\": [-0.0716542036388106, -0.023703675037380224, -0.0722322271924553, 0.04012248474802565, 0.05501954589339877, 0.11640399393716735, 0.0017703880671537454, -0.0457263067770995], \"y\": [-0.03395105744529287, 0.007995488515765358, -0.09503042885145778, -0.027799976838221763, 0.012454008839094676, -0.04013010140224057, 0.08554237086530299, 0.09091969631704995], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [18.512035008492994, 17.738497132059216, 15.353280063078827, 13.311889135917893, 11.742106883385746, 8.782703483114975, 8.744571195471268, 5.814917098479084]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Freq\": [127.0, 133.0, 16.0, 199.0, 23.0, 12.0, 14.0, 40.0, 23.0, 180.0, 74.0, 38.0, 27.0, 19.0, 65.0, 51.0, 30.0, 22.0, 40.0, 13.0, 13.0, 8.0, 24.0, 51.0, 30.0, 15.0, 9.0, 15.0, 12.0, 18.0, 7.216552008687445, 3.6638517838981635, 2.7756751708647305, 2.775675170606689, 2.7756751695215294, 2.7756751652491802, 2.7756751624454594, 2.7750951607903422, 2.77496157688508, 1.8874591188044976, 1.8874591140467198, 1.8874591134900893, 1.8874591119475888, 1.8874591097526252, 1.8874591094767843, 1.8874591084246717, 1.8874591068334154, 1.8874591037013562, 1.8874591037013562, 1.8874591037013562, 1.8874590983789659, 1.8874590956077042, 1.8874590940095128, 1.8874590938128124, 1.887459093786797, 1.8874590919605634, 1.8874590919605634, 1.8874590698288516, 1.8874590082660012, 1.8874590082660012, 3.663845832973773, 14.21838038570913, 72.79245980998282, 3.6639661067779983, 5.440518618883697, 5.440395109550936, 2.775624405658855, 7.2168933514547575, 3.5584249907080525, 2.7757422788361272, 2.775651933381048, 2.7738887758043185, 13.386650485448358, 6.232665820497388, 31.597018020326114, 13.373502925940134, 5.869753148526057, 10.512692430309352, 6.28927530911539, 19.414125214534803, 34.47901898338193, 10.16303505907233, 16.139368925575553, 6.328728040820843, 17.204666434648253, 12.180871119512428, 12.914723189584718, 9.544458019832389, 9.356295659584232, 6.030047124038486, 6.482784877651906, 11.581129252124784, 5.385186139995948, 4.552119150444307, 9.436959988227466, 8.40153291577677, 7.440169379017458, 6.437143363206521, 8.671920627811607, 7.2165090438811, 10.059131148537118, 6.407032670693259, 7.250760640638223, 4.52685240104799, 4.526844422199351, 2.7603050288393485, 2.7603050067413797, 2.7602344738375417, 1.8770074171822357, 1.877007413219744, 1.8770074029408703, 1.8770074029408703, 1.8770074006527857, 1.8770073989795129, 1.8770073913819478, 1.8770073913819478, 1.8770073833890266, 1.8770073724196317, 1.877007366978576, 1.877007364388696, 1.8770073447791433, 1.8769758822308074, 1.87696372672359, 1.8769630709649507, 1.8769629618931423, 1.8769466533702055, 1.8769466510758441, 1.8769466461695297, 1.8769367176087668, 1.87689418899795, 1.8768015717021875, 1.876503410873747, 1.8763487685548732, 3.6435085546593218, 3.643728814317593, 8.59933491756279, 4.492820746964089, 6.2401341243350945, 5.00683664164226, 41.41383893215952, 3.6436310057942833, 2.7602511686231113, 2.760185702613627, 2.7603187888349336, 2.7603323118338228, 2.760406370157067, 2.7603188643409107, 6.107421971804506, 10.43745534586447, 6.596830435435811, 19.004826668039353, 5.410282532204186, 4.5269195773109665, 4.526921984683591, 7.266207508647675, 10.303947419251395, 34.16474466347784, 8.638286952021279, 15.630705458878403, 13.305033593207268, 8.025701663942309, 14.078701385449834, 4.462502047192524, 4.155757329844143, 10.37567456126741, 19.927022905514896, 21.611451837364953, 12.61644705298561, 6.719735698367016, 8.21743158921619, 8.39251914589797, 7.571187991248881, 8.511993846919012, 8.059295284542474, 7.866216737361896, 6.434438398470009, 6.414960512454328, 7.350232046813, 6.624673384259667, 6.744881041718589, 6.568075056082798, 3.6073720508817217, 2.7328575904053145, 2.7328575904053145, 2.732857586639479, 2.732799598604438, 2.7327547949309623, 2.7327056807630172, 1.8583431938892343, 1.858343188136809, 1.8583431869369618, 1.8583431841165123, 1.8583431756279234, 1.8583431756142492, 1.858343162298901, 1.8583431168303273, 1.8582239928908064, 1.8582239887566296, 1.8581782227343417, 1.858178220024366, 1.8581357227413005, 1.8581308775099752, 1.8580982537884305, 1.8580743116885041, 1.857996867258753, 1.857996866867806, 3.60734827064284, 3.6071922902527747, 3.6073942578004288, 3.292038803909635, 2.7327625880546424, 6.231025599422895, 7.392087603014206, 7.105583088685484, 7.042094482627454, 3.60746759014123, 3.6074284962718863, 2.7327978574411165, 44.24484205505144, 7.042410505713244, 2.7329757637495624, 45.31780147028121, 10.603690391024285, 4.072697098588535, 7.105591751848162, 5.356374421931376, 7.105859865546332, 11.122337427025938, 3.6073781262155147, 11.464777031539443, 10.81493386705972, 8.58170556613137, 5.186774910315213, 11.13834851733488, 10.802965860106914, 7.105615953672331, 8.774887988018753, 5.3989379395568875, 5.356674084362699, 13.202097743328714, 5.356311583870406, 6.431139230109643, 5.8611367649587605, 5.463620388523005, 6.230901692000957, 5.701158688586098, 5.356354267169388, 6.769488000951186, 5.832053155629809, 5.2810937545847105, 1.832220855704899, 1.8322208545757455, 1.8322208520144707, 1.8322208507827995, 1.8322208477201347, 1.8322208355980167, 1.8322208292986266, 1.8322208271243123, 1.8322208255164834, 1.832220822046795, 1.832174934467801, 1.8321002971883966, 1.8320343677571398, 1.8320257394447008, 1.8319834774180326, 1.8319834765981162, 1.831884724008606, 1.831884724008475, 11.20946602516763, 2.6944431952391343, 5.281156430072032, 5.3557921654969665, 1.8322220517195433, 1.83225018679727, 1.8321800333140363, 1.8319836598787176, 1.8319836598787114, 2.694488918798074, 2.694253632045147, 4.419028124281928, 3.5567780108094227, 2.6943524034701563, 2.694206441281313, 7.531723140788559, 3.556541595265271, 8.383339152146354, 7.868291273487387, 5.281391443121663, 30.75484088475024, 18.390686285036715, 7.868651449317647, 21.534171758980325, 4.418910292721342, 4.814365617680467, 24.50652347880782, 4.023309763209462, 4.474777108398454, 6.000245797071718, 10.870656192178068, 5.281352754989838, 11.586236585391868, 2.694475519659822, 3.5567621770978954, 6.434748254610123, 6.7094317355514175, 14.414245348191857, 4.419782246594258, 7.584243736149694, 5.133104439058623, 6.143723335533275, 6.830799515756534, 6.01068971622136, 6.143302486550877, 6.143303654746352, 6.54539300806509, 5.531555319885902, 5.281356356114763, 5.192905189999802, 2.6435738779026843, 2.6435738716991826, 1.7976302341338157, 1.79763023412248, 1.7976302295930555, 1.7976302283909245, 1.7976302139241729, 1.7976302108650417, 1.7976302059362426, 1.7976244208807866, 1.7976243860449905, 1.7976243860449905, 1.7975604711606623, 1.7969474450146405, 3.489538606496947, 3.489548388766045, 2.6436223553495615, 2.6435585128024344, 2.6435585128024344, 2.6434992932559194, 2.5362235503448396, 3.3086372908054997, 1.7976472914726862, 1.7976408598372462, 1.7976804849840866, 1.7976448876219677, 1.797641048961888, 1.7975704545454028, 1.797691884506854, 1.7976591883432818, 2.643633851993353, 2.6437108288738758, 6.564277862346503, 5.113114344041591, 3.489710651990661, 3.3900113771301514, 9.924003229828939, 4.191871716239356, 9.369221982090906, 20.448095131875167, 7.719786064030328, 17.652663234939723, 5.181820655165028, 5.181840568271838, 6.659402998012819, 8.53321071129399, 6.873933927856345, 4.335670442258009, 4.198700867418193, 4.335601756726847, 4.303271888665667, 17.044235707682105, 7.369414216822043, 10.154966099030652, 9.807818200794344, 4.770552903118278, 12.090855717751566, 5.181595440108421, 6.389196632189867, 4.335475777533173, 5.181670696347849, 4.335599741574744, 5.403323979629598, 5.661908863406667, 5.4533418659050295, 4.3356679034300045, 4.335620350719708, 1.7280139419655258, 1.7280139414203497, 1.7280139396145227, 1.7280139372556942, 1.728013935779149, 1.728013929716125, 1.7280139114205881, 1.7280138908321292, 1.7279921331879098, 2.5412818307270104, 3.231017373275636, 1.7279950028588773, 1.7279089000419063, 1.7270086455350842, 1.7279963635326185, 1.7280442906368276, 1.7270046603220217, 1.7280751285240035, 1.7280497030046174, 2.5415192665783133, 2.5414327852665664, 2.541296305312931, 1.7280237574505477, 1.7280022390641168, 1.727685384993295, 1.7280407476948738, 1.7280267200524952, 1.7280617949440376, 1.7280690900353586, 1.7281589339027572, 3.354568167573912, 3.354752678307714, 5.73394856495619, 3.354620541080494, 2.5413112224010974, 2.5413162445305137, 2.541185395955325, 2.541261208417954, 4.167686017095293, 15.553213840329105, 7.4206675083612925, 16.84131112445276, 7.095997966206371, 7.819362760056079, 6.992641940365385, 3.8770455116593854, 7.420976204244846, 4.886234821556326, 7.42014286349406, 4.981007458589085, 3.354553744090238, 3.696122551996372, 3.354698695000691, 3.3545490162208966, 2.541307700308722, 4.167764272446462, 4.0096249964379105, 5.744625978110049, 3.2779278886813246, 3.354551399735479, 3.3541421143328183, 3.140218774232276, 3.354083914751874, 2.733265644347826, 2.5415847465537307, 1.7283320089810965, 1.7283320089810965, 1.728332006732835, 1.7283320059269023, 1.7283319996097979, 1.7283319981421918, 1.7283319884418504, 1.7283319854292518, 1.728331967926763, 1.7283319549431975, 1.728269663171081, 1.728203460869632, 1.7283533174258234, 1.7283436945366812, 1.7282659072637008, 1.7283676998894493, 1.7283467479262038, 1.7279485772860552, 1.7283313680723105, 4.168479990216401, 3.3550157241505243, 1.728387506062397, 1.7283911490657387, 1.7283426416377017, 1.728184139350344, 1.7284188086726424, 1.728445061535963, 3.35512564947779, 2.541916744670068, 4.1686025001544635, 4.981946095915022, 3.1677577353365973, 3.7108799412514393, 5.656446964869365, 3.060121528897873, 7.096624673596114, 7.296783764018158, 4.9817376494874335, 16.035213394403648, 7.860592044675606, 12.149813358911587, 6.891313207785834, 4.168661232675268, 7.786927295721615, 6.592832602555947, 4.099864491856002, 4.489536788906487, 4.845116697662209, 7.765306356490818, 4.081893148104681, 4.981466831947023, 8.416850717537729, 4.168633753372605, 2.9305355121775727, 4.565032897032977, 4.406576736639896, 3.35482615455536, 3.355208636349485, 3.3553212327823214, 3.3551114665803485, 2.347370091795794, 2.3472995222778863, 1.5962222643439972, 1.5962222552817822, 1.5962222537627486, 1.5962222390038974, 1.5962222390038974, 1.5961989459770616, 1.5961989459770616, 1.5961784074472307, 1.5963014145289773, 1.596297763007243, 1.596256854411608, 1.596270654292339, 1.596177702227004, 3.0988566889860256, 4.601349081653096, 2.3474823292509943, 0.8450668994005267, 0.8450553334763329, 0.8450553334763329, 0.8450546199318261, 0.8450522427275402, 0.845061487865977, 0.8450589417885505, 0.8450399034643379, 0.8445286971609149, 0.8450923831367761, 0.8450851362244317, 0.8450745373536963, 1.5962990602503742, 4.963707191083706, 3.0992542412007693, 4.521630827023802, 3.0842538782031577, 2.347654404353295, 1.596447253951577, 2.3475911523855313, 1.5963522780397994, 2.3476757146235823, 3.064330823096996, 1.59647757819587, 3.0990045304415212, 4.370345471677086, 3.098817609311287, 3.892156131501783, 6.103119502937024, 6.8536248262193835, 3.065811421745892, 3.320016873329521, 6.103053408297761, 3.00637799944552, 3.098922414385595, 3.92675041386449, 3.098558662829717, 2.6975514880304066, 2.9436445986212396, 3.098681838419723, 2.3476976281737065, 2.56267801808853, 2.3476988357354083], \"Term\": [\"make\", \"people\", \"industry\", \"research\", \"idea\", \"large\", \"learning\", \"good\", \"content\", \"conference\", \"talk\", \"focus\", \"love\", \"small\", \"researcher\", \"event\", \"think\", \"big\", \"way\", \"professional\", \"nice\", \"high\", \"consider\", \"like\", \"great\", \"maybe\", \"uxr\", \"community\", \"hand\", \"place\", \"don know\", \"gathering\", \"explore\", \"generative\", \"biggest challenge\", \"aimed\", \"expert field\", \"tip\", \"people talk\", \"fascinating\", \"exploring\", \"base\", \"ops research\", \"event good\", \"just doing\", \"research like\", \"expert research\", \"consent\", \"informed consent\", \"informed\", \"define research\", \"led\", \"ux researcher\", \"internal\", \"research track\", \"careful\", \"research researcher\", \"speech\", \"art\", \"art gathering\", \"far\", \"know\", \"research\", \"making\", \"talking\", \"start\", \"people want\", \"include\", \"doing research\", \"worked\", \"analysis\", \"people need\", \"focus\", \"expert\", \"people\", \"good\", \"outside\", \"want\", \"interested\", \"don\", \"conference\", \"think\", \"researcher\", \"field\", \"talk\", \"experience\", \"event\", \"learn\", \"work\", \"survey\", \"practical\", \"just\", \"create\", \"end\", \"topic\", \"lot\", \"ux\", \"doing\", \"like\", \"attendee\", \"make\", \"try\", \"need\", \"make affordable\", \"starting\", \"want learn\", \"conference make\", \"global\", \"preconference\", \"context\", \"building research practice\", \"building research\", \"workplace\", \"make easy\", \"practiced\", \"research practiced\", \"worst\", \"walk away\", \"ha lot\", \"id love\", \"make money\", \"microphone\", \"takeaway just\", \"learn best\", \"looking forward\", \"unknown\", \"person hear\", \"cost don\", \"justify\", \"wide variety\", \"research product\", \"real business\", \"really cool\", \"forward\", \"support\", \"hear\", \"make fun\", \"affordable\", \"building\", \"make\", \"slack\", \"junior\", \"manager\", \"startup\", \"channel\", \"walk\", \"innovation\", \"practice\", \"love\", \"fun\", \"don\", \"tech\", \"price\", \"easy\", \"team\", \"learn\", \"research\", \"level\", \"researcher\", \"like\", \"content\", \"just\", \"takeaway\", \"tool\", \"topic\", \"people\", \"conference\", \"talk\", \"location\", \"work\", \"lot\", \"session\", \"way\", \"attend\", \"day\", \"big\", \"design\", \"focus\", \"attendee\", \"speaker\", \"experience\", \"north america\", \"america europe\", \"north america europe\", \"real world\", \"supporting\", \"sound\", \"actual\", \"coaching\", \"felt\", \"attending conference\", \"multitrack\", \"isnt\", \"turn\", \"technology\", \"check\", \"gain\", \"researcher experience\", \"benefit\", \"type researcher\", \"research professional\", \"professional researcher\", \"actual research\", \"day workshop\", \"sure presenter\", \"make sure presenter\", \"america\", \"hold\", \"research design\", \"hotel\", \"country\", \"attending\", \"professional\", \"right\", \"type\", \"teaching\", \"north\", \"keynote speaker\", \"conference\", \"academic\", \"research method\", \"research\", \"love\", \"looking\", \"ha\", \"keynote\", \"world\", \"time\", \"minute\", \"need\", \"speaker\", \"great\", \"audience\", \"just\", \"researcher\", \"method\", \"experience\", \"study\", \"having\", \"people\", \"place\", \"workshop\", \"ux\", \"company\", \"good\", \"day\", \"know\", \"make\", \"don\", \"make people\", \"human\", \"state\", \"pair\", \"innovative\", \"industry make\", \"let people\", \"come mind\", \"people chance\", \"varied\", \"young\", \"don make people\", \"date\", \"new thing\", \"stuff like\", \"site\", \"throw\", \"people similar\", \"hearing\", \"industry\", \"talk workshop\", \"mind\", \"remote\", \"inspiring\", \"organizing\", \"newbie\", \"lightning\", \"lightning talk\", \"subject\", \"bunch\", \"kind\", \"schedule\", \"couple\", \"bit\", \"maybe\", \"view\", \"networking\", \"group\", \"insight\", \"people\", \"talk\", \"dont\", \"make\", \"say\", \"best\", \"conference\", \"material\", \"stuff\", \"thing\", \"event\", \"bring\", \"researcher\", \"data\", \"stage\", \"help\", \"new\", \"research\", \"cost\", \"just\", \"big\", \"attend\", \"like\", \"workshop\", \"need\", \"topic\", \"don\", \"lot\", \"great\", \"work\", \"maturity level\", \"food option\", \"conference especially\", \"bar\", \"overly\", \"highlight\", \"make virtual\", \"mix theory\", \"communicate\", \"need travel\", \"bay\", \"bay area\", \"extra\", \"people interested\", \"maturity\", \"near\", \"pick\", \"make expensive\", \"don make expensive\", \"past\", \"day conference\", \"rosenfeld\", \"concept\", \"listening\", \"don let\", \"problem\", \"don want\", \"conference consider\", \"nicely\", \"paid\", \"record\", \"broad\", \"learning\", \"expensive\", \"sit\", \"value\", \"day\", \"europe\", \"workshop\", \"make\", \"session\", \"people\", \"food\", \"make sure\", \"sure\", \"need\", \"different\", \"hand\", \"don make\", \"case\", \"area\", \"conference\", \"time\", \"talk\", \"don\", \"real\", \"research\", \"dont\", \"event\", \"pay\", \"ux\", \"option\", \"attend\", \"speaker\", \"just\", \"level\", \"method\", \"conference went\", \"panel workshop\", \"online conference\", \"don forget\", \"report\", \"come new\", \"city conference\", \"ll come\", \"ve seen\", \"oh\", \"connect\", \"community conference\", \"note\", \"engaged\", \"like conference\", \"forget\", \"individual\", \"sponsor\", \"ideation\", \"inclusive\", \"andor\", \"little\", \"send\", \"seen\", \"yes\", \"went\", \"spot\", \"unconference\", \"recording\", \"exchange\", \"diverse\", \"ticket\", \"community\", \"long\", \"free\", \"offering\", \"similar\", \"digital\", \"come\", \"make\", \"good\", \"conference\", \"way\", \"like\", \"speaker\", \"opportunity\", \"don\", \"really\", \"talk\", \"new\", \"interested\", \"wa\", \"food\", \"bring\", \"example\", \"time\", \"workshop\", \"research\", \"ve\", \"method\", \"session\", \"use\", \"event\", \"topic\", \"uxr conference\", \"attend uxr\", \"attend uxr conference\", \"happy\", \"mingle\", \"weed\", \"location year\", \"simple\", \"preferably\", \"just big\", \"famous people\", \"meeting\", \"accessible people\", \"uxr collective\", \"previously\", \"paying\", \"discounted\", \"reasonable\", \"agile\", \"pilot\", \"uxr\", \"feedback\", \"balance\", \"freelancer\", \"degree\", \"understanding\", \"info\", \"conference feel\", \"engage\", \"theme\", \"experienced\", \"nice\", \"possible\", \"question\", \"ve\", \"basic\", \"focus\", \"way\", \"big\", \"conference\", \"event\", \"people\", \"experience\", \"accessible\", \"researcher\", \"like\", \"small\", \"consider\", \"think\", \"make\", \"sure\", \"speaker\", \"research\", \"lot\", \"better\", \"just\", \"talk\", \"idea\", \"attendee\", \"great\", \"day\", \"high quality\", \"great idea\", \"afford attend\", \"major research\", \"good mix\", \"purchase\", \"option purchase\", \"bringing\", \"consider bringing\", \"streaming\", \"multiple location\", \"different level\", \"seriously\", \"guide\", \"definitely\", \"high\", \"large\", \"position\", \"decent\", \"level expertise\", \"expertise\", \"fluff\", \"safe\", \"focus sharing\", \"way people\", \"scaling\", \"make work\", \"strive uxr\", \"road\", \"associated\", \"major\", \"idea\", \"look\", \"content\", \"learning\", \"quality\", \"ensure\", \"multiple\", \"video\", \"hand\", \"small\", \"invite\", \"provide\", \"attend\", \"feel\", \"topic\", \"people\", \"research\", \"consider\", \"great\", \"conference\", \"think\", \"good\", \"make\", \"event\", \"different\", \"experience\", \"just\", \"pay\", \"like\", \"focus\"], \"Total\": [127.0, 133.0, 16.0, 199.0, 23.0, 12.0, 14.0, 40.0, 23.0, 180.0, 74.0, 38.0, 27.0, 19.0, 65.0, 51.0, 30.0, 22.0, 40.0, 13.0, 13.0, 8.0, 24.0, 51.0, 30.0, 15.0, 9.0, 15.0, 12.0, 18.0, 7.947205011021487, 4.3943449783085455, 3.506132243521891, 3.506132243502703, 3.5061322434206987, 3.506132243099085, 3.5061322428878947, 3.506129023433353, 3.506109178721109, 2.6179161841226577, 2.6179161837637817, 2.6179161837217544, 2.61791618360561, 2.6179161834408577, 2.6179161834198843, 2.617916183340587, 2.6179161832207507, 2.617916182985904, 2.617916182985904, 2.617916182985904, 2.617916182584727, 2.6179161823753496, 2.6179161822536585, 2.617916182240969, 2.6179161822386527, 2.6179161821017645, 2.6179161821017645, 2.6179161804396793, 2.6179161757900014, 2.6179161757900014, 5.207681961153094, 27.7322010615045, 199.79520853155242, 6.160929197317042, 10.379989244583646, 10.441157620003185, 4.352071477518751, 15.77346588042047, 6.123003356852603, 4.380647722414537, 4.380642590338312, 4.380563025485876, 38.59033890125574, 13.742315525693773, 133.1513570688457, 40.095116674238824, 13.030382670122268, 30.179064882175034, 14.60069530723213, 73.23697401990455, 180.86564998944243, 30.60006859056382, 65.08392960923942, 15.691423151476904, 74.96190196708329, 45.3436216731354, 51.875721291674935, 33.02163827436015, 32.7988621409767, 14.682242545392942, 18.141867552918722, 59.3741936315783, 12.962196736987021, 9.45945533684182, 41.917451681257376, 35.16543543734077, 28.47339805558983, 20.066787334509044, 51.9376582963402, 30.192459856935987, 127.46999558318772, 20.352425662534394, 41.35786277297553, 5.25797090587202, 5.257972430931363, 3.491376899044195, 3.4913768974994603, 3.4913772857796963, 2.6080792874469862, 2.6080792871701277, 2.6080792864506175, 2.6080792864506175, 2.6080792862917184, 2.6080792861727207, 2.6080792856472677, 2.6080792856472677, 2.60807928508035, 2.608079284323808, 2.6080792839370055, 2.6080792837544426, 2.6080792823875294, 2.6080789721383275, 2.6080788516968423, 2.608078228974456, 2.60807822135886, 2.608079624618422, 2.608079624458498, 2.6080796241164124, 2.6080785829718387, 2.6080799147246987, 2.6080804325578737, 2.6080579658109713, 2.608027005333779, 5.188006919951591, 5.262889859835871, 13.160931677745547, 6.88330413939056, 11.26236927718855, 8.733134022846567, 127.46999558318772, 6.062371947201072, 4.304563537428918, 4.30471099794523, 4.353598808589177, 4.365891618059523, 4.3795862111047015, 4.37959288055238, 12.933632647718667, 27.85443385021464, 15.430225913966133, 73.23697401990455, 12.042508619065678, 9.343980380523902, 9.506712147894673, 19.07203127582659, 33.02163827436015, 199.79520853155242, 25.573343505841635, 65.08392960923942, 51.9376582963402, 23.40836773242625, 59.3741936315783, 9.5309846785335, 8.643792006171907, 41.917451681257376, 133.1513570688457, 180.86564998944243, 74.96190196708329, 21.388946453965477, 32.7988621409767, 35.16543543734077, 29.091123249655517, 40.651353807042774, 36.459379037030814, 35.7675224299616, 22.04871355012543, 22.4975712710676, 38.59033890125574, 30.192459856935987, 45.03188103730988, 45.3436216731354, 4.33954185932281, 3.465027409219769, 3.465027409219769, 3.4650274089895854, 3.4650283205182624, 3.4650169769670103, 3.4650297910895715, 2.590512962980178, 2.590512962631394, 2.5905129625607763, 2.590512962389557, 2.590512961875975, 2.590512961875236, 2.5905129610724993, 2.5905129583296462, 2.5905148272573912, 2.5905148270079295, 2.5904962066019275, 2.590496206437911, 2.590498448754071, 2.590515094333366, 2.5905167992116964, 2.5905041745627844, 2.5905164395824802, 2.590516439586406, 5.090701926611894, 5.185494536583803, 5.222836663872067, 5.130827362644292, 4.278220954311844, 10.38895533516263, 13.613307961126813, 13.095407149598525, 12.970925750717079, 6.0899783085737305, 6.106136511738202, 4.327249877707111, 180.86564998944243, 15.59494182806446, 4.353241613441641, 199.79520853155242, 27.85443385021464, 7.798093313393025, 17.34804563944209, 11.963405416835823, 18.033523770574053, 38.36191089477172, 6.989434635337776, 41.35786277297553, 45.03188103730988, 30.455298915024827, 13.646994761918306, 59.3741936315783, 65.08392960923942, 26.51771393775918, 45.3436216731354, 16.265753010512373, 16.100489041088867, 133.1513570688457, 18.620612984061793, 37.69342162255056, 28.47339805558983, 22.459523890275484, 40.095116674238824, 35.7675224299616, 27.7322010615045, 127.46999558318772, 73.23697401990455, 6.014813886762785, 2.5659272298227016, 2.5659272297704048, 2.565927229652518, 2.5659272295951965, 2.5659272294529654, 2.5659272288918102, 2.565927228600878, 2.5659272285015353, 2.5659272284283587, 2.5659272282625163, 2.565928349082701, 2.5659203733483924, 2.5659166560480005, 2.5659331102242224, 2.565926613035076, 2.565926612996941, 2.565935445128332, 2.5659354451283347, 16.307862141917465, 4.241331890837161, 8.637183652757805, 9.49039034735335, 3.3791103330955963, 3.379261607330425, 3.379257630292868, 3.3791096584889138, 3.3791096584889133, 5.05466719778056, 5.054670729145101, 8.555549646716043, 6.8701458493471845, 5.115846449574979, 5.115995483050004, 15.657606005600028, 6.940262754143164, 18.80962360981535, 18.68536596157845, 11.804658291467092, 133.1513570688457, 74.96190196708329, 25.003288584548766, 127.46999558318772, 10.339565977028451, 12.028020588173705, 180.86564998944243, 9.46055787239737, 11.313762842810304, 18.879573547335667, 51.875721291674935, 16.175316524608963, 65.08392960923942, 5.129552469302317, 8.605804934149841, 28.279484844207193, 31.663020575548423, 199.79520853155242, 15.157038178771646, 59.3741936315783, 22.04871355012543, 36.459379037030814, 51.9376582963402, 37.69342162255056, 41.35786277297553, 41.917451681257376, 73.23697401990455, 35.16543543734077, 30.455298915024827, 32.7988621409767, 3.3793149989079976, 3.3793149987473625, 2.5333713541209155, 2.5333713541219227, 2.533371354002768, 2.5333713539704035, 2.533371353597217, 2.5333713535204785, 2.5333713533914812, 2.5333716437366176, 2.533371642837477, 2.533371642837477, 2.5333726921075437, 2.5334054583512016, 5.0385921705776955, 5.087479711888405, 4.192649582520284, 4.241537388892176, 4.241537388892176, 4.25383175170348, 4.257455082271534, 6.010728444351329, 3.3465550501506414, 3.3467044781123536, 3.395591967292526, 3.3955933093864057, 3.39559272781765, 3.3955903629410815, 3.4078837164340707, 3.407884823329323, 5.067160928974708, 5.137122154298122, 14.043681003899167, 11.086607456489872, 7.609610145971105, 7.590568636642691, 35.7675224299616, 11.103999348942528, 37.69342162255056, 127.46999558318772, 29.091123249655517, 133.1513570688457, 16.068877552697135, 16.213873128628954, 25.289358444002442, 41.35786277297553, 27.97023193153511, 12.375611244466155, 11.994643016144375, 12.794465965689314, 12.80226753682558, 180.86564998944243, 38.36191089477172, 74.96190196708329, 73.23697401990455, 17.109617006357798, 199.79520853155242, 25.003288584548766, 51.875721291674935, 15.930918271497589, 28.47339805558983, 16.056503236527178, 36.459379037030814, 45.03188103730988, 59.3741936315783, 25.573343505841635, 26.51771393775918, 2.4678501347547237, 2.4678501347657678, 2.467850134800695, 2.467850134845581, 2.4678501348760746, 2.4678501349935473, 2.467850135347305, 2.467850135748619, 2.4678520149465593, 4.126973395085085, 5.834038799956796, 3.2190156551223787, 3.3138002655964254, 3.313721303103375, 3.3300733352778153, 3.3423622935298325, 3.342297315964203, 3.356060544975474, 3.3560628920837763, 4.95656615360893, 4.9776675362051765, 5.831097478329712, 4.081233735796704, 4.159743541920971, 4.1644903400910405, 4.197100743581792, 4.197102080700609, 4.204582907683668, 4.218283552408216, 4.230568972673877, 8.274982626203508, 8.476926463702705, 15.970670162650766, 9.261729710461324, 6.644849950765566, 6.705606871035704, 6.742218429421829, 6.7519239145069685, 14.255920212436418, 127.46999558318772, 40.095116674238824, 180.86564998944243, 40.651353807042774, 51.9376582963402, 45.03188103730988, 15.39068942737124, 73.23697401990455, 28.905754097904943, 74.96190196708329, 31.663020575548423, 14.60069530723213, 19.681356666264794, 16.068877552697135, 16.175316524608963, 7.49068083742327, 38.36191089477172, 37.69342162255056, 199.79520853155242, 22.932170798772354, 26.51771393775918, 29.091123249655517, 19.824695479573602, 51.875721291674935, 41.917451681257376, 3.28148956963156, 2.4681494928416603, 2.4681494928416603, 2.468149492885664, 2.4681494929008845, 2.4681494930229158, 2.4681494930482826, 2.4681494932399923, 2.4681494932980077, 2.468149493637711, 2.468149493887745, 2.468154182182805, 2.4681613265936653, 3.219314543798688, 3.219313808361678, 3.2193173165327797, 3.33036892920875, 3.3514458307792574, 3.351477060571588, 3.356365606960549, 9.080436129324784, 7.445619816254296, 4.202306991061071, 4.213664460589284, 4.217179722920777, 4.217192218714708, 4.2259548140781655, 4.239653425936345, 8.456374540814895, 6.608535957669017, 10.95142571372989, 13.574683712782948, 9.258356662209039, 12.014096500479043, 22.932170798772354, 10.15391046054894, 38.59033890125574, 40.651353807042774, 22.04871355012543, 180.86564998944243, 51.875721291674935, 133.1513570688457, 45.3436216731354, 17.81192027457954, 65.08392960923942, 51.9376582963402, 19.337083332461912, 24.40178893694703, 30.60006859056382, 127.46999558318772, 25.289358444002442, 45.03188103730988, 199.79520853155242, 35.16543543734077, 13.534641450767921, 59.3741936315783, 74.96190196708329, 23.242080222585173, 30.192459856935987, 30.455298915024827, 35.7675224299616, 3.0949756159737527, 3.094988876422716, 2.3438109071525117, 2.343810908309104, 2.3438109085019123, 2.3438109103859097, 2.3438109103859097, 2.3438137799175527, 2.3438137799175527, 2.343818618152886, 4.040432019268934, 4.040426814730814, 4.045354176753624, 4.080539287401873, 4.120246572608099, 8.234859009756391, 12.324789472097013, 6.478531064530761, 2.4058298567665313, 2.405830812006948, 2.405830812006948, 2.405830875695741, 2.4058310671524725, 2.4059799818972243, 2.4059801937888996, 2.4059817694488563, 2.406052508693822, 2.4385868992201245, 2.4385878135882786, 2.438589150921376, 4.994725705926413, 23.242080222585173, 13.297762538513828, 23.40836773242625, 14.043681003899167, 9.912945669553313, 5.803127733267253, 9.914278889684597, 6.627877936746304, 12.375611244466155, 19.337083332461912, 6.775007848066775, 20.24494008122201, 36.459379037030814, 22.00782244070807, 41.917451681257376, 133.1513570688457, 199.79520853155242, 24.40178893694703, 30.455298915024827, 180.86564998944243, 30.60006859056382, 40.095116674238824, 127.46999558318772, 51.875721291674935, 27.97023193153511, 45.3436216731354, 59.3741936315783, 15.930918271497589, 51.9376582963402, 38.59033890125574], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5903, 1.5049, 1.4531, 1.4531, 1.4531, 1.4531, 1.4531, 1.4529, 1.4529, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3596, 1.3351, 1.0187, 0.6771, 1.1671, 1.0407, 1.0348, 1.237, 0.9048, 1.144, 1.2305, 1.2304, 1.2298, 0.628, 0.8961, 0.2483, 0.5888, 0.8893, 0.6322, 0.8445, 0.359, 0.0293, 0.5845, 0.2923, 0.7787, 0.2149, 0.3723, 0.2963, 0.4455, 0.4324, 0.7969, 0.6577, 0.0523, 0.8084, 0.9553, 0.1957, 0.2551, 0.3447, 0.5498, -0.1032, 0.2555, -0.8527, 0.5309, -0.0544, 1.5797, 1.5797, 1.4945, 1.4945, 1.4945, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4005, 1.4004, 1.4004, 1.4002, 1.4002, 1.376, 1.3618, 1.3039, 1.3028, 1.139, 1.1731, 0.6052, 1.2203, 1.2851, 1.285, 1.2738, 1.271, 1.2679, 1.2678, 0.9791, 0.7478, 0.8797, 0.3804, 0.9293, 1.0047, 0.9875, 0.7644, 0.5648, -0.0367, 0.6441, 0.303, 0.3675, 0.659, 0.2902, 0.9706, 0.9971, 0.3332, -0.17, -0.3951, -0.0525, 0.5716, 0.3453, 0.2967, 0.3833, 0.1659, 0.2201, 0.215, 0.4978, 0.4747, 0.0712, 0.2126, -0.1692, -0.2026, 1.6891, 1.6365, 1.6365, 1.6365, 1.6364, 1.6364, 1.6364, 1.5417, 1.5417, 1.5417, 1.5417, 1.5417, 1.5417, 1.5417, 1.5417, 1.5416, 1.5416, 1.5416, 1.5416, 1.5416, 1.5416, 1.5415, 1.5415, 1.5415, 1.5415, 1.5294, 1.5109, 1.5038, 1.4301, 1.4256, 1.3626, 1.2632, 1.2625, 1.263, 1.3502, 1.3475, 1.4142, 0.4658, 1.0788, 1.4083, 0.3902, 0.9081, 1.2243, 0.9812, 1.0703, 0.9425, 0.6357, 1.2124, 0.5909, 0.4474, 0.6072, 0.9064, 0.2004, 0.078, 0.5569, 0.2315, 0.771, 0.7733, -0.4373, 0.6278, 0.1055, 0.2932, 0.4602, 0.0121, 0.0375, 0.2295, -1.0616, -0.6565, 1.8864, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6797, 1.6796, 1.6796, 1.6796, 1.6796, 1.6795, 1.6795, 1.6416, 1.5628, 1.5246, 1.4444, 1.4044, 1.4044, 1.4044, 1.4043, 1.4043, 1.3874, 1.3873, 1.3559, 1.3582, 1.3753, 1.3752, 1.2847, 1.348, 1.2084, 1.1516, 1.2122, 0.5511, 0.6114, 0.8604, 0.2383, 1.1664, 1.1009, 0.0177, 1.1615, 1.0889, 0.8702, 0.4537, 0.8972, 0.2907, 1.3727, 1.1329, 0.5361, 0.4649, -0.6126, 0.7841, -0.0413, 0.559, 0.2357, -0.0121, 0.1806, 0.1096, 0.0962, -0.3984, 0.1669, 0.2644, 0.1734, 1.8964, 1.8964, 1.7989, 1.7989, 1.7989, 1.7989, 1.7989, 1.7989, 1.7989, 1.7989, 1.7989, 1.7989, 1.7989, 1.7985, 1.7746, 1.765, 1.6808, 1.6692, 1.6692, 1.6663, 1.624, 1.545, 1.5205, 1.5205, 1.506, 1.506, 1.506, 1.5059, 1.5024, 1.5024, 1.4914, 1.4777, 1.3815, 1.3681, 1.3624, 1.3359, 0.8599, 1.1678, 0.7499, 0.312, 0.8153, 0.1214, 1.0103, 1.0013, 0.8076, 0.5637, 0.7386, 1.0931, 1.0923, 1.0598, 1.0517, -0.22, 0.4923, 0.143, 0.1315, 0.8648, -0.6629, 0.5681, 0.0477, 0.8406, 0.4381, 0.8327, 0.2328, 0.0684, -0.2456, 0.3673, 0.331, 2.076, 2.076, 2.076, 2.076, 2.076, 2.076, 2.076, 2.076, 2.076, 1.9475, 1.8415, 1.8103, 1.7812, 1.7807, 1.7764, 1.7727, 1.7721, 1.7686, 1.7686, 1.7644, 1.7602, 1.6019, 1.573, 1.5539, 1.5526, 1.545, 1.545, 1.5432, 1.54, 1.5371, 1.5295, 1.5054, 1.408, 1.4168, 1.4712, 1.4621, 1.4566, 1.4552, 1.2026, 0.3288, 0.7454, 0.0585, 0.6869, 0.5389, 0.5699, 1.0537, 0.143, 0.6548, 0.1196, 0.5829, 0.9616, 0.76, 0.8659, 0.8592, 1.3514, 0.2127, 0.1916, -1.1166, 0.4871, 0.3649, 0.2721, 0.5897, -0.3063, -0.2978, 2.1812, 2.0804, 2.0804, 2.0804, 2.0804, 2.0804, 2.0804, 2.0804, 2.0804, 2.0804, 2.0804, 2.0804, 2.0803, 1.8147, 1.8147, 1.8147, 1.7808, 1.7745, 1.7743, 1.773, 1.6582, 1.6396, 1.5483, 1.5456, 1.5447, 1.5446, 1.5427, 1.5395, 1.5123, 1.4813, 1.4708, 1.4344, 1.3642, 1.2619, 1.037, 1.2373, 0.7434, 0.7191, 0.9493, 0.0138, 0.5497, 0.0426, 0.5527, 0.9845, 0.3135, 0.3727, 0.8857, 0.7438, 0.5937, -0.3615, 0.6129, 0.2351, -0.7303, 0.3043, 0.9067, -0.1287, -0.3971, 0.5012, 0.2397, 0.231, 0.0702, 2.5683, 2.5682, 2.4606, 2.4606, 2.4606, 2.4606, 2.4606, 2.4606, 2.4606, 2.4606, 1.9161, 1.9161, 1.9148, 1.9062, 1.8964, 1.8674, 1.8595, 1.8296, 1.7985, 1.7985, 1.7985, 1.7985, 1.7985, 1.7984, 1.7984, 1.7984, 1.7978, 1.785, 1.785, 1.785, 1.704, 1.3009, 1.3883, 1.2005, 1.3289, 1.4043, 1.5541, 1.4042, 1.4212, 1.1824, 1.0025, 1.3993, 0.9679, 0.7234, 0.8844, 0.468, -0.2379, -0.5278, 0.7704, 0.6285, -0.5442, 0.5245, 0.2845, -0.6353, 0.0268, 0.5059, 0.1101, -0.1081, 0.9299, -0.1642, 0.0452], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.3547, -6.0326, -6.3102, -6.3102, -6.3102, -6.3102, -6.3102, -6.3104, -6.3105, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.6959, -6.0326, -4.6766, -3.0435, -6.0326, -5.6372, -5.6372, -6.3102, -5.3547, -6.0618, -6.3102, -6.3102, -6.3108, -4.7368, -5.5013, -3.878, -4.7378, -5.5613, -4.9785, -5.4923, -4.3651, -3.7907, -5.0123, -4.5498, -5.486, -4.4859, -4.8312, -4.7727, -5.0751, -5.095, -5.5343, -5.4619, -4.8817, -5.6474, -5.8155, -5.0865, -5.2027, -5.3242, -5.469, -5.171, -5.3547, -5.0226, -5.4737, -5.35, -5.7784, -5.7784, -6.2731, -6.2731, -6.2731, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6587, -6.6588, -6.6588, -6.6588, -6.6588, -6.6588, -6.6588, -6.6588, -6.6588, -6.6588, -6.6588, -6.659, -6.6591, -5.9955, -5.9954, -5.1367, -5.7859, -5.4574, -5.6776, -3.5648, -5.9954, -6.2731, -6.2731, -6.2731, -6.2731, -6.273, -6.2731, -5.4789, -4.943, -5.4018, -4.3437, -5.6001, -5.7784, -5.7784, -5.3052, -4.9559, -3.7572, -5.1322, -4.5392, -4.7003, -5.2058, -4.6438, -5.7927, -5.8639, -4.949, -4.2963, -4.2152, -4.7534, -5.3834, -5.1822, -5.1611, -5.2641, -5.1469, -5.2016, -5.2258, -5.4267, -5.4298, -5.2937, -5.3976, -5.3796, -5.4062, -5.861, -6.1387, -6.1387, -6.1387, -6.1387, -6.1387, -6.1387, -6.5243, -6.5243, -6.5243, -6.5243, -6.5243, -6.5243, -6.5243, -6.5243, -6.5244, -6.5244, -6.5244, -6.5244, -6.5244, -6.5244, -6.5245, -6.5245, -6.5245, -6.5245, -5.861, -5.8611, -5.861, -5.9525, -6.1387, -5.3145, -5.1436, -5.1831, -5.1921, -5.861, -5.861, -6.1387, -3.3543, -5.1921, -6.1386, -3.3303, -4.7828, -5.7397, -5.1831, -5.4657, -5.1831, -4.7351, -5.861, -4.7047, -4.7631, -4.9944, -5.4979, -4.7336, -4.7642, -5.1831, -4.9721, -5.4578, -5.4657, -4.5636, -5.4657, -5.2829, -5.3757, -5.4459, -5.3145, -5.4033, -5.4657, -5.2316, -5.3806, -5.3372, -6.3958, -6.3958, -6.3958, -6.3958, -6.3958, -6.3958, -6.3958, -6.3958, -6.3958, -6.3958, -6.3958, -6.3959, -6.3959, -6.3959, -6.3959, -6.3959, -6.396, -6.396, -4.5846, -6.0101, -5.3372, -5.3232, -6.3958, -6.3958, -6.3958, -6.3959, -6.3959, -6.0101, -6.0102, -5.5154, -5.7325, -6.0102, -6.0102, -4.9822, -5.7325, -4.8751, -4.9385, -5.3371, -3.5753, -4.0895, -4.9384, -3.9317, -5.5154, -5.4297, -3.8024, -5.6092, -5.5029, -5.2095, -4.6153, -5.3372, -4.5515, -6.0101, -5.7325, -5.1396, -5.0978, -4.3331, -5.5152, -4.9753, -5.3656, -5.1859, -5.0799, -5.2078, -5.186, -5.186, -5.1226, -5.2909, -5.3372, -5.354, -5.9037, -5.9037, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2898, -5.6261, -5.6261, -5.9037, -5.9037, -5.9037, -5.9038, -5.9452, -5.6793, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -6.2894, -5.9037, -5.9037, -4.9942, -5.244, -5.626, -5.655, -4.5809, -5.4427, -4.6384, -3.858, -4.8321, -4.005, -5.2307, -5.2307, -4.9798, -4.7319, -4.9481, -5.409, -5.4411, -5.409, -5.4165, -4.04, -4.8785, -4.5579, -4.5927, -5.3134, -4.3834, -5.2307, -5.0212, -5.409, -5.2307, -5.409, -5.1888, -5.1421, -5.1796, -5.409, -5.409, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -6.0385, -5.6528, -5.4127, -6.0385, -6.0385, -6.0391, -6.0385, -6.0385, -6.0391, -6.0385, -6.0385, -5.6527, -5.6527, -5.6528, -6.0385, -6.0385, -6.0387, -6.0385, -6.0385, -6.0385, -6.0385, -6.0384, -5.3751, -5.3751, -4.8391, -5.3751, -5.6528, -5.6528, -5.6528, -5.6528, -5.1581, -3.8412, -4.5812, -3.7616, -4.6259, -4.5289, -4.6406, -5.2304, -4.5812, -4.999, -4.5813, -4.9798, -5.3751, -5.2782, -5.3751, -5.3751, -5.6528, -5.1581, -5.1968, -4.8372, -5.3982, -5.3751, -5.3753, -5.4412, -5.3753, -5.58, -5.6483, -6.034, -6.034, -6.034, -6.034, -6.034, -6.034, -6.034, -6.034, -6.034, -6.034, -6.034, -6.034, -6.0339, -6.0339, -6.034, -6.0339, -6.0339, -6.0342, -6.034, -5.1536, -5.3707, -6.0339, -6.0339, -6.0339, -6.034, -6.0339, -6.0339, -5.3706, -5.6482, -5.1535, -4.9753, -5.4281, -5.2698, -4.8483, -5.4627, -4.6215, -4.5937, -4.9753, -3.8063, -4.5192, -4.0838, -4.6508, -5.1535, -4.5287, -4.6951, -5.1702, -5.0794, -5.0031, -4.5314, -5.1745, -4.9754, -4.4509, -5.1535, -5.5059, -5.0627, -5.098, -5.3707, -5.3706, -5.3706, -5.3706, -5.3198, -5.3198, -5.7055, -5.7055, -5.7055, -5.7055, -5.7055, -5.7055, -5.7055, -5.7055, -5.7054, -5.7054, -5.7054, -5.7054, -5.7055, -5.0421, -4.6468, -5.3198, -6.3414, -6.3415, -6.3415, -6.3415, -6.3415, -6.3414, -6.3415, -6.3415, -6.3421, -6.3414, -6.3414, -6.3414, -5.7054, -4.571, -5.0419, -4.6642, -5.0468, -5.3197, -5.7053, -5.3197, -5.7054, -5.3197, -5.0533, -5.7053, -5.042, -4.6983, -5.0421, -4.8141, -4.3643, -4.2483, -5.0528, -4.9731, -4.3643, -5.0724, -5.042, -4.8053, -5.0422, -5.1808, -5.0935, -5.0421, -5.3197, -5.2321, -5.3197]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 7, 2, 3, 4, 5, 6, 7, 7, 3, 3, 8, 1, 2, 3, 4, 8, 2, 7, 1, 3, 8, 3, 1, 3, 2, 6, 7, 1, 3, 4, 5, 6, 7, 1, 1, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 7, 7, 1, 2, 3, 4, 5, 6, 7, 2, 3, 5, 7, 3, 1, 2, 3, 5, 6, 7, 8, 1, 5, 7, 5, 1, 1, 4, 5, 6, 7, 5, 5, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 4, 6, 7, 8, 1, 3, 4, 7, 1, 2, 4, 5, 6, 8, 8, 2, 3, 5, 1, 2, 6, 2, 2, 4, 6, 7, 1, 1, 2, 3, 5, 6, 8, 2, 3, 3, 6, 3, 1, 2, 4, 5, 6, 7, 8, 4, 6, 5, 1, 2, 3, 5, 6, 7, 8, 6, 8, 1, 2, 3, 4, 5, 7, 8, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 5, 1, 2, 7, 2, 6, 2, 5, 6, 1, 1, 2, 3, 4, 5, 7, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 2, 3, 4, 5, 6, 7, 8, 2, 3, 6, 3, 4, 6, 1, 2, 3, 4, 7, 8, 1, 4, 6, 4, 1, 2, 3, 4, 5, 6, 7, 8, 3, 5, 3, 6, 8, 1, 1, 8, 3, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 2, 7, 8, 1, 3, 4, 5, 6, 4, 7, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 6, 1, 4, 5, 2, 4, 5, 6, 4, 5, 4, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 5, 6, 1, 2, 5, 6, 8, 2, 3, 5, 7, 5, 6, 1, 2, 3, 7, 8, 1, 3, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 5, 6, 8, 1, 3, 6, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 4, 5, 6, 7, 1, 3, 4, 5, 6, 8, 1, 1, 6, 8, 1, 1, 5, 7, 1, 7, 1, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 3, 1, 2, 3, 4, 5, 6, 6, 8, 1, 2, 3, 4, 5, 7, 8, 7, 8, 1, 2, 4, 5, 6, 7, 5, 3, 6, 2, 7, 1, 4, 6, 8, 2, 4, 7, 1, 2, 3, 6, 8, 3, 1, 1, 2, 1, 2, 3, 4, 5, 6, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 3, 4, 8, 2, 3, 4, 5, 2, 3, 4, 5, 6, 7, 8, 7, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 5, 8, 8, 5, 3, 5, 3, 7, 4, 2, 1, 3, 4, 5, 6, 7, 8, 1, 6, 1, 2, 3, 4, 5, 4, 6, 7, 3, 6, 1, 3, 4, 6, 4, 2, 3, 7, 1, 1, 1, 2, 4, 1, 2, 3, 4, 6, 8, 4, 6, 1, 3, 4, 5, 6, 1, 1, 2, 8, 3, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 7, 1, 2, 3, 4, 5, 6, 3, 4, 1, 4, 6, 7, 1, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 8, 1, 2, 3, 4, 6, 7, 8, 2, 2, 4, 5, 7, 8, 1, 4, 1, 2, 4, 5, 6, 7, 8, 6, 8, 4, 6, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 4, 6, 5, 7, 3, 4, 6, 7, 6, 1, 2, 3, 4, 5, 7, 8, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 8, 2, 3, 7, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 6, 7, 1, 3, 8, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 2, 4, 5, 2, 3, 8, 2, 4, 1, 2, 3, 4, 5, 6, 8, 3, 5, 7, 8, 1, 2, 2, 7, 3, 4, 5, 5, 7, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 8, 2, 1, 4, 5, 7, 2, 3, 5, 2, 3, 4, 5, 7, 8, 2, 7, 8, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 5, 1, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 4, 4, 7, 1, 3, 4, 6, 7, 3, 5, 2, 3, 3, 3, 5, 6, 3, 4, 6, 7, 5, 6, 6, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 8, 4, 7, 1, 2, 3, 4, 8, 5, 3, 5, 4, 6, 3, 5, 1, 2, 3, 5, 6, 7, 8, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 4, 5, 1, 3, 4, 1, 1, 5, 2, 5, 7, 1, 7, 1, 3, 4, 6, 7, 8, 4, 5, 6, 8, 1, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 7, 1, 2, 5, 6, 7, 2, 2, 7, 7, 8, 2, 4, 5, 7, 8, 4, 5, 2, 3, 6, 8, 3, 1, 2, 3, 4, 5, 6, 7, 8, 8, 1, 3, 4, 5, 7, 8, 1, 2, 3, 7, 2, 3, 4, 5, 6, 7, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 2, 2, 7, 3, 5, 7, 1, 4, 6, 1, 4, 6, 6, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 1, 1, 3, 2, 2, 3, 1, 1, 1, 2, 3, 4, 5, 6, 7, 3, 1, 2, 3, 4, 5, 8, 1, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 2, 4, 6, 5, 6, 4, 6, 8, 1, 7, 8, 1, 2, 3, 4, 5, 6, 7, 3, 4, 6, 7, 2, 3, 5, 6, 7, 4, 2, 3, 6, 1, 2, 3, 4, 6, 7, 8, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 6, 2, 5, 6, 3, 4, 5, 1, 3, 4, 5, 6, 2, 2, 4, 4, 8, 5, 8, 1, 2, 3, 5, 6, 8, 1, 2, 3, 4, 5, 4, 4, 6, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 3, 1, 2, 5, 6, 7, 1, 2, 3, 6, 2, 1, 2, 3, 4, 5, 6, 7, 4, 6, 1, 3, 4, 5, 6, 7, 1, 3, 4, 1, 2, 3, 4, 6, 8, 2, 3, 4, 5, 7, 3, 1, 3, 6, 7, 8, 1, 2, 3, 4, 5, 7, 8, 1, 2, 4, 5, 6, 7, 8, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 2, 4, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 4, 5, 6, 7, 8, 3, 1, 2, 3, 5, 7, 3, 3, 4, 6, 3, 7, 2, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 5, 7, 8, 7, 8, 7, 3, 4, 5, 7, 4, 1, 2, 3, 4, 5, 6, 7, 6, 1, 3, 4, 5, 6, 8, 2, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 2, 1, 2, 3, 4, 5, 6, 8, 2, 1, 2, 3, 4, 5, 6, 7, 8, 7, 8, 7, 2, 5, 6, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 2, 2, 6, 7, 4], \"Freq\": [0.12824671114840744, 0.12824671114840744, 0.4488634890194261, 0.19237006672261117, 0.12824671114840744, 0.28071089039938046, 0.1122843561597522, 0.1122843561597522, 0.1122843561597522, 0.1684265342396283, 0.2245687123195044, 0.810319803025283, 0.8657934219540018, 0.7720467207966407, 0.8533111582921139, 0.08879126366647003, 0.5327475819988201, 0.08879126366647003, 0.17758252733294005, 0.08879126366647003, 0.2983759046912444, 0.5967518093824888, 0.8556437099327113, 0.7857462600765925, 0.19643656501914813, 0.8657940171028891, 0.6848310352039729, 0.22827701173465764, 0.20089730636417108, 0.6026919190925133, 0.20089730636417108, 0.312444650019541, 0.07811116250488526, 0.07811116250488526, 0.312444650019541, 0.07811116250488526, 0.1562223250097705, 0.7639664014056774, 0.7639664014056774, 0.4100731767883771, 0.4100731767883771, 0.13713892370250283, 0.21942227792400454, 0.0822833542215017, 0.1645667084430034, 0.13713892370250283, 0.0822833542215017, 0.054855569481001135, 0.10971113896200227, 0.8103236881722814, 0.8103236881722814, 0.23184596528963902, 0.23184596528963902, 0.1324834087369366, 0.09936255655270243, 0.09936255655270243, 0.0662417043684683, 0.09936255655270243, 0.19251213769595937, 0.5775364130878782, 0.09625606884797969, 0.09625606884797969, 0.7720478642280014, 0.07327620603991745, 0.1465524120798349, 0.3663810301995873, 0.21982861811975235, 0.07327620603991745, 0.07327620603991745, 0.07327620603991745, 0.2379645280859176, 0.2379645280859176, 0.4759290561718352, 0.7894618358046479, 0.7639663990910147, 0.2954526742830677, 0.09848422476102257, 0.19696844952204515, 0.09848422476102257, 0.2954526742830677, 0.7894617458336751, 0.7894617458336751, 0.7720528580211633, 0.08313919922811146, 0.16627839845622291, 0.08313919922811146, 0.4156959961405573, 0.08313919922811146, 0.08313919922811146, 0.08313919922811146, 0.22165345206317139, 0.07388448402105713, 0.07388448402105713, 0.22165345206317139, 0.07388448402105713, 0.07388448402105713, 0.22165345206317139, 0.07388448402105713, 0.09070823998203842, 0.27212471994611526, 0.22677059995509607, 0.13606235997305763, 0.22677059995509607, 0.04535411999101921, 0.855643709854224, 0.195465379770787, 0.586396139312361, 0.195465379770787, 0.12364518474536311, 0.18546777711804466, 0.30911296186340775, 0.061822592372681555, 0.18546777711804466, 0.061822592372681555, 0.8533101124059238, 0.19466151864100043, 0.19466151864100043, 0.5839845559230012, 0.22901286007610125, 0.572532150190253, 0.11450643003805062, 0.7668478525136544, 0.7668478525136544, 0.5935104699702944, 0.19783682332343147, 0.19783682332343147, 0.763966399563764, 0.07815879167459445, 0.1563175833491889, 0.23447637502378335, 0.3126351666983778, 0.07815879167459445, 0.07815879167459445, 0.6871448635120697, 0.22904828783735656, 0.7720478654890007, 0.8104219828237409, 0.7720478641030075, 0.07014629607197376, 0.21043888821592127, 0.21043888821592127, 0.07014629607197376, 0.28058518428789503, 0.14029259214394751, 0.07014629607197376, 0.7794453317721481, 0.810421982939912, 0.7894618360322718, 0.12522956016443368, 0.18784434024665053, 0.12522956016443368, 0.12522956016443368, 0.37568868049330106, 0.06261478008221684, 0.06261478008221684, 0.6213079445008058, 0.3106539722504029, 0.1335736240294452, 0.2671472480588904, 0.222622706715742, 0.0890490826862968, 0.1780981653725936, 0.0445245413431484, 0.0445245413431484, 0.5976294936220973, 0.29881474681104864, 0.18798483848085396, 0.12163724842878786, 0.2432744968575757, 0.13822414594180438, 0.09399241924042698, 0.09399241924042698, 0.0884634534027548, 0.03317379502603305, 0.2944995989250755, 0.588999197850151, 0.7894618358049619, 0.235868336284857, 0.235868336284857, 0.471736672569714, 0.8592598530822075, 0.8104219830183397, 0.17140784185518365, 0.17140784185518365, 0.514223525565551, 0.7639663993057523, 0.16392240791590298, 0.08196120395795149, 0.16392240791590298, 0.16392240791590298, 0.16392240791590298, 0.16392240791590298, 0.12294180593692725, 0.8533101124059238, 0.04271976634298846, 0.3417581307439077, 0.08543953268597693, 0.04271976634298846, 0.1281592990289654, 0.1281592990289654, 0.08543953268597693, 0.2135988317149423, 0.7668478523020983, 0.1979278513794128, 0.06597595045980427, 0.2639038018392171, 0.1979278513794128, 0.06597595045980427, 0.13195190091960854, 0.13195190091960854, 0.7668477532305316, 0.7012260544833298, 0.2337420181611099, 0.1954710740161248, 0.5864132220483743, 0.1954710740161248, 0.3857370861940966, 0.15429483447763864, 0.07714741723881932, 0.23144225171645794, 0.07714741723881932, 0.07714741723881932, 0.19494878081167427, 0.5848463424350229, 0.19494878081167427, 0.7794474141807075, 0.08387497361256903, 0.22366659630018407, 0.16774994722513806, 0.08387497361256903, 0.27958324537523005, 0.02795832453752301, 0.08387497361256903, 0.05591664907504602, 0.23488210225965728, 0.7046463067789719, 0.7720504833147209, 0.4156569913651391, 0.4156569913651391, 0.7639663994228247, 0.4854078426510306, 0.4854078426510306, 0.47425059670324404, 0.47425059670324404, 0.17779696980642942, 0.2666954547096441, 0.17779696980642942, 0.13334772735482206, 0.08889848490321471, 0.08889848490321471, 0.08889848490321471, 0.1787614779969964, 0.14300918239759713, 0.07150459119879857, 0.14300918239759713, 0.25026606919579497, 0.10725688679819785, 0.035752295599399284, 0.10725688679819785, 0.24749860493800901, 0.24749860493800901, 0.49499720987601803, 0.1481059343473098, 0.1481059343473098, 0.1481059343473098, 0.1481059343473098, 0.44431780304192936, 0.30026703385008646, 0.6005340677001729, 0.12084617517303375, 0.2416923503460675, 0.36253852551910126, 0.2416923503460675, 0.2990015242590299, 0.24916793688252492, 0.19933434950601994, 0.09966717475300997, 0.09966717475300997, 0.049833587376504986, 0.653274180476052, 0.163318545119013, 0.163318545119013, 0.25943180004728383, 0.25943180004728383, 0.08192583159387912, 0.09558013685952563, 0.13654305265646519, 0.09558013685952563, 0.04096291579693956, 0.027308610531293038, 0.810421982988503, 0.8808128128432742, 0.29449945977971836, 0.5889989195594367, 0.2501116536742364, 0.2501116536742364, 0.33348220489898184, 0.08337055122474546, 0.23576357068520018, 0.7072907120556006, 0.7794449914063205, 0.294499393819441, 0.588998787638882, 0.07998947791355479, 0.19997369478388696, 0.11998421687033217, 0.31995791165421916, 0.19997369478388696, 0.07998947791355479, 0.2103776751505949, 0.5259441878764873, 0.10518883757529746, 0.2103776751505949, 0.5285716589333065, 0.21142866357332257, 0.10571433178666129, 0.10571433178666129, 0.10571433178666129, 0.23650797281352096, 0.23650797281352096, 0.11825398640676048, 0.3547619592202814, 0.3017755292406387, 0.6035510584812774, 0.1723208666022218, 0.1723208666022218, 0.1723208666022218, 0.1723208666022218, 0.3446417332044436, 0.1801152843358611, 0.3602305686717222, 0.3602305686717222, 0.09005764216793055, 0.2505989252063904, 0.1156610424029494, 0.038553680800983134, 0.21204524440540726, 0.1156610424029494, 0.0578305212014747, 0.15421472320393254, 0.0578305212014747, 0.7639663991729866, 0.26699842689973463, 0.26699842689973463, 0.400497640349602, 0.13349921344986732, 0.23637482486616043, 0.23637482486616043, 0.47274964973232086, 0.18039783656534544, 0.27059675484801815, 0.45099459141336357, 0.09019891828267272, 0.26464582133521114, 0.1543767291122065, 0.19848436600140837, 0.08821527377840371, 0.04410763688920186, 0.04410763688920186, 0.1543767291122065, 0.06616145533380278, 0.18262462370470942, 0.09131231185235471, 0.18262462370470942, 0.09131231185235471, 0.09131231185235471, 0.36524924740941883, 0.43660764365233085, 0.0727679406087218, 0.0727679406087218, 0.21830382182616542, 0.0727679406087218, 0.0727679406087218, 0.8556437099842507, 0.7639663992372188, 0.4156568263276163, 0.4156568263276163, 0.8556437098295289, 0.7639663990787502, 0.7894614188551056, 0.810323687828839, 0.768096060749899, 0.19202401518747475, 0.7639663989740222, 0.268614306042576, 0.268614306042576, 0.402921459063864, 0.18175355652639053, 0.22719194565798817, 0.1363151673947929, 0.04543838913159763, 0.1363151673947929, 0.04543838913159763, 0.09087677826319526, 0.1363151673947929, 0.7720478642069553, 0.3823744947847684, 0.1911872473923842, 0.06372908246412808, 0.2549163298565123, 0.06372908246412808, 0.06372908246412808, 0.41565681532406573, 0.41565681532406573, 0.3368718795982633, 0.181392550552911, 0.10365288603023486, 0.05182644301511743, 0.07773966452267614, 0.181392550552911, 0.05182644301511743, 0.4156310557544434, 0.4156310557544434, 0.18669630098067772, 0.06223210032689257, 0.12446420065378513, 0.31116050163446285, 0.18669630098067772, 0.12446420065378513, 0.887753879443625, 0.2991895887336351, 0.5983791774672702, 0.7710089947291981, 0.19275224868229954, 0.15049248777766427, 0.30098497555532855, 0.4514774633329928, 0.15049248777766427, 0.2373231208495774, 0.2373231208495774, 0.4746462416991548, 0.12961573026547651, 0.45365505592916777, 0.25923146053095303, 0.06480786513273826, 0.12961573026547651, 0.772047308494823, 0.9102608055910223, 0.8556437098342116, 0.8592597575228935, 0.324229010371044, 0.0997627724218597, 0.14964415863278954, 0.04988138621092985, 0.0997627724218597, 0.17458485173825447, 0.07482207931639477, 0.8533111578008377, 0.032835008541211845, 0.16417504270605923, 0.2955150768709066, 0.16417504270605923, 0.032835008541211845, 0.09850502562363553, 0.09850502562363553, 0.09850502562363553, 0.6462058766142197, 0.05351781720819584, 0.21407126883278335, 0.05351781720819584, 0.4281425376655667, 0.05351781720819584, 0.10703563441639168, 0.05351781720819584, 0.10703563441639168, 0.24506564685882776, 0.24506564685882776, 0.4901312937176555, 0.23057352298553435, 0.4035036652246851, 0.17293014223915076, 0.17293014223915076, 0.7668478532527262, 0.16160817922381931, 0.08080408961190966, 0.32321635844763863, 0.16160817922381931, 0.08080408961190966, 0.16160817922381931, 0.8103236881578344, 0.06210991463973386, 0.3105495731986693, 0.24843965855893543, 0.12421982927946772, 0.18632974391920157, 0.06210991463973386, 0.07598246267708754, 0.6838421640937878, 0.07598246267708754, 0.15196492535417508, 0.7794428358660327, 0.10608396922812136, 0.2121679384562427, 0.17680661538020226, 0.2121679384562427, 0.10608396922812136, 0.03536132307604045, 0.0707226461520809, 0.0707226461520809, 0.24286997477800962, 0.24286997477800962, 0.12143498738900481, 0.3643049621670144, 0.6462086452887134, 0.7894618358518651, 0.7713825502620613, 0.19284563756551532, 0.5847010214847455, 0.19490034049491514, 0.7794453314009978, 0.7668478533064047, 0.21512704336771535, 0.21512704336771535, 0.08605081734708614, 0.04302540867354307, 0.1290762260206292, 0.1290762260206292, 0.21512704336771535, 0.2979681943263885, 0.595936388652777, 0.44378325303185695, 0.06339760757597956, 0.25359043030391826, 0.12679521515195913, 0.06339760757597956, 0.2017525780972154, 0.6052577342916461, 0.2017525780972154, 0.2991954052751632, 0.5983908105503264, 0.06132011610704117, 0.12264023221408234, 0.6745212771774528, 0.12264023221408234, 0.7794453315133117, 0.23663291350599458, 0.23663291350599458, 0.47326582701198916, 0.7639663993057523, 0.7639663993057523, 0.2283317256360765, 0.6849951769082295, 0.7794453314701065, 0.08471232078973794, 0.08471232078973794, 0.08471232078973794, 0.42356160394868964, 0.16942464157947587, 0.08471232078973794, 0.5918717658940139, 0.29593588294700696, 0.4109393336239291, 0.06848988893732151, 0.13697977787464302, 0.13697977787464302, 0.20546966681196455, 0.7639663995231409, 0.4428039151063183, 0.29520261007087883, 0.29520261007087883, 0.7720478644320922, 0.6969347702535891, 0.2323115900845297, 0.20210800797499628, 0.23579267597082898, 0.1852656739770799, 0.13473867198333084, 0.08421166998958178, 0.03368466799583271, 0.08421166998958178, 0.05052700199374907, 0.8103236879109281, 0.7639663991791071, 0.766848059356038, 0.41794119866268314, 0.08358823973253662, 0.2507647191976099, 0.16717647946507325, 0.6932809716987308, 0.23109365723291028, 0.2337663952154937, 0.4675327904309874, 0.11688319760774685, 0.11688319760774685, 0.5048283029879521, 0.18029582249569717, 0.036059164499139436, 0.1081774934974183, 0.07211832899827887, 0.036059164499139436, 0.036059164499139436, 0.16227457714616103, 0.24341186571924153, 0.08113728857308052, 0.08113728857308052, 0.08113728857308052, 0.40568644286540256, 0.3028317346618311, 0.3028317346618311, 0.15141586733091555, 0.12113269386473245, 0.09084952039854934, 0.030283173466183113, 0.030283173466183113, 0.766848163441185, 0.0712064023472446, 0.1424128046944892, 0.4984448164307122, 0.0712064023472446, 0.2136192070417338, 0.7639663994839256, 0.7794453316837724, 0.11730965093847505, 0.35192895281542513, 0.11730965093847505, 0.15641286791796674, 0.11730965093847505, 0.07820643395898337, 0.07820643395898337, 0.4156568263276163, 0.4156568263276163, 0.5918718840555087, 0.29593594202775436, 0.5918718840555088, 0.2959359420277544, 0.17328467041484208, 0.25030007948810523, 0.07701540907326314, 0.1347769658782105, 0.03850770453663157, 0.15403081814652628, 0.1347769658782105, 0.05776155680494736, 0.3002936870507609, 0.6005873741015219, 0.5976028098925731, 0.29880140494628654, 0.17149430338222454, 0.17149430338222454, 0.5144829101466736, 0.17149430338222454, 0.8104219826919525, 0.04675312092403698, 0.3272718464682589, 0.18701248369614792, 0.18701248369614792, 0.04675312092403698, 0.14025936277211096, 0.09350624184807396, 0.8103236881044448, 0.1079711923433134, 0.1079711923433134, 0.1079711923433134, 0.1079711923433134, 0.1079711923433134, 0.3239135770299402, 0.1079711923433134, 0.15040124187865986, 0.07520062093932993, 0.15040124187865986, 0.15040124187865986, 0.15040124187865986, 0.15040124187865986, 0.22560186281798977, 0.25647295045380536, 0.5129459009076107, 0.12823647522690268, 0.7668481656803838, 0.22749611658455735, 0.22749611658455735, 0.056874029146139336, 0.170622087438418, 0.085311043719209, 0.056874029146139336, 0.11374805829227867, 0.056874029146139336, 0.10770278140034366, 0.35900927133447885, 0.39491019846792674, 0.07180185426689577, 0.07180185426689577, 0.40042238908673833, 0.20021119454336916, 0.40042238908673833, 0.8533111578710334, 0.07844983405113509, 0.3216443196096539, 0.05491488383579456, 0.1725896349124972, 0.15689966810227018, 0.12551973448181614, 0.06275986724090807, 0.031379933620454034, 0.9509371751022961, 0.7668478525953637, 0.23576357068520018, 0.7072907120556006, 0.5811162661125934, 0.14527906652814834, 0.14527906652814834, 0.7668478537083153, 0.8312809164393007, 0.1233511563914106, 0.2467023127828212, 0.1233511563914106, 0.0616755781957053, 0.3083778909785265, 0.1233511563914106, 0.0616755781957053, 0.7720468279750867, 0.7894618359681593, 0.41561852718786746, 0.41561852718786746, 0.6492527136559072, 0.3246263568279536, 0.6969108963254425, 0.23230363210848082, 0.3171060354435292, 0.422808047258039, 0.2114040236290195, 0.5954044102870977, 0.19846813676236588, 0.8877538794014258, 0.19160017175850724, 0.06386672391950242, 0.2554668956780097, 0.5109337913560194, 0.810322148607112, 0.18855320680114834, 0.15084256544091867, 0.2639744895216077, 0.07542128272045934, 0.15084256544091867, 0.113131924080689, 0.07542128272045934, 0.7668479449302211, 0.23155696120475694, 0.5788924030118924, 0.11577848060237847, 0.8103236881528374, 0.42921926543705635, 0.5722923539160751, 0.789461835992073, 0.10086462274532737, 0.20172924549065474, 0.10086462274532737, 0.10086462274532737, 0.20172924549065474, 0.20172924549065474, 0.2474982861315255, 0.2474982861315255, 0.494996572263051, 0.7720478642790298, 0.19656098041299377, 0.5896829412389814, 0.1692543939812579, 0.12089599570089851, 0.2659711905419767, 0.1450751948410782, 0.2176127922616173, 0.0483583982803594, 0.0483583982803594, 0.7894617455534804, 0.15949282464294087, 0.15949282464294087, 0.4253141990478423, 0.053164274880980286, 0.053164274880980286, 0.10632854976196057, 0.053164274880980286, 0.12633033511303643, 0.18949550266955464, 0.15791291889129555, 0.22107808644781377, 0.06316516755651821, 0.15791291889129555, 0.06316516755651821, 0.7794485433834707, 0.5918459670169235, 0.29592298350846175, 0.36833270710326915, 0.07366654142065383, 0.14733308284130767, 0.07366654142065383, 0.36833270710326915, 0.2934372423500343, 0.5868744847000686, 0.32753935260950634, 0.6550787052190127, 0.9217562889517107, 0.8657940171028891, 0.30176833841855516, 0.6035366768371103, 0.2982578666576517, 0.14912893332882585, 0.4473867999864775, 0.14912893332882585, 0.2423083224115098, 0.7269249672345294, 0.8104219830032431, 0.32487173648685663, 0.12994869459474265, 0.12994869459474265, 0.19492304189211399, 0.2598973891894853, 0.7639663991249083, 0.24912024374649275, 0.06228006093662319, 0.24912024374649275, 0.24912024374649275, 0.12456012187324637, 0.12456012187324637, 0.8533111571149308, 0.5918452704761071, 0.29592263523805357, 0.4604623019827015, 0.07674371699711692, 0.23023115099135075, 0.15348743399423384, 0.07674371699711692, 0.7894618358417796, 0.29343714704039, 0.58687429408078, 0.779445331452694, 0.8104219830147129, 0.23508217023382325, 0.7052465107014697, 0.12554204132590718, 0.12554204132590718, 0.18831306198886075, 0.25108408265181437, 0.12554204132590718, 0.06277102066295359, 0.12554204132590718, 0.6212497257505544, 0.3106248628752772, 0.24032800494443665, 0.1502050030902729, 0.0976332520086774, 0.232817754789923, 0.1351845027812456, 0.01502050030902729, 0.09012300185416375, 0.045061500927081874, 0.7794453318023252, 0.7894512082174346, 0.6848434738973425, 0.2282811579657808, 0.7794428358660335, 0.8556493386478861, 0.6893269137460012, 0.2297756379153337, 0.7668477531299489, 0.7155379768696627, 0.23851265895655424, 0.297941320196514, 0.595882640393028, 0.1611117744924849, 0.2685196241541415, 0.2148156993233132, 0.1074078496616566, 0.0537039248308283, 0.1074078496616566, 0.3087119564726297, 0.15435597823631486, 0.15435597823631486, 0.3087119564726297, 0.1080105289183578, 0.1080105289183578, 0.2160210578367156, 0.1080105289183578, 0.1080105289183578, 0.32403158675507343, 0.3307267006827365, 0.22048446712182435, 0.055121116780456086, 0.16536335034136826, 0.055121116780456086, 0.16536335034136826, 0.15463559654702078, 0.46390678964106236, 0.15463559654702078, 0.15463559654702078, 0.07731779827351039, 0.7668478527498616, 0.7668478522206942, 0.8103236880224569, 0.6212504027427534, 0.3106252013713767, 0.5351038632766969, 0.10702077265533937, 0.10702077265533937, 0.21404154531067873, 0.10702077265533937, 0.2944993433800537, 0.5889986867601074, 0.14691506323893183, 0.5142027213362614, 0.14691506323893183, 0.14691506323893183, 0.7720472288985728, 0.09879011703547001, 0.29637035110641, 0.09879011703547001, 0.09879011703547001, 0.148185175553205, 0.09879011703547001, 0.049395058517735006, 0.148185175553205, 0.8533111571149308, 0.10087818831403532, 0.20175637662807064, 0.10087818831403532, 0.20175637662807064, 0.20175637662807064, 0.20175637662807064, 0.1664711116578973, 0.41617777914474324, 0.08323555582894865, 0.3329422233157946, 0.17533998562827116, 0.23378664750436154, 0.17533998562827116, 0.29223330938045194, 0.11689332375218077, 0.058446661876090385, 0.7668541214259796, 0.8657940171604042, 0.17297594046724402, 0.1383807523737952, 0.17297594046724402, 0.1383807523737952, 0.0345951880934488, 0.17297594046724402, 0.10378556428034641, 0.0691903761868976, 0.7668632249243282, 0.29837868504874093, 0.5967573700974819, 0.19734916929159788, 0.5920475078747937, 0.19734916929159788, 0.23706324801923298, 0.23706324801923298, 0.47412649603846596, 0.31610923156987225, 0.5268487192831204, 0.10536974385662408, 0.810421982978489, 0.36537412752053844, 0.1701742511739494, 0.22523062655375656, 0.07007175048339093, 0.060061500414335084, 0.030030750207167542, 0.04004100027622339, 0.03503587524169546, 0.19146683389838726, 0.765867335593549, 0.763966399202248, 0.22971387503791854, 0.6891416251137555, 0.7668478527498616, 0.7668475155263907, 0.7720521897868429, 0.763966399563764, 0.7639663995238168, 0.24583641608709217, 0.24583641608709217, 0.16901253605987587, 0.18437731206531913, 0.03072955201088652, 0.01536477600544326, 0.12291820804354608, 0.7720473085691696, 0.0763626505519271, 0.22908795165578133, 0.5345385538634897, 0.1527253011038542, 0.41007340167444795, 0.41007340167444795, 0.3327383724812139, 0.49910755872182083, 0.4156567822459763, 0.4156567822459763, 0.09671585850138323, 0.19343171700276646, 0.09671585850138323, 0.3868634340055329, 0.09671585850138323, 0.09671585850138323, 0.415630746956604, 0.415630746956604, 0.2911146348064858, 0.5822292696129716, 0.1455573174032429, 0.4807988713353226, 0.4807988713353226, 0.24502394734929056, 0.4900478946985811, 0.24502394734929056, 0.24719714425659878, 0.24719714425659878, 0.49439428851319756, 0.034374746943187956, 0.27499797554550365, 0.17187373471593978, 0.06874949388637591, 0.27499797554550365, 0.10312424082956387, 0.06874949388637591, 0.14831913419419634, 0.44495740258258903, 0.44495740258258903, 0.8103236880415041, 0.13141277684632086, 0.13141277684632086, 0.39423833053896257, 0.13141277684632086, 0.13141277684632086, 0.7794455187610855, 0.659807750965652, 0.164951937741413, 0.164951937741413, 0.3102846430789057, 0.15514232153945284, 0.05171410717981761, 0.05171410717981761, 0.05171410717981761, 0.20685642871927043, 0.15514232153945284, 0.8657966237804561, 0.11103244823056342, 0.15544542752278878, 0.24427138610723953, 0.06661946893833806, 0.13323893787667612, 0.15544542752278878, 0.11103244823056342, 0.04441297929222537, 0.7639664000487975, 0.2979684027146501, 0.5959368054293002, 0.23825963266375288, 0.23825963266375288, 0.47651926532750577, 0.3486019056852312, 0.4648025409136416, 0.2324012704568208, 0.4788741039998278, 0.19154964159993113, 0.09577482079996556, 0.09577482079996556, 0.09577482079996556, 0.9509368992857827, 0.6890850838348556, 0.22969502794495184, 0.7794453314168839, 0.8533083509577024, 0.4100735554348325, 0.4100735554348325, 0.18443658882937258, 0.18443658882937258, 0.307394314715621, 0.1229577258862484, 0.1229577258862484, 0.0614788629431242, 0.3535516923568828, 0.0883879230892207, 0.0883879230892207, 0.3535516923568828, 0.0883879230892207, 0.77944354513015, 0.5935108846171439, 0.19783696153904795, 0.19783696153904795, 0.19000967655271928, 0.7600387062108771, 0.8657937894000507, 0.03954232378865101, 0.11862697136595303, 0.19771161894325504, 0.03954232378865101, 0.27679626652055705, 0.11862697136595303, 0.15816929515460404, 0.07908464757730202, 0.7720468279762567, 0.4086569188221663, 0.20432845941108316, 0.20432845941108316, 0.06810948647036105, 0.1362189729407221, 0.20984190694426058, 0.41968381388852116, 0.10492095347213029, 0.20984190694426058, 0.766847980343378, 0.22678186590656293, 0.17342142686972462, 0.06670054879604792, 0.24012197566577254, 0.13340109759209584, 0.0933807683144671, 0.05336043903683834, 0.7073249812119408, 0.2357749937373136, 0.4816960675184742, 0.09633921350369484, 0.09633921350369484, 0.09633921350369484, 0.09633921350369484, 0.09633921350369484, 0.16420419734371755, 0.6568167893748702, 0.16420419734371755, 0.2097311996897739, 0.36702959945710434, 0.15729839976733043, 0.10486559984488696, 0.10486559984488696, 0.05243279992244348, 0.4151958830308835, 0.0830391766061767, 0.0830391766061767, 0.2491175298185301, 0.1660783532123534, 0.7720478646715511, 0.1513194460021858, 0.1513194460021858, 0.1513194460021858, 0.4539583380065574, 0.1513194460021858, 0.052967298095624754, 0.3178037885737485, 0.15890189428687426, 0.3178037885737485, 0.052967298095624754, 0.052967298095624754, 0.052967298095624754, 0.32679665309912775, 0.13071866123965112, 0.16339832654956388, 0.06535933061982556, 0.03267966530991278, 0.16339832654956388, 0.09803899592973833, 0.7794455187726698, 0.11796728499201843, 0.11796728499201843, 0.23593456998403686, 0.11796728499201843, 0.3539018549760553, 0.1042700925658308, 0.07820256942437309, 0.2867427545560347, 0.1303376157072885, 0.1824726619902039, 0.1042700925658308, 0.07820256942437309, 0.0521350462829154, 0.8556444956672673, 0.23137993123526626, 0.4627598624705325, 0.11568996561763313, 0.11568996561763313, 0.21470770858010402, 0.23856412064456003, 0.09542564825782401, 0.14313847238673602, 0.09542564825782401, 0.07156923619336801, 0.04771282412891201, 0.09542564825782401, 0.29480515489832027, 0.09826838496610675, 0.14740257744916013, 0.14740257744916013, 0.049134192483053375, 0.14740257744916013, 0.09826838496610675, 0.7720478644323123, 0.15419099904179415, 0.07709549952089707, 0.5396684966462795, 0.07709549952089707, 0.15419099904179415, 0.7720528580700455, 0.23783571925114125, 0.23783571925114125, 0.4756714385022825, 0.474249191470231, 0.474249191470231, 0.7668477530829267, 0.20176854691772717, 0.30265282037659075, 0.15132641018829537, 0.10088427345886358, 0.15132641018829537, 0.10088427345886358, 0.24584350579911823, 0.14048200331378186, 0.21072300497067278, 0.14048200331378186, 0.1756025041422273, 0.07024100165689093, 0.7639663995194379, 0.1101268689915183, 0.3303806069745549, 0.4405074759660732, 0.1101268689915183, 0.6212502608210704, 0.3106251304105352, 0.9142189656073888, 0.13174243562894652, 0.13174243562894652, 0.39522730688683955, 0.26348487125789305, 0.7794453318245539, 0.2616411700684352, 0.08721372335614505, 0.08721372335614505, 0.08721372335614505, 0.08721372335614505, 0.1308205850342176, 0.2616411700684352, 0.8104213655790498, 0.15087785404975496, 0.15087785404975496, 0.15087785404975496, 0.15087785404975496, 0.15087785404975496, 0.3017557080995099, 0.4322602913281741, 0.5763470551042321, 0.20323802204429722, 0.20323802204429722, 0.1524285165332229, 0.10161901102214861, 0.050809505511074306, 0.20323802204429722, 0.10161901102214861, 0.22833207335077466, 0.684996220052324, 0.7668478531389955, 0.364491081580763, 0.16567776435489226, 0.09940665861293536, 0.13254221148391382, 0.09940665861293536, 0.09940665861293536, 0.06627110574195691, 0.8592598527020342, 0.1475965604609338, 0.2213948406914007, 0.0737982802304669, 0.12299713371744483, 0.0737982802304669, 0.17219598720442275, 0.17219598720442275, 0.04919885348697793, 0.4156310191503346, 0.4156310191503346, 0.810323688112773, 0.23825970856887346, 0.23825970856887346, 0.4765194171377469, 0.7668476677836439, 0.2743997630562922, 0.24391090049448197, 0.09146658768543074, 0.1524443128090512, 0.09146658768543074, 0.030488862561810246, 0.06097772512362049, 0.06097772512362049, 0.6848302329013692, 0.2282767443004564, 0.7668478525603751, 0.13264914101108527, 0.13264914101108527, 0.15917896921330232, 0.15917896921330232, 0.2387684538199535, 0.10611931280886822, 0.026529828202217054, 0.026529828202217054, 0.05545227947250863, 0.2772613973625431, 0.3881659563075604, 0.05545227947250863, 0.05545227947250863, 0.05545227947250863, 0.11090455894501726, 0.7668478529165511, 0.2401254219209304, 0.4802508438418608, 0.2401254219209304, 0.7794453318749315], \"Term\": [\"academic\", \"academic\", \"academic\", \"academic\", \"academic\", \"accessible\", \"accessible\", \"accessible\", \"accessible\", \"accessible\", \"accessible\", \"accessible people\", \"actual\", \"actual research\", \"afford attend\", \"affordable\", \"affordable\", \"affordable\", \"affordable\", \"affordable\", \"agile\", \"agile\", \"aimed\", \"america\", \"america\", \"america europe\", \"analysis\", \"analysis\", \"andor\", \"andor\", \"andor\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"art\", \"art gathering\", \"associated\", \"associated\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend\", \"attend uxr\", \"attend uxr conference\", \"attendee\", \"attendee\", \"attendee\", \"attendee\", \"attendee\", \"attendee\", \"attendee\", \"attending\", \"attending\", \"attending\", \"attending\", \"attending conference\", \"audience\", \"audience\", \"audience\", \"audience\", \"audience\", \"audience\", \"audience\", \"balance\", \"balance\", \"balance\", \"bar\", \"base\", \"basic\", \"basic\", \"basic\", \"basic\", \"basic\", \"bay\", \"bay area\", \"benefit\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"biggest challenge\", \"bit\", \"bit\", \"bit\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"bringing\", \"broad\", \"broad\", \"broad\", \"building\", \"building\", \"building\", \"building research\", \"building research practice\", \"bunch\", \"bunch\", \"bunch\", \"careful\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"channel\", \"channel\", \"check\", \"city conference\", \"coaching\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come mind\", \"come new\", \"communicate\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community conference\", \"community conference\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"company\", \"concept\", \"concept\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference\", \"conference consider\", \"conference consider\", \"conference especially\", \"conference feel\", \"conference feel\", \"conference feel\", \"conference make\", \"conference went\", \"connect\", \"connect\", \"connect\", \"consent\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider bringing\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"content\", \"context\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost don\", \"country\", \"country\", \"couple\", \"couple\", \"couple\", \"create\", \"create\", \"create\", \"create\", \"create\", \"create\", \"data\", \"data\", \"data\", \"date\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day conference\", \"day conference\", \"day workshop\", \"decent\", \"decent\", \"define research\", \"definitely\", \"definitely\", \"degree\", \"degree\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different level\", \"different level\", \"different level\", \"digital\", \"digital\", \"digital\", \"digital\", \"digital\", \"discounted\", \"discounted\", \"diverse\", \"diverse\", \"diverse\", \"diverse\", \"doing\", \"doing\", \"doing\", \"doing\", \"doing\", \"doing\", \"doing research\", \"doing research\", \"doing research\", \"don\", \"don\", \"don\", \"don\", \"don\", \"don\", \"don\", \"don\", \"don forget\", \"don know\", \"don let\", \"don let\", \"don make\", \"don make\", \"don make\", \"don make\", \"don make expensive\", \"don make expensive\", \"don make people\", \"don want\", \"don want\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"easy\", \"easy\", \"easy\", \"easy\", \"end\", \"end\", \"end\", \"end\", \"end\", \"engage\", \"engage\", \"engage\", \"engage\", \"engaged\", \"engaged\", \"ensure\", \"ensure\", \"ensure\", \"ensure\", \"ensure\", \"europe\", \"europe\", \"europe\", \"europe\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event good\", \"example\", \"example\", \"example\", \"example\", \"exchange\", \"exchange\", \"exchange\", \"expensive\", \"expensive\", \"expensive\", \"expensive\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experienced\", \"experienced\", \"experienced\", \"experienced\", \"experienced\", \"experienced\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert field\", \"expert research\", \"expertise\", \"expertise\", \"explore\", \"exploring\", \"extra\", \"famous people\", \"far\", \"far\", \"fascinating\", \"feedback\", \"feedback\", \"feedback\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"felt\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"fluff\", \"fluff\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus\", \"focus sharing\", \"focus sharing\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food\", \"food option\", \"forget\", \"forget\", \"forward\", \"forward\", \"free\", \"free\", \"free\", \"free\", \"freelancer\", \"freelancer\", \"freelancer\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"gain\", \"gathering\", \"generative\", \"global\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good mix\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great idea\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"guide\", \"guide\", \"guide\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha lot\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"happy\", \"having\", \"having\", \"having\", \"having\", \"having\", \"having\", \"hear\", \"hear\", \"hear\", \"hear\", \"hearing\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"high\", \"high\", \"high\", \"high\", \"high quality\", \"highlight\", \"hold\", \"hold\", \"hotel\", \"hotel\", \"human\", \"id love\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"ideation\", \"ideation\", \"include\", \"include\", \"include\", \"include\", \"include\", \"inclusive\", \"inclusive\", \"inclusive\", \"individual\", \"individual\", \"industry\", \"industry\", \"industry\", \"industry\", \"industry make\", \"info\", \"info\", \"info\", \"informed\", \"informed consent\", \"innovation\", \"innovation\", \"innovative\", \"insight\", \"insight\", \"insight\", \"insight\", \"insight\", \"insight\", \"inspiring\", \"inspiring\", \"interested\", \"interested\", \"interested\", \"interested\", \"interested\", \"internal\", \"invite\", \"invite\", \"invite\", \"isnt\", \"junior\", \"junior\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just\", \"just big\", \"just doing\", \"justify\", \"keynote\", \"keynote\", \"keynote\", \"keynote\", \"keynote speaker\", \"keynote speaker\", \"kind\", \"kind\", \"kind\", \"kind\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn best\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"led\", \"let people\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level expertise\", \"level expertise\", \"lightning\", \"lightning\", \"lightning talk\", \"lightning talk\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like conference\", \"like conference\", \"listening\", \"listening\", \"little\", \"little\", \"little\", \"little\", \"ll come\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location year\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"looking\", \"looking\", \"looking\", \"looking forward\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"major\", \"major\", \"major\", \"major research\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make affordable\", \"make easy\", \"make expensive\", \"make expensive\", \"make fun\", \"make fun\", \"make fun\", \"make money\", \"make people\", \"make sure\", \"make sure\", \"make sure\", \"make sure\", \"make sure\", \"make sure\", \"make sure\", \"make sure presenter\", \"make virtual\", \"make work\", \"make work\", \"making\", \"making\", \"manager\", \"manager\", \"material\", \"material\", \"material\", \"maturity\", \"maturity\", \"maturity level\", \"maybe\", \"maybe\", \"maybe\", \"maybe\", \"meeting\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"microphone\", \"mind\", \"mind\", \"mind\", \"mingle\", \"minute\", \"minute\", \"mix theory\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple location\", \"multiple location\", \"multiple location\", \"multitrack\", \"near\", \"near\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need travel\", \"networking\", \"networking\", \"networking\", \"networking\", \"networking\", \"networking\", \"networking\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new thing\", \"newbie\", \"newbie\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nicely\", \"nicely\", \"north\", \"north\", \"north america\", \"north america europe\", \"note\", \"note\", \"offering\", \"offering\", \"offering\", \"offering\", \"oh\", \"oh\", \"online conference\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"ops research\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option purchase\", \"organizing\", \"organizing\", \"outside\", \"outside\", \"outside\", \"outside\", \"outside\", \"overly\", \"paid\", \"paid\", \"pair\", \"panel workshop\", \"past\", \"past\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"paying\", \"paying\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people chance\", \"people interested\", \"people need\", \"people need\", \"people similar\", \"people talk\", \"people want\", \"people want\", \"person hear\", \"pick\", \"pick\", \"pilot\", \"pilot\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"position\", \"position\", \"position\", \"position\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"practical\", \"practical\", \"practical\", \"practical\", \"practical\", \"practical\", \"practice\", \"practice\", \"practice\", \"practice\", \"practice\", \"practiced\", \"preconference\", \"preferably\", \"previously\", \"previously\", \"price\", \"price\", \"price\", \"price\", \"price\", \"problem\", \"problem\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional researcher\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"purchase\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"quality\", \"question\", \"question\", \"question\", \"question\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real business\", \"real world\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really\", \"really cool\", \"reasonable\", \"reasonable\", \"record\", \"record\", \"record\", \"recording\", \"recording\", \"recording\", \"remote\", \"remote\", \"remote\", \"report\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research\", \"research design\", \"research design\", \"research like\", \"research method\", \"research method\", \"research practiced\", \"research product\", \"research professional\", \"research researcher\", \"research track\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"researcher\", \"researcher experience\", \"right\", \"right\", \"right\", \"right\", \"road\", \"road\", \"rosenfeld\", \"rosenfeld\", \"safe\", \"safe\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scaling\", \"scaling\", \"schedule\", \"schedule\", \"schedule\", \"seen\", \"seen\", \"send\", \"send\", \"send\", \"seriously\", \"seriously\", \"seriously\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"similar\", \"similar\", \"similar\", \"simple\", \"sit\", \"sit\", \"sit\", \"sit\", \"sit\", \"site\", \"slack\", \"slack\", \"slack\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"sound\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speech\", \"sponsor\", \"sponsor\", \"spot\", \"spot\", \"spot\", \"stage\", \"stage\", \"stage\", \"start\", \"start\", \"start\", \"start\", \"start\", \"starting\", \"startup\", \"startup\", \"state\", \"streaming\", \"strive uxr\", \"strive uxr\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff\", \"stuff like\", \"subject\", \"subject\", \"subject\", \"support\", \"support\", \"supporting\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure presenter\", \"survey\", \"survey\", \"survey\", \"survey\", \"survey\", \"takeaway\", \"takeaway\", \"takeaway\", \"takeaway\", \"takeaway just\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk workshop\", \"talk workshop\", \"talking\", \"talking\", \"talking\", \"talking\", \"talking\", \"talking\", \"teaching\", \"teaching\", \"teaching\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"tech\", \"tech\", \"tech\", \"tech\", \"tech\", \"technology\", \"theme\", \"theme\", \"theme\", \"theme\", \"theme\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"throw\", \"ticket\", \"ticket\", \"ticket\", \"ticket\", \"ticket\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tip\", \"tool\", \"tool\", \"tool\", \"tool\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"turn\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type researcher\", \"unconference\", \"unconference\", \"unconference\", \"understanding\", \"understanding\", \"unknown\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux\", \"ux researcher\", \"uxr\", \"uxr\", \"uxr\", \"uxr\", \"uxr collective\", \"uxr collective\", \"uxr conference\", \"value\", \"value\", \"value\", \"value\", \"varied\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve\", \"ve seen\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"view\", \"view\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"walk\", \"walk\", \"walk away\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want learn\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way people\", \"way people\", \"weed\", \"went\", \"went\", \"went\", \"wide variety\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worked\", \"worked\", \"workplace\", \"workshop\", \"workshop\", \"workshop\", \"workshop\", \"workshop\", \"workshop\", \"workshop\", \"workshop\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worst\", \"yes\", \"yes\", \"yes\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 7, 8, 2, 5, 3, 6, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el327801121391581763126018302\", ldavis_el327801121391581763126018302_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el327801121391581763126018302\", ldavis_el327801121391581763126018302_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el327801121391581763126018302\", ldavis_el327801121391581763126018302_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.071654 -0.033951       1        1  18.512035\n",
       "6     -0.023704  0.007995       2        1  17.738497\n",
       "7     -0.072232 -0.095030       3        1  15.353280\n",
       "1      0.040122 -0.027800       4        1  13.311889\n",
       "4      0.055020  0.012454       5        1  11.742107\n",
       "2      0.116404 -0.040130       6        1   8.782703\n",
       "5      0.001770  0.085542       7        1   8.744571\n",
       "0     -0.045726  0.090920       8        1   5.814917, topic_info=     Category        Freq        Term       Total  loglift  logprob\n",
       "736   Default  127.000000        make  127.000000  30.0000  30.0000\n",
       "896   Default  133.000000      people  133.000000  29.0000  29.0000\n",
       "573   Default   16.000000    industry   16.000000  28.0000  28.0000\n",
       "1039  Default  199.000000    research  199.000000  27.0000  27.0000\n",
       "553   Default   23.000000        idea   23.000000  26.0000  26.0000\n",
       "...       ...         ...         ...         ...      ...      ...\n",
       "410    Topic8    2.943645  experience   45.343622   0.1101  -5.0935\n",
       "622    Topic8    3.098682        just   59.374194  -0.1081  -5.0421\n",
       "892    Topic8    2.347698         pay   15.930918   0.9299  -5.3197\n",
       "677    Topic8    2.562678        like   51.937658  -0.1642  -5.2321\n",
       "449    Topic8    2.347699       focus   38.590339   0.0452  -5.3197\n",
       "\n",
       "[571 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "9         1  0.128247  academic\n",
       "9         2  0.128247  academic\n",
       "9         3  0.448863  academic\n",
       "9         4  0.192370  academic\n",
       "9         7  0.128247  academic\n",
       "...     ...       ...       ...\n",
       "1402      2  0.766848     worst\n",
       "1408      2  0.240125       yes\n",
       "1408      6  0.480251       yes\n",
       "1408      7  0.240125       yes\n",
       "1409      4  0.779445     young\n",
       "\n",
       "[1299 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 7, 8, 2, 5, 3, 6, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda23, recommendations_matrix, recommendations_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic groups (4)\n",
    "1. pratical\n",
    "2. affordable\n",
    "3. expensive\n",
    "4. levels\n",
    "\n",
    "#### Topic groups (6) - some overlap between 2, 3, & 4; 5 is mostly overlapped with 2 & 4\n",
    "1. ux\n",
    "2. interesting\n",
    "3. content\n",
    "4. food\n",
    "5. learning\n",
    "6. affordalbe\n",
    "\n",
    "#### Topic groups (8) - significant overlap amoung 6 of the 8 groups\n",
    "1. events\n",
    "2. ux\n",
    "3. world\n",
    "4. new\n",
    "5. food\n",
    "6. diverse\n",
    "7. make accessible\n",
    "8. north america"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_W23 = lda23.transform(recommendations_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_doc_column23 = datadf.recommendations.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_matrix23, count_vect23 = nlp.create_wordcount_matrix(datadf.recommendations.dropna(), max_df=0.8, min_df=2, ngram=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA23a = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA23a.fit(word_count_matrix23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda23.fit(recommendations_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_H = LDA23a.transform(word_count_matrix23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.find_top_documents_per_topic(lda_H, top_doc_column23, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
