{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import wrangle\n",
    "import explore\n",
    "import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_counts(input_column, max_df=.3, min_df=2, ngram_range=(1,3), stop_words='english'):\n",
    "    input_column = input_column.dropna().apply(nlp.basic_clean)\n",
    "    input_column = input_column.apply(nlp.lemmatize)\n",
    "    cv = CountVectorizer(max_df=max_df, min_df=min_df, stop_words=stop_words, ngram_range=ngram_range)   \n",
    "    cv_fit=cv.fit_transform(input_column)    \n",
    "    word_list = cv.get_feature_names()    \n",
    "    count_list = cv_fit.toarray().sum(axis=0)\n",
    "    word_counts = {'word_list': word_list, 'count_list': count_list}\n",
    "    df_word_count = pd.DataFrame(data=word_counts)\n",
    "    return df_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df, data_dict = wrangle.wrangle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = explore.add_target_to_df(df)\n",
    "\n",
    "targetB = df.targetb\n",
    "\n",
    "targetB = targetB.reset_index().drop('resp_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.read_csv('topics.csv', index_col=False)\n",
    "\n",
    "big_df.drop('Unnamed: 0', axis=1,inplace=True)\n",
    "\n",
    "big_df['targetB'] = targetB\n",
    "\n",
    "likely = big_df[big_df.targetB == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['like', 'plus', 'real', 'love', 'big', 'avoiding', 'mean', 'content', 'people', 'problem', \n",
    "              'doing', 'using','research', 'work', 'don', 'make', 'conference', 'yes', 've', 'ha', '300']\n",
    "\n",
    "stopWords = nlp.set_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respondents NOT Likely To Go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21702682130075124"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely.big_answer.apply(nlp.find_polarity).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4313958863792966"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely.big_answer.apply(nlp.find_subjectivity).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOTAL KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['researchi',\n",
       " 'phd',\n",
       " 'library',\n",
       " 'information',\n",
       " 'science',\n",
       " 'teaching',\n",
       " 'involved',\n",
       " 'ux',\n",
       " 'architecture',\n",
       " 'interned',\n",
       " 'local',\n",
       " 'firm',\n",
       " 'doe',\n",
       " 'additionally',\n",
       " 'discipline',\n",
       " 'increasingly',\n",
       " 'data',\n",
       " 'getting',\n",
       " 'familiar',\n",
       " 'self']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.big_answer, max_df=.8, stop_words=stopWords, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>attendeessingletrack attendee</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>attendeessingletrack</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>attendeessingletrack attendee experience</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>day</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>50</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>attend</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>company</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>attendee experience</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>time</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>new</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>method</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>speaker</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>researcher</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>talk</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>workshop</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>topic</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>ux</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>event</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>experience</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>design</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     word_list  count_list\n",
       "244              attendeessingletrack attendee          95\n",
       "243                       attendeessingletrack          95\n",
       "245   attendeessingletrack attendee experience          95\n",
       "734                                        day          97\n",
       "28                                          50         101\n",
       "208                                     attend         102\n",
       "507                                    company         104\n",
       "227                        attendee experience         105\n",
       "2915                                      time         108\n",
       "1912                                       new         112\n",
       "1800                                    method         118\n",
       "2643                                   speaker         123\n",
       "2350                                researcher         124\n",
       "2792                                      talk         139\n",
       "3243                                  workshop         157\n",
       "2974                                     topic         158\n",
       "3103                                        ux         186\n",
       "1011                                     event         195\n",
       "1070                                experience         202\n",
       "799                                     design         214"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_answer_df = find_word_counts(likely.big_answer, max_df=.5, stop_words=stopWords, ngram_range=(1,3))\n",
    "big_answer_df.sort_values(by='count_list').tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does your company do?\n",
    "\n",
    "q5 primary industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['higher',\n",
       " 'education',\n",
       " 'higher education',\n",
       " 'food',\n",
       " 'financial',\n",
       " 'banking',\n",
       " 'health',\n",
       " 'healthcare',\n",
       " 'tech',\n",
       " 'ux',\n",
       " 'consulting',\n",
       " 'ux consulting',\n",
       " 'technology',\n",
       " 'consultant',\n",
       " 'company',\n",
       " 'industry',\n",
       " 'design',\n",
       " 'cpg',\n",
       " 'independent',\n",
       " 'freelancer']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.prim_ind_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>government</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fintech</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>consulting</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>financial</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>software</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tech</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>design</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>technology</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>healthcare</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>service</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_list  count_list\n",
       "39  government          16\n",
       "35     fintech          18\n",
       "8   consulting          19\n",
       "33   financial          19\n",
       "76    software          21\n",
       "79        tech          22\n",
       "16      design          23\n",
       "80  technology          24\n",
       "42  healthcare          25\n",
       "74     service          27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words\n",
    "prim_ind_df = find_word_counts(likely.prim_ind_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))\n",
    "prim_ind_df.sort_values(by='count_list').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['higher education',\n",
       " 'ux consulting',\n",
       " 'financial service',\n",
       " 'consulting industry',\n",
       " 'management consulting',\n",
       " 'software design',\n",
       " 'enterprise software',\n",
       " 'information technology',\n",
       " 'customer experience',\n",
       " 'software service',\n",
       " 'public sector',\n",
       " 'product design',\n",
       " 'estate tech',\n",
       " 'digital product',\n",
       " 'saas software',\n",
       " 'fashion retail']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.prim_ind_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>higher education</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>product design</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>software service</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enterprise software</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>financial service</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word_list  count_list\n",
       "7      higher education           3\n",
       "10       product design           3\n",
       "14     software service           3\n",
       "3   enterprise software           4\n",
       "6     financial service          15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ngrams\n",
    "prim_ind_df = find_word_counts(likely.prim_ind_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))\n",
    "prim_ind_df.sort_values(by='count_list').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likely[likely.prim_ind_text.notnull()].prim_ind_topic_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What kind of research are you doing?\n",
    "\n",
    "q7 future_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['think',\n",
       " 'focused',\n",
       " 'social',\n",
       " 'user',\n",
       " 'usability',\n",
       " 'study',\n",
       " 'ethnographic',\n",
       " 'customer',\n",
       " 'interview',\n",
       " 'user usability',\n",
       " 'usability study',\n",
       " 'service',\n",
       " 'design',\n",
       " 'thinking',\n",
       " 'learning',\n",
       " 'quant',\n",
       " 'method',\n",
       " 'qual',\n",
       " 'analysis',\n",
       " 'service design']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.future_res_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>unmoderated</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>usability testing</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>diary</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>user</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>data</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>method</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>usability</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>study</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>testing</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word_list  count_list\n",
       "225        unmoderated          18\n",
       "233  usability testing          21\n",
       "42               diary          21\n",
       "164       quantitative          22\n",
       "237               user          22\n",
       "35                data          25\n",
       "122             method          26\n",
       "230          usability          34\n",
       "192              study          42\n",
       "203            testing          56"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words\n",
    "future_res_text_df = find_word_counts(likely.future_res_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))\n",
    "future_res_text_df.sort_values(by='count_list').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user usability',\n",
       " 'usability study',\n",
       " 'service design',\n",
       " 'quant method',\n",
       " 'card sorting',\n",
       " 'unmoderated usability',\n",
       " 'usability testing',\n",
       " 'unmoderated usability testing',\n",
       " 'study survey',\n",
       " 'unmoderated usability study',\n",
       " 'data science',\n",
       " 'looking new',\n",
       " 'new way',\n",
       " 'looking new way',\n",
       " 'testing card',\n",
       " 'competitive analysis',\n",
       " 'testing card sorting',\n",
       " 'field study',\n",
       " 'diary study',\n",
       " 'multivariate testing']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.future_res_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mixed method</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>focus group</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab testing</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>usability testing</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>diary study</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word_list  count_list\n",
       "32       mixed method           7\n",
       "21        focus group           8\n",
       "1          ab testing          12\n",
       "75  usability testing          16\n",
       "15        diary study          23"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ngrams\n",
    "future_res_text_df = find_word_counts(likely.future_res_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))\n",
    "future_res_text_df.sort_values(by='count_list').tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluative, quantitative, qualitative    76\n",
       "focus group                              57\n",
       "market research                          41\n",
       "card sort                                36\n",
       "moderate, unmoderate                     29\n",
       "misc                                     26\n",
       "journey mapping                          21\n",
       "inquiry                                  21\n",
       "Name: future_res_topic_id, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely[likely.future_res_text.notnull()].future_res_topic_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What kind of research are you doing?\n",
    "\n",
    "q6 types_res_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conduct',\n",
       " 'variety',\n",
       " 'mix',\n",
       " 'qualitative',\n",
       " 'quantitative',\n",
       " 'lot',\n",
       " 'online',\n",
       " 'mix qualitative',\n",
       " 'qualitative quantitative',\n",
       " 'mix qualitative quantitative',\n",
       " 'interview',\n",
       " 'workshop',\n",
       " 'brainstorming',\n",
       " 'market',\n",
       " 'interview workshop',\n",
       " 'ethnography',\n",
       " 'mixed',\n",
       " 'method',\n",
       " 'qual',\n",
       " 'quant']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.types_res_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>analytics</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>study</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>usability testing</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>user</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>qualitative</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>survey</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>testing</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>usability</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>interview</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word_list  count_list\n",
       "349       quantitative          49\n",
       "10           analytics          50\n",
       "409              study          67\n",
       "544  usability testing          75\n",
       "554               user          88\n",
       "325        qualitative          94\n",
       "427             survey         136\n",
       "475            testing         139\n",
       "534          usability         140\n",
       "184          interview         170"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words\n",
    "types_res_df = find_word_counts(likely.types_res_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))\n",
    "types_res_df.sort_values(by='count_list').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mix qualitative',\n",
       " 'qualitative quantitative',\n",
       " 'mix qualitative quantitative',\n",
       " 'interview workshop',\n",
       " 'mixed method',\n",
       " 'qual quant',\n",
       " 'quant survey',\n",
       " 'survey focus',\n",
       " 'focus group',\n",
       " 'design thinking',\n",
       " 'service design',\n",
       " 'design methodology',\n",
       " 'grounded theory',\n",
       " 'theory analysis',\n",
       " 'survey focus group',\n",
       " 'grounded theory analysis',\n",
       " 'product usability',\n",
       " 'usability testing',\n",
       " 'testing contextual',\n",
       " 'contextual inquiry']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.types_res_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>user testing</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>usability study</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>interview survey</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>interview usability</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>diary study</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>contextual inquiry</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>usability test</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>user interview</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>focus group</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>usability testing</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word_list  count_list\n",
       "348         user testing          19\n",
       "319      usability study          19\n",
       "116     interview survey          20\n",
       "119  interview usability          22\n",
       "43           diary study          22\n",
       "25    contextual inquiry          23\n",
       "321       usability test          23\n",
       "338       user interview          24\n",
       "65           focus group          31\n",
       "326    usability testing          75"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ngrams\n",
    "types_res_df = find_word_counts(likely.types_res_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))\n",
    "types_res_df.sort_values(by='count_list').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "focus group                62\n",
       "ngram                      60\n",
       "validation                 49\n",
       "market                     47\n",
       "qual/quant                 42\n",
       "testing                    39\n",
       "generative/mixed method    26\n",
       "misc                       23\n",
       "Name: types_res_topic_id, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely[likely.types_res_text.notnull()].types_res_topic_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What topics would they be most attracted to at a conference about research?\n",
    "\n",
    "q21 ideal_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['like', 'plus', 'real', 'love', 'big', 'avoiding', 'mean', 'content', 'people', 'problem', \n",
    "              'doing', 'using','research', 'work', 'don', 'make', 'conference', 'good', 'best', 'self', 'report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = nlp.set_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['design',\n",
       " 'innovative',\n",
       " 'method',\n",
       " 'communicating',\n",
       " 'working',\n",
       " 'nonresearchers',\n",
       " 'cycle',\n",
       " 'innovative method',\n",
       " 'method communicating',\n",
       " 'participatory',\n",
       " 'analysis',\n",
       " 'design participatory',\n",
       " 'session',\n",
       " 'new',\n",
       " 'methodology',\n",
       " 'case',\n",
       " 'study',\n",
       " 'new methodology',\n",
       " 'case study',\n",
       " 'participant']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.ideal_topics_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>case study</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>product</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>design</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>case</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>practice</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>technique</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>analysis</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>study</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>new</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>method</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_list  count_list\n",
       "56   case study          23\n",
       "295     product          24\n",
       "105      design          27\n",
       "55         case          27\n",
       "287    practice          28\n",
       "389   technique          29\n",
       "18     analysis          31\n",
       "374       study          33\n",
       "251         new          36\n",
       "234      method          83"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words\n",
    "ideal_topics_df = find_word_counts(likely.ideal_topics_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))\n",
    "ideal_topics_df.sort_values(by='count_list').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['innovative method',\n",
       " 'method communicating',\n",
       " 'design participatory',\n",
       " 'new methodology',\n",
       " 'case study',\n",
       " 'participant recruitment',\n",
       " 'recruitment strategy',\n",
       " 'participant recruitment strategy',\n",
       " 'best practice',\n",
       " 'space solution',\n",
       " 'theory practice',\n",
       " 'sell qualitative',\n",
       " 'qualitative quantitative',\n",
       " 'qualitative data',\n",
       " 'want hear',\n",
       " 'creative approach',\n",
       " 'conducting analyzing',\n",
       " 'cutting edge',\n",
       " 'application method',\n",
       " 'data science']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.ideal_topics_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>product team</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>new method</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>mixed method</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best practice</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>case study</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_list  count_list\n",
       "59   product team           5\n",
       "47     new method           8\n",
       "46   mixed method           9\n",
       "9   best practice          10\n",
       "12     case study          23"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bi-grams\n",
    "ideal_topics_df = find_word_counts(likely.ideal_topics_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))\n",
    "ideal_topics_df.sort_values(by='count_list').tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quant/qual/data             77\n",
       "case_study                  73\n",
       "new_method, mixed_method    71\n",
       "ops/ai                      63\n",
       "Name: ideal_topics_topic_id, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely[likely.ideal_topics_text.notnull()].ideal_topics_topic_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who would they expect to see at a conference about research?\n",
    "\n",
    "q22 Ideal Attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['like', 'plus', 'real', 'love', 'big', 'avoiding', 'mean', 'content', 'people', 'problem', \n",
    "              'doing', 'using','research', 'work', 'don', 'make', 'conference']\n",
    "\n",
    "stopWords = nlp.set_stop_words(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['company',\n",
       " 'academic',\n",
       " 'researcher',\n",
       " 'public',\n",
       " 'maker',\n",
       " 'academic researcher',\n",
       " 'leading',\n",
       " 'known',\n",
       " 'skill',\n",
       " 'set',\n",
       " 'expertise',\n",
       " 'good',\n",
       " 'sam',\n",
       " 'ladner',\n",
       " 'sam ladner',\n",
       " 'open',\n",
       " 'woman',\n",
       " 'minority',\n",
       " 'walk',\n",
       " 'just']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.ideal_attendees_text, max_df=.5, stop_words=stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>portigal</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>new</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>steve</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>just</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>field</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>different</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>industry</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>company</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>leader</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>researcher</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_list  count_list\n",
       "256    portigal          14\n",
       "233         new          17\n",
       "330       steve          17\n",
       "178        just          17\n",
       "118       field          20\n",
       "73    different          21\n",
       "160    industry          23\n",
       "47      company          32\n",
       "196      leader          34\n",
       "287  researcher          52"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#terms\n",
    "ideal_attendees_df = find_word_counts(likely.ideal_attendees_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))\n",
    "ideal_attendees_df.sort_values(by='count_list').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['academic researcher',\n",
       " 'sam ladner',\n",
       " 'different field',\n",
       " 'civic tech',\n",
       " 'steve portigal',\n",
       " 'working company',\n",
       " 'kim goodwin',\n",
       " 'laura klein',\n",
       " 'way working',\n",
       " 'industry folk',\n",
       " 'social scientist',\n",
       " 'industry thought',\n",
       " 'thought leader',\n",
       " 'natalie hanson',\n",
       " 'industry leader',\n",
       " 'jared spool',\n",
       " 'spool steve',\n",
       " 'google facebook',\n",
       " 'jared spool steve',\n",
       " 'spool steve portigal']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.ideal_attendees_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>erika hall</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>jared spool</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>indi young</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sam ladner</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>steve portigal</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_list  count_list\n",
       "18      erika hall           7\n",
       "32     jared spool           8\n",
       "26      indi young           8\n",
       "56      sam ladner          11\n",
       "63  steve portigal          14"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bigrams\n",
    "ideal_attendees_df = find_word_counts(likely.ideal_attendees_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))\n",
    "ideal_attendees_df.sort_values(by='count_list').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry, team, product    76\n",
       "sam ladner, erika hall     55\n",
       "experience, jared spool    52\n",
       "indi young                 52\n",
       "Name: ideal_attendees_topic_id, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely[likely.ideal_attendees_text.notnull()].ideal_attendees_topic_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What advice do they have for the Rosenfeld Media team in pursuing a conference?\n",
    "q23 recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dont',\n",
       " 'create',\n",
       " 'schedule',\n",
       " 'relevant',\n",
       " 'event',\n",
       " 'looking',\n",
       " 'forward',\n",
       " 'looking forward',\n",
       " 'nice',\n",
       " 'bring',\n",
       " 'practitioner',\n",
       " 'researcher',\n",
       " 'academic',\n",
       " 'position',\n",
       " 'similar',\n",
       " 'tool',\n",
       " 'strategy',\n",
       " 'key',\n",
       " 'opinion',\n",
       " 'leader']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.recommendations_text, max_df=.9, stop_words=stopWords, ngram_range=(1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>need</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>topic</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>speaker</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>just</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>experience</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>way</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>good</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>event</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>researcher</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>talk</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_list  count_list\n",
       "393        need          24\n",
       "600       topic          25\n",
       "533     speaker          26\n",
       "309        just          27\n",
       "190  experience          28\n",
       "648         way          28\n",
       "234        good          29\n",
       "182       event          40\n",
       "486  researcher          42\n",
       "570        talk          44"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words\n",
    "recommendations_df = find_word_counts(likely.recommendations_text, max_df=.5, stop_words=stopWords, ngram_range=(1,3))\n",
    "recommendations_df.sort_values(by='count_list').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['looking forward',\n",
       " 'good luck',\n",
       " 'event know',\n",
       " 'ux researcher',\n",
       " 'advice talk',\n",
       " 'networking event',\n",
       " 'introvert extrovert',\n",
       " 'food good',\n",
       " 'good mix',\n",
       " 'mix speaker',\n",
       " 'way learn',\n",
       " 'high quality',\n",
       " 'want attend',\n",
       " 'healthy food',\n",
       " 'food option',\n",
       " 'time break',\n",
       " 'talk specific',\n",
       " 'leading team',\n",
       " 'thought leader',\n",
       " 'lightning talk']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.show_column_keywords(likely.recommendations_text, max_df=.9, stop_words=stopWords, ngram_range=(2,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_list</th>\n",
       "      <th>count_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>thought leader</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>code conduct</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>senior researcher</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>experienced researcher</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>level experience</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word_list  count_list\n",
       "70          thought leader           3\n",
       "5             code conduct           4\n",
       "59       senior researcher           4\n",
       "17  experienced researcher           4\n",
       "37        level experience           5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ngrams\n",
    "recommendations_df = find_word_counts(likely.recommendations_text, max_df=.5, stop_words=stopWords, ngram_range=(2,3))\n",
    "recommendations_df.sort_values(by='count_list').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker, industry      67\n",
       "group, career, city    57\n",
       "event, opportunity     52\n",
       "good, know             45\n",
       "field, survery         41\n",
       "Name: recommendations_topic_id, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likely[likely.recommendations_text.notnull()].recommendations_topic_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Documents per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=4, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix, count_vect = nlp.create_wordcount_matrix(likely.recommendations_text, max_df=.3, ngram=(1,3), stop_words=stopWords)\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=4, random_state=42)\n",
    "\n",
    "LDA.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_dict = {0 : 'speaker, industry', \n",
    "                        1 : 'event, opportunity', \n",
    "                        2 : 'good, know', \n",
    "                        3 : 'field, survery', \n",
    "                        4 : 'group, career, city'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Documents for Topic 0: \n",
      "\n",
      "Document 1\n",
      "I think more events for experienced practitioners would be nice. I’m not sure how’d you’d do that at a conference, but, in general, it’s nice to have space for people who are trying to advance research at their organization. A lot of events seem geared toward getting research off the ground or breaking into the business, which I also love, but sometimes it’s nice to have a conversation that goes beyond the basics. \n",
      "\n",
      "Document 2\n",
      "Short periods of structured interaction are good - NOT \"find a buddy and learn about each other\" but more like group speed dating: \"Create a circle of 5-6 chairs and for 10 minutes your topic is X.\" \n",
      "\n",
      "Provide ways to text Qs to a moderator, who can then ask them of the speaker at the end of the talk - because if I have to ask a Q with a microphone, I will be too distracted by that to concentrate on the talk itself.\n",
      "\n",
      "Lots of bottled water for breaks - conferences always run out and leave nothing but flavored drinks.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Document 3\n",
      "For the love of god, do not ask non-researchers to present actual research. It's so terribly disheartening to see poor-quality research presented from a stage. Have professionals do it. If you get researchers who know what they're doing, they may need coaching for how to present dramatically and with interest. I'd rather see someone who has contributed to the knowledge of the world who needs a little help with jazz hands than some 28-year-old who doesn't know what a p-value is pretend they've just invented \"technology studies.\"\n",
      "\n",
      "Document 4\n",
      "Don't assume that you know; continue to hone and refine with input from potential participants.\n",
      "Ask keynote speakers to talk specifics- not super generic 'my company is so amazing because we do great research\"; really get into the details or the specifics.  I'd rather see a keynote that doesn't have a flashy C-Suite title but is capable of actually talking about what's going on in the world than a C-Suite flashy name that isn't actually doing the work any more, but is just leading a team through it (and then taking the credit for being a 'thought leader' to this amazing team).\n",
      "\n",
      "Document 5\n",
      "I'd love to be involved in that, as I'm pretty passionate about supporting and growing researchers.  \n",
      "\n",
      "I see a huge number of early-career folks who are struggling to get work in UX research roles, and we need to get them real-world experience (not just the General Assembly courses or an academic degree).  The world will benefit greatly from having more skilled researchers in it, but the current paths we have for gaining experience are fairly limited.  We need to grow more senior researchers and research strategists. We need to grow business acumen and help people gain strategies for dealing with organizations that don't embrace research (or apply the results).  \n",
      "\n",
      "I would LOVE to have a \"Conspiracy\" session - to envision and map out how Research can move from a supportive role to one that drives the direction that companies invest in.  How might we change the power-structure over time (what types of events, people, actions need to be embraced to get us there as a \"field\".  I'd love to lead that conversation... :)\n",
      "\n",
      "Top 5 Documents for Topic 1: \n",
      "\n",
      "Document 1\n",
      "\"hypothetically\" ;)\n",
      "\n",
      "Given your author base, I can easily see Rosenfeld putting together an amazing lineup for a conference.  Your far greater challenge -- as you know, hence this survey -- is carving out your niche. I wish I had better advice about that.\n",
      "\n",
      "I feel that the \"techniques\" side is covered across a range of conferences. I feel like there are less conferences that really focus on the strategic (and possibly ops) side of research. Likewise there might be opportunities around more directly exploring the alchemic process of turning research into action.\n",
      "\n",
      "Document 2\n",
      "This goes in the face of all of my previous answers because I don't really like workshops, but I think opportunities to apply what's being presented are really impactful. If there are creative ways to build activities into the day, that would be fun. I went to the Innovation Learning Network in-person event a few years ago and they organized surprise field trips to local organizations who were doing innovation work; that was a cool non-workshop way to bring the conference topics to life. \n",
      "\n",
      "Document 3\n",
      "Consider that the audience may be in different maturity levels of the research practice at least for some sessions so you may have different tracks based on that to cover a wider range of people.\n",
      "\n",
      "At a certain level of maturity, co-working sessions can be more enlighting than workshops so it may be interesting to build some knowledge from the conference. Especially because product design research is a discipline that we are currently nailing and adapting to our needs and there are lots of topics that we should build together as a community. It is tricky in logistic terms but very catchy as well.\n",
      "\n",
      "To have different ways to assist to the conference so you can afford a broader audience (i.e: people that cannot attend due to the length of the event or its total price when it means travelling abroad to expensive cities such as SF or NYC).\n",
      "\n",
      "Document 4\n",
      "Make sure to consider the needs of attendees at all stages of their career. Past conferences I have attended have sometimes felt more appropriate for one audience vs another (e.g., early career qual researchers vs veterans) and this can result in a conference that is not as valuable as it should be to a large segment of attendees.\n",
      "\n",
      "Also consider offering speaking/presentation slots of 90 minutes in addition to shorter 50-60 minute sessions. The QRCA annual conference used to include both but has recently eliminated the 90 minute slots. For some topics and speakers, 60 min is adequate but in some cases, a session would be much better in a longer format, especially if it enables greater Q&A/audience interaction.\n",
      "\n",
      "Document 5\n",
      "Ha ha ha. I wonder how this would be similar to or different from EPIC? I like the idea of a small, intimate conference that focuses on interactive sessions and workshops rather than papers (there is a place for that too, but I feel there are enough of those). I'd love a space where I can take my own challenges on my team and in terms of my experience and work on those so I have a game plan when I get back to my office--i.e. maybe some coaching in how to define challenges and possible approaches, with some solid materials on tech trends in digital products. \n",
      "\n",
      "I also see a space for retraining academics for this field--I get asked about this a lot and have written about it on my website (http://www.rachelfleming.net/faqs) and will be writing more, as this is a critical need right now. I want to get involved more in helping academics find new employment options. \n",
      "\n",
      "I'm not sure where you're based but having the conference be within the US would probably help with getting my company to pay for it. Advertising well in advance is also helpful because I have to decide about the conference I'm attending several months before. As for venue, I prefer retreat settings to a hotel or conference center, to set the tone of it being a transformational experience. \n",
      "\n",
      "Top 5 Documents for Topic 2: \n",
      "\n",
      "Document 1\n",
      "Find fun ways to let researchers act as researchees in interesting ways. Floating between the two could be fun. Build empathy from both sides.\n",
      "\n",
      "I'd also consider bringing in some random topics. Opera. Bookbinding. NASA water systems. I read an article years back about a leading designer who was being asked about how he kept engaged with his craft. He said he studies \"other\" things. He'd take ballroom dancing, or read about physics, or any non-subject related topics. Inevitably he'd find inspiration in those topics while reflecting on design tasks.  We're creatures of analogy. Setting up learning experiences where we can let individuals connect the dots between seemingly unrelated topics can be exhilarating!  \n",
      "\n",
      "Think Mixed tastes: \n",
      "\n",
      "https://mcadenver.org/events/series/mixed-taste-dcpa-2019\n",
      "\n",
      "Document 2\n",
      "Reminder that not all UX research projects begin with an app or digital experience in mind. Much of the solutions to today’s problems require behavior change that won’t be cured with a shiny toy. Analog methods are still very much relevant. Play is still very much a part of discovery.\n",
      "\n",
      "Other than that, pick a location that is convenient and not to expensive and that is near reasonably priced dining and accommodations and transportation hubs. Find ways to welcome all types of people, like activities that accommodate both introverts and extroverts, healthy food options that address various diets, time during breaks and comfortable hallways to network in, if possible offer a one day or two day pass. \n",
      "\n",
      "Document 3\n",
      "Please have a conference about research!!! Design is so much more widely accepted and gaining traction, and research teams are coming up right behind them (in my universe, not everywhere). Would love to learn about best practices, methods, how to make an impact. I would love the opportunity to build more solid relationships with the interesting people I have encountered in places like Twitter and Slack. Have it in NYC, that is your stomping ground! Try it as a 1 day event and see how it goes. If it's awesome, make it longer + workshops. I'd love a day in NYC to hear a bunch of talks. I would also love to see how I could be paired or teamed up with people who have a similar level of experience/challenges so we could cohort together and share how we work and help each other advance. Looking forward to hearing more about your findings and how this might manifest into an event!\n",
      "\n",
      "Document 4\n",
      "Don't be afraid to mimic conferences that are doing things right.\n",
      "For instance, An Event Apart limits their attendees to a manageable size and highly curates their speakers.\n",
      "Front Utah did a great job with the welcoming committee and allowing for longer breaks between sessions (4 30-minute talks, and then a 30 minute break). They also did a great job of getting folks out into the surrounding city where they host (every swag bag had a $20 bill and a map of local restaurants w/in walking distance -- attendees were encouraged to group up and go find lunch).\n",
      "Lots of conferences use Slack for pre-conference introductions, a channel for each speaker, they handle Q&A through the Slack channels (which allows attendees to \"vote\" for their questions if they've already been asked)... it's an interesting use of a communication platform like that.\n",
      "\n",
      "Document 5\n",
      "Have a lot of them rather than one, small, exclusive one. Go do it where the interested attendees are.\n",
      "Offer day-long or multiday workshops for the people who need to learn methods.\n",
      "Look into whether you could offer continuing education credits for people who need that.\n",
      "Ask attendees during registration to chip in to the scholarship funds for people who can't pay to go. Get some sponsorship for that.\n",
      "No plastic water bottles and as few as possible disposables\n",
      "No junk swag, no RM-logo t-shirts\n",
      "Recycle lanyards and badgeholders\n",
      "No photos without permission\n",
      "People can put what they want on their badges, but focus on first names\n",
      "Get someone to make a more usable Attendify and use that\n",
      "Start a Mattermost for attendees to talk and network in across all your conferences\n",
      "Publish videos of all the talks for free so you can help people not have to travel and so you can multiply the educational effectiveness over time and distance\n",
      "Breakfast worth waking up for\n",
      "Easy ways to hang out with each other in the evenings, such as dinner party lotteries, BOFs, geeky fun\n",
      "Sessions that start no earlier than 10 and quit no later than 6\n",
      "Long lunch break if people have to find it outside and do it during rush-lunch\n",
      "Coffee worth drinking\n",
      "An observational outing to a fascinating nearby place\n",
      "Gee, I better quit here before I end up on a committee or something\n",
      "\n",
      "Top 5 Documents for Topic 3: \n",
      "\n",
      "Document 1\n",
      "Think outside the typical conference box. Allow for more discussion and deep dives on actual research studies. As a participant I want to engage and create take-aways and artifacts that I can share with colleagues when I get back to work. I don't mind getting homework to complete. I want to network through structured activities. I want to stay connected to fellow participants over time and continue discussions until the next \"conference\". \n",
      "\n",
      "Document 2\n",
      "Diversity on all levels, including levels of experience. A code of conduct. Considerations for childcare and rooms for pumping/infant care clearly stated on the event site. A range of options and prices for lodging. If food is served, consideration for all kinds of diets and allergies. Giveaways that are sustainable and usable. I like sxsw and other conferences which allow people to vote on topics or specific talks to help guide the schedule.\n",
      "\n",
      "Document 3\n",
      "Have a wide variety of topics, for people of various levels of experience (some topics are interesting to me but not applicable since I'm a junior researcher. For example, I would love to hear how someone leads a global research team, but that advice isn't immediately relevant to me since I'm far from being a supervisor.  Instead, I'd be interested to hear from someone who has been in research for 1-2 years, and built a research practice from the ground up. I would want to know how they did that since I'm trying to do that)\n",
      "\n",
      "Document 4\n",
      "The two conferences I have attended in the past year have been on the smaller side (250-500 attendees), have been 1 or 2 days, and had built-in networking times with a social hour after. Both of these conferences (UX Burlington and Talk UX) were nicely intimate, and you could eat lunch with the speakers if you were lucky to sit at the same table as them. Lot's of food options for folks with food sensitivities and allergies is always appreciated! Most conferences default to the sandwich/wrap/salad option, but I always say conferences should consider a burrito bar. \n",
      "\n",
      "Document 5\n",
      "I don't know what the ideal ratio is for most people  of talks to not-talks. My growing preference is \"anything but talks\". Sitting quietly to see people talk for 8 hours seems like an inefficient way to learn or spend your time, and doesn't suit my learning style.\n",
      "A mix of workshops, hands-on learning, lightning talks by new speakers with new perspectives to share, off-site activities / site visits, \"networking by doing stuff\"... that would be my sweet spot. Throw in a keynote or two maybe. \n",
      "I feel I am not alone in this view, especially when i talk to more senior practitioners. They are often not in the talk but outside, chatting. \n",
      "\n",
      "Other advice: I'm biased and maybe trying to sell my own agenda a bit here, but feel that there is a growing distaste for long-haul air travel. You're seeing that in Europe in the \"never fly\" movement. \n",
      "If you did multiple regional events (a bit like how An Event Apart does it), instead of a big International 1-time event, that could help environmentally-conscious folk make the decision more easily. \n",
      "Also, having a posted zero-waste approach (no vendor tchotckes!), carbon offset policy, etc can help ppl alleviate the guilt.  \n",
      "\n",
      "Remote events: I know Rosenfeld has done all-remote events in the past (I don't know how they went, I haven't seen any new ones posted). I'm curious about the potential of remote workshop events over just remote \"webinar\" talky events. I've been to a couple of remote design/participation events (facilitated by Jim Kalbach's MURAL), and I think they are on to something. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nlp.find_top_documents_per_topic(LDA.transform(doc_term_matrix), likely.recommendations_text, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
